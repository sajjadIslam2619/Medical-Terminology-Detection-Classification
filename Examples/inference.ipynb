{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from scipy.special import softmax\n",
    "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import BertForTokenClassification, BertTokenizer\n",
    "\n",
    "import processor\n",
    "from processor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "save_model_address = './trained_models/C-Bert-test'\n",
    "model = BertForTokenClassification.from_pretrained(save_model_address, num_labels=num_labels)\n",
    "tokenizer = BertTokenizer.from_pretrained(save_model_address, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_text = [['He',\n",
    " 'was',\n",
    " 'admitted',\n",
    " ',',\n",
    " 'taken',\n",
    " 'to',\n",
    " 'the',\n",
    " 'operating',\n",
    " 'room',\n",
    " 'where',\n",
    " 'he',\n",
    " 'underwent',\n",
    " 'L5-S1',\n",
    " 'right',\n",
    " 'hemilaminectomy',\n",
    " 'and',\n",
    " 'discectomy',\n",
    " '.']\n",
    ", \n",
    "['Over',\n",
    " 'the',\n",
    " 'next',\n",
    " 'three',\n",
    " 'days',\n",
    " 'he',\n",
    " 'increased',\n",
    " 'his',\n",
    " 'activity',\n",
    " 'gradually',\n",
    " ',',\n",
    " 'was',\n",
    " 'able',\n",
    " 'to',\n",
    " 'do',\n",
    " 'stairs',\n",
    " 'with',\n",
    " 'Physical',\n",
    " 'Therapy',\n",
    " 'and',\n",
    " 'had',\n",
    " 'pain',\n",
    " 'which',\n",
    " 'could',\n",
    " 'be',\n",
    " 'controlled',\n",
    " 'with',\n",
    " 'oral',\n",
    " 'analgesics',\n",
    " '.'],\n",
    "\n",
    "['However', ',', 'her', 'creatinine', 'continued', 'to', 'increase', '.']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_tags = [['O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'B-treatment',\n",
    " 'I-treatment',\n",
    " 'I-treatment',\n",
    " 'O',\n",
    " 'B-treatment',\n",
    " 'O'],\n",
    "                 \n",
    " ['O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'B-treatment',\n",
    " 'I-treatment',\n",
    " 'O',\n",
    " 'O',\n",
    " 'B-problem',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'B-treatment',\n",
    " 'I-treatment',\n",
    " 'O'],\n",
    " \n",
    " ['O', 'O', 'B-test', 'I-test', 'O', 'O', 'O', 'O']                \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_input_ids, query_input_tags, query_attention_masks = process_data(clinical_text, clinical_tags, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_inputs = torch.tensor(query_input_ids)\n",
    "query_tags = torch.tensor(query_input_tags)\n",
    "query_masks = torch.tensor(query_attention_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(input_ids, label_ids, input_mask):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, token_type_ids=None,\n",
    "        attention_mask=input_mask)\n",
    "        # For eval mode, the first result of outputs is logits\n",
    "        logits = outputs[0] \n",
    "    # Get NER predict result\n",
    "    logits = torch.argmax(F.log_softmax(logits, dim=2), dim=2)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    # Get NER true result\n",
    "    label_ids = label_ids.to('cpu').numpy()\n",
    "    # Only predict the real word, mark=0, will not calculate\n",
    "    input_mask = input_mask.to('cpu').numpy()\n",
    "    # Compare the valuable predict result\n",
    "    for i, mask in enumerate(input_mask):\n",
    "        # Real one\n",
    "        temp_1 = []\n",
    "        # Predict one\n",
    "        temp_2 = []\n",
    "        for j, m in enumerate(mask):\n",
    "            # Mark=0, meaning its a pad word, dont compare\n",
    "            if m:\n",
    "                if tag2name[label_ids[i][j]] != \"X\" and tag2name[label_ids[i][j]] != \"[CLS]\" and tag2name[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n",
    "                    # print(tag2name[logits[i][j]])\n",
    "                    temp_1.append(tag2name[label_ids[i][j]])\n",
    "                    temp_2.append(tag2name[logits[i][j]])\n",
    "            else:\n",
    "                break\n",
    "        y_true.append(temp_1)\n",
    "        y_pred.append(temp_2)\n",
    "\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = model_evaluation(query_inputs, query_tags, query_masks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, digits=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     problem     1.0000    1.0000    1.0000         1\n",
      "        test     1.0000    1.0000    1.0000         1\n",
      "   treatment     1.0000    1.0000    1.0000         4\n",
      "\n",
      "   micro avg     1.0000    1.0000    1.0000         6\n",
      "   macro avg     1.0000    1.0000    1.0000         6\n",
      "weighted avg     1.0000    1.0000    1.0000         6\n",
      "\n",
      "f1 socre: 1.000000\n",
      "Accuracy score: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Get acc , recall, F1 result report\n",
    "report = classification_report(y_true, y_pred, digits=4)\n",
    "\n",
    "# Save the report into file\n",
    "output_eval_file = \"eval_results.txt\"\n",
    "\n",
    "with open(output_eval_file, \"w\") as writer:\n",
    "    print(\"***** Eval results *****\")\n",
    "    print(\"\\n%s\"%(report))\n",
    "    print(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\n",
    "    print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
    "    \n",
    "    writer.write(\"f1 socre:\\n\")\n",
    "    writer.write(str(f1_score(y_true, y_pred)))\n",
    "    writer.write(\"\\n\\nAccuracy score:\\n\")\n",
    "    writer.write(str(accuracy_score(y_true, y_pred)))\n",
    "    writer.write(\"\\n\\n\")  \n",
    "    writer.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['              precision    recall  f1-score   support',\n",
       " '',\n",
       " '     problem     1.0000    1.0000    1.0000         1',\n",
       " '        test     1.0000    1.0000    1.0000         1',\n",
       " '   treatment     1.0000    1.0000    1.0000         4',\n",
       " '',\n",
       " '   micro avg     1.0000    1.0000    1.0000         6',\n",
       " '   macro avg     1.0000    1.0000    1.0000         6',\n",
       " 'weighted avg     1.0000    1.0000    1.0000         6',\n",
       " '']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(bert_out_address, num_labels=len(tag2idx))\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_out_address, do_lower_case=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = ' '.join(test_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Over the next three days he increased his activity gradually , was able to do stairs with Physical Therapy and had pain which could be controlled with oral analgesics .'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = []\n",
    "temp_token = []\n",
    "temp_token.append('[CLS]')\n",
    "token_list = tokenizer.tokenize(test_query)\n",
    "temp_token.extend(token_list)\n",
    "temp_token = temp_token[:max_len-1]\n",
    "temp_token.append('[SEP]')\n",
    "input_id = tokenizer.convert_tokens_to_ids(temp_token)\n",
    "padding_len = max_len - len(input_id)\n",
    "input_id = input_id + ([0] * padding_len)\n",
    "tokenized_texts = []\n",
    "tokenized_texts.append(input_id)\n",
    "attention_masks = [[int(i>0) for i in input_id]]\n",
    "\n",
    "tokenized_texts = torch.tensor(tokenized_texts)\n",
    "attention_masks = torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set save model to Evalue loop\n",
    "model.eval()\n",
    "# Get model predict result\n",
    "with torch.no_grad():\n",
    "        outputs = model(tokenized_texts, token_type_ids=None,\n",
    "        attention_mask=None,)\n",
    "        # For eval mode, the first result of outputs is logits\n",
    "        logits = outputs[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_results = logits.detach().cpu().numpy()\n",
    "result_arrays_soft = softmax(predict_results[0])\n",
    "result_list = np.argmax(result_arrays_soft,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [tag2name[t] for t in result_list]\n",
    "pretok_sent = \"\"\n",
    "pretags = \"\"\n",
    "for i, tok in enumerate(temp_token):\n",
    "     if tok.startswith(\"##\"):\n",
    "         pretok_sent += tok[2:]\n",
    "     else:\n",
    "         pretok_sent += \" \" + tok\n",
    "         pretags += \" \" + result[i]\n",
    "pretok_sent = pretok_sent[1:]\n",
    "pretags = pretags[1:]\n",
    "\n",
    "s = pretok_sent.split()\n",
    "t = pretags.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:[CLS]\n",
      "Predict_Tag:[CLS]\n",
      "\n",
      "Token:Over\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:the\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:next\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:three\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:days\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:he\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:increased\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:his\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:activity\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:gradually\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:,\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:was\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:able\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:to\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:do\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:stairs\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:with\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:Physical\n",
      "Predict_Tag:B-treatment\n",
      "\n",
      "Token:Therapy\n",
      "Predict_Tag:I-treatment\n",
      "\n",
      "Token:and\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:had\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:pain\n",
      "Predict_Tag:B-problem\n",
      "\n",
      "Token:which\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:could\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:be\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:controlled\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:with\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:oral\n",
      "Predict_Tag:B-treatment\n",
      "\n",
      "Token:anal\n",
      "Predict_Tag:I-treatment\n",
      "\n",
      "Token:##ges\n",
      "Predict_Tag:X\n",
      "\n",
      "Token:##ics\n",
      "Predict_Tag:X\n",
      "\n",
      "Token:.\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:[SEP]\n",
      "Predict_Tag:[SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, mark in enumerate(attention_masks[0]):\n",
    "    if mark>0:\n",
    "        print(\"Token:%s\"%(temp_token[i]))\n",
    "#         print(\"Tag:%s\"%(result_list[i]))\n",
    "        print(\"Predict_Tag:%s\"%(tag2name[result_list[i]]))\n",
    "        #print(\"Posibility:%f\"%(result_array[i][result_list[i]]))\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(temp_token)\n",
    "re = ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "from docx.enum.text import WD_COLOR_INDEX\n",
    "# Create an instance of a word document\n",
    "doc = docx.Document()\n",
    "\n",
    "# Add a Title to the document \n",
    "doc.add_heading('Results', 0)\n",
    "\n",
    "# Creating paragraph with some content\n",
    "para = doc.add_paragraph(''' ''')\n",
    "  \n",
    "flag_treatment, flag_problem, flag_test = 0, 0, 0 \n",
    "for i in range(1, len(t)-1):\n",
    "    if t[i] == 'B-treatment':\n",
    "        flag_treatment = 1\n",
    "        para.add_run(s[i]+' ').font.highlight_color = WD_COLOR_INDEX.RED\n",
    "        # print(print_treatment(s[i]), end=' ')\n",
    "    elif (t[i] == 'I-treatment' or t[i] == 'X') and flag_treatment == 1 :\n",
    "        para.add_run(s[i]+' ').font.highlight_color = WD_COLOR_INDEX.RED\n",
    "    elif t[i] == 'B-test':\n",
    "        flag_test = 1\n",
    "        para.add_run(s[i]+' ').font.highlight_color = WD_COLOR_INDEX.PINK\n",
    "    elif (t[i] == 'I-test' or t[i] == 'X') and flag_test == 1 :\n",
    "        para.add_run(s[i]+' ').font.highlight_color = WD_COLOR_INDEX.PINK\n",
    "    elif t[i] == 'B-problem':\n",
    "        flag_problem = 1\n",
    "        para.add_run(s[i]+' ').font.highlight_color = WD_COLOR_INDEX.TURQUOISE\n",
    "    elif (t[i] == 'I-problem' or t[i] == 'X') and flag_problem == 1 :\n",
    "        para.add_run(s[i]+' ').font.highlight_color = WD_COLOR_INDEX.TURQUOISE    \n",
    "    elif t[i] == 'O':\n",
    "        flag_treatment, flag_problem, flag_test = 0, 0, 0 \n",
    "        para.add_run(s[i]+' ').font.highlight_color = WD_COLOR_INDEX.AUTO\n",
    "        \n",
    "\n",
    "# # Adding more content to paragraph and highlighting them\n",
    "# para.add_run(''' It contains well written, well thought and well-explained '''\n",
    "#             ).font.highlight_color = WD_COLOR_INDEX.YELLOW\n",
    "  \n",
    "# # Adding more content to paragraph\n",
    "# para.add_run('''computer science and programming articles, quizzes etc.''')\n",
    "  \n",
    "# Now save the document to a location \n",
    "doc.save('result.docx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "def print_treatment(word):\n",
    "    return colored(word,'white','on_red', attrs=['underline'])\n",
    "def print_test(word):\n",
    "    return colored(word, 'white','on_magenta')\n",
    "def print_problem(word):\n",
    "    return colored(word, 'magenta','on_cyan', attrs=['reverse', 'bold'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[7m\u001b[46m\u001b[35mproblem\u001b[0m\n",
      "\u001b[4m\u001b[41m\u001b[37mtreatment\u001b[0m\n",
      "\u001b[45m\u001b[37mtest\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(print_problem('problem'))\n",
    "print(print_treatment('treatment'))\n",
    "print(print_test('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the next three days he increased his activity gradually , was able to do stairs with \u001b[4m\u001b[41m\u001b[37mPhysical\u001b[0m \u001b[4m\u001b[41m\u001b[37mTherapy\u001b[0m and had \u001b[1m\u001b[7m\u001b[46m\u001b[35mpain\u001b[0m which could be controlled with \u001b[4m\u001b[41m\u001b[37moral\u001b[0m \u001b[4m\u001b[41m\u001b[37manalgesics\u001b[0m . "
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "location = {}\n",
    "flag_treatment, flag_problem, flag_test = 0, 0, 0 \n",
    "for i in range(1, len(t)-1):\n",
    "    if t[i] == 'B-treatment':\n",
    "        flag_treatment = 1\n",
    "        print(print_treatment(s[i]), end=' ')\n",
    "    elif (t[i] == 'I-treatment' or t[i] == 'X') and flag_treatment == 1 :\n",
    "        print(print_treatment(s[i]), end=' ')\n",
    "    elif t[i] == 'B-test':\n",
    "        flag_test = 1\n",
    "        print(print_test(s[i]), end=' ')\n",
    "    elif (t[i] == 'I-test' or t[i] == 'X') and flag_test == 1 :\n",
    "        print(print_test(s[i]), end=' ')\n",
    "    elif t[i] == 'B-problem':\n",
    "        flag_problem = 1\n",
    "        print(print_problem(s[i]), end=' ')\n",
    "    elif (t[i] == 'I-problem' or t[i] == 'X') and flag_problem == 1 :\n",
    "        print(print_problem(s[i]), end=' ')    \n",
    "    elif t[i] == 'O':\n",
    "        flag_treatment, flag_problem, flag_test = 0, 0, 0 \n",
    "        print(s[i], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_lable = []\n",
    "temp_token = []\n",
    "\n",
    "# Add [CLS] at the front \n",
    "temp_lable.append('[CLS]')\n",
    "temp_token.append('[CLS]')\n",
    "\n",
    "# Tokenize words\n",
    "# [lidocaine patch] -> lid ##oc ##aine patch\n",
    "# [B-treatment I-treatment] -> B-treatment X X I-treatment\n",
    "for word, lab in zip(word_list, label):\n",
    "    token_list = tokenizer.tokenize(word)\n",
    "    for m, token in enumerate(token_list):\n",
    "        temp_token.append(token)\n",
    "        if m == 0:\n",
    "            temp_lable.append(lab)\n",
    "        else:\n",
    "            temp_lable.append('X')  \n",
    "            \n",
    "# Add [SEP] at the end\n",
    "temp_lable.append('[SEP]')\n",
    "temp_token.append('[SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object) :\n",
    "    \"\"\"\n",
    "    input a dataframe\n",
    "    \n",
    "    \n",
    "    Generate sets of words and tags.\n",
    "    self.sentence:\n",
    "    Each sentence is a list\n",
    "    [('Supraventricular', 'B-problem'),\n",
    "    ('tachycardia', 'I-problem'),\n",
    "    ('(', 'O'),\n",
    "    ('on', 'O'),\n",
    "    ('a', 'B-treatment'),\n",
    "    ('beta', 'I-treatment'),\n",
    "    ('blocker', 'I-treatment'),\n",
    "    (')', 'O')]\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"].values.tolist(),\n",
    "                                                        #    s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def get_examples(self):\n",
    "        return random.sample(self.sentences, 10)\n",
    "    \n",
    "    def get_sentences(self):\n",
    "        return[[s[0] for s in sent] for sent in self.sentences]\n",
    "        \n",
    "    def get_labels(self):\n",
    "        return [[s[1] for s in sent] for sent in self.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputGenerater(object):\n",
    "    def __init__(self, sentences, labels) -> None:\n",
    "        self.tokenized_texts = []\n",
    "        self.word_piece_labels = []\n",
    "        i_inc = 0\n",
    "        for word_list,label in (zip(sentences,labels)):\n",
    "            temp_lable = []\n",
    "            temp_token = []\n",
    "            \n",
    "            # Add [CLS] at the front \n",
    "            temp_lable.append('[CLS]')\n",
    "            temp_token.append('[CLS]')\n",
    "            \n",
    "            for word,lab in zip(word_list,label):\n",
    "                token_list = tokenizer.tokenize(word)\n",
    "                for m,token in enumerate(token_list):\n",
    "                    temp_token.append(token)\n",
    "                    if m==0:\n",
    "                        temp_lable.append(lab)\n",
    "                    else:\n",
    "                        temp_lable.append('X')  \n",
    "                        \n",
    "            # Add [SEP] at the end\n",
    "            temp_lable.append('[SEP]')\n",
    "            temp_token.append('[SEP]')\n",
    "            \n",
    "            self.tokenized_texts.append(temp_token)\n",
    "            self.word_piece_labels.append(temp_lable)\n",
    "            \n",
    "            if 5 > i_inc:\n",
    "                print(\"No.%d,len:%d\"%(i_inc,len(temp_token)))\n",
    "                print(\"texts:%s\"%(\" \".join(temp_token)))\n",
    "                print(\"No.%d,len:%d\"%(i_inc,len(temp_lable)))\n",
    "                print(\"lables:%s\"%(\" \".join(temp_lable)))\n",
    "            i_inc +=1\n",
    "            \n",
    "        self.input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in self.tokenized_texts],\n",
    "                    maxlen=config.MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "            \n",
    "    def get_input_ids(self):    \n",
    "        return self.input_ids\n",
    "    \n",
    "    def get_tags(self):\n",
    "        tags = pad_sequences([[get_tag2idx().get(l) for l in lab] for lab in self.word_piece_labels],\n",
    "                        maxlen=config.MAX_LEN, value=get_tag2idx()[\"O\"], padding=\"post\",\n",
    "                        dtype=\"long\", truncating=\"post\")\n",
    "        return tags\n",
    "    def get_attention_masks(self):\n",
    "        attention_masks = [[int(i>0) for i in ii] for ii in self.input_ids]\n",
    "        return attention_masks\n",
    "    def get_segment_ids(self):\n",
    "        segment_ids = [[0] * len(input_id) for input_id in self.input_ids]\n",
    "        return segment_ids\n",
    "\n",
    "\n",
    "def convert_to_tensor(*inputs, drop_last=False):\n",
    "    data = TensorDataset(*tuple(torch.tensor(inputs)))\n",
    "    data_sampler = RandomSampler(data)\n",
    "    # Drop last can make batch training better for the last one\n",
    "    dataloader = DataLoader(data, sampler=data_sampler, batch_size=config.BATCH_NUM, drop_last=drop_last)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.0,len:5\n",
      "texts:[CLS] admission date : [SEP]\n",
      "No.0,len:5\n",
      "lables:[CLS] O O O [SEP]\n",
      "No.1,len:7\n",
      "texts:[CLS] 2014 - 12 - 29 [SEP]\n",
      "No.1,len:7\n",
      "lables:[CLS] O X X X X [SEP]\n",
      "No.2,len:6\n",
      "texts:[CLS] all ##er ##gies : [SEP]\n",
      "No.2,len:6\n",
      "lables:[CLS] O X X O [SEP]\n",
      "No.3,len:4\n",
      "texts:[CLS] 17 units [SEP]\n",
      "No.3,len:4\n",
      "lables:[CLS] O O [SEP]\n",
      "No.4,len:22\n",
      "texts:[CLS] includes a history of at ##rial fi ##bri ##lla ##tion with good heart rate control on dig ##ox ##in . [SEP]\n",
      "No.4,len:22\n",
      "lables:[CLS] O O O O B-problem X I-problem X X X O O B-treatment I-treatment I-treatment O B-treatment X X O [SEP]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pad_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b054d79cb97e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputGenerater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-dec2e08486b9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, labels)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mi_inc\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         self.input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in self.tokenized_texts],\n\u001b[0m\u001b[1;32m     38\u001b[0m                     maxlen=config.MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pad_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(config.data_path_test, sep=\"\\t\").astype(str)\n",
    "sg = SentenceGetter(df_test)\n",
    "sentences = sg.get_sentences()\n",
    "tags = sg.get_labels()\n",
    "test_sets = InputGenerater(sentences=sentences, labels=tags)\n",
    "\n",
    "test_inputs = test_sets.get_input_ids()\n",
    "test_tags = test_sets.get_tags()\n",
    "test_attetion_masks = test_sets.get_attention_masks()\n",
    "\n",
    "test_dataloader = utils.convert_to_tensor(test_inputs, test_attetion_masks, test_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = glob.glob('processed/test/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0289.tsv',\n",
       " '0090.tsv',\n",
       " '0246.tsv',\n",
       " '0390.tsv',\n",
       " '0365.tsv',\n",
       " '0174.tsv',\n",
       " '0282.tsv',\n",
       " '0305.tsv',\n",
       " '0150.tsv',\n",
       " '0101.tsv',\n",
       " '0086.tsv',\n",
       " '0357.tsv',\n",
       " '0230.tsv',\n",
       " '0294.tsv',\n",
       " '0377.tsv',\n",
       " '0266.tsv',\n",
       " '0050.tsv',\n",
       " '0026.tsv',\n",
       " '0049.tsv',\n",
       " '0029.tsv',\n",
       " '0005.tsv',\n",
       " '0081.tsv',\n",
       " '0466.tsv',\n",
       " '0245.tsv',\n",
       " '0378.tsv',\n",
       " '0463.tsv',\n",
       " '0445.tsv',\n",
       " '0053.tsv',\n",
       " '0477.tsv',\n",
       " '0461.tsv',\n",
       " '0362.tsv',\n",
       " '0473.tsv',\n",
       " '0309.tsv',\n",
       " '0415.tsv',\n",
       " '0222.tsv',\n",
       " '0329.tsv',\n",
       " '0474.tsv',\n",
       " '0393.tsv',\n",
       " '0345.tsv',\n",
       " '0109.tsv',\n",
       " '0129.tsv',\n",
       " '0454.tsv',\n",
       " '0366.tsv',\n",
       " '0082.tsv',\n",
       " '0439.tsv',\n",
       " '0173.tsv',\n",
       " '0094.tsv',\n",
       " '0025.tsv',\n",
       " '0270.tsv',\n",
       " '0133.tsv',\n",
       " '0261.tsv',\n",
       " '0153.tsv',\n",
       " '0237.tsv',\n",
       " '0074.tsv',\n",
       " '0046.tsv',\n",
       " '0066.tsv',\n",
       " '0037.tsv',\n",
       " '0338.tsv',\n",
       " '0285.tsv',\n",
       " '0425.tsv',\n",
       " '0322.tsv',\n",
       " '0385.tsv',\n",
       " '0446.tsv',\n",
       " '0141.tsv',\n",
       " '0138.tsv',\n",
       " '0121.tsv',\n",
       " '0421.tsv',\n",
       " '0389.tsv',\n",
       " '0186.tsv',\n",
       " '0233.tsv',\n",
       " '0134.tsv',\n",
       " '0054.tsv',\n",
       " '0013.tsv',\n",
       " '0190.tsv',\n",
       " '0185.tsv',\n",
       " '0409.tsv',\n",
       " '0205.tsv',\n",
       " '0442.tsv',\n",
       " '0433.tsv',\n",
       " '0321.tsv',\n",
       " '0374.tsv',\n",
       " '0342.tsv',\n",
       " '0465.tsv',\n",
       " '0009.tsv',\n",
       " '0229.tsv',\n",
       " '0437.tsv',\n",
       " '0427.tsv',\n",
       " '0318.tsv',\n",
       " '0073.tsv',\n",
       " '0214.tsv',\n",
       " '0431.tsv',\n",
       " '0333.tsv',\n",
       " '0405.tsv',\n",
       " '0457.tsv',\n",
       " '0310.tsv',\n",
       " '0460.tsv',\n",
       " '0146.tsv',\n",
       " '0041.tsv',\n",
       " '0234.tsv',\n",
       " '0193.tsv',\n",
       " '0269.tsv',\n",
       " '0102.tsv',\n",
       " '0349.tsv',\n",
       " '0301.tsv',\n",
       " '0394.tsv',\n",
       " '0386.tsv',\n",
       " '0238.tsv',\n",
       " '0157.tsv',\n",
       " '0061.tsv',\n",
       " '0428.tsv',\n",
       " '0117.tsv',\n",
       " '0078.tsv',\n",
       " '0262.tsv',\n",
       " '0464.tsv',\n",
       " '0468.tsv',\n",
       " '0249.tsv',\n",
       " '0265.tsv',\n",
       " '0470.tsv',\n",
       " '0225.tsv',\n",
       " '0369.tsv',\n",
       " '0302.tsv',\n",
       " '0058.tsv',\n",
       " '0105.tsv',\n",
       " '0197.tsv',\n",
       " '0118.tsv',\n",
       " '0217.tsv',\n",
       " '0346.tsv',\n",
       " '0209.tsv',\n",
       " '0113.tsv',\n",
       " '0242.tsv',\n",
       " '0142.tsv',\n",
       " '0410.tsv',\n",
       " '0449.tsv',\n",
       " '0034.tsv',\n",
       " '0475.tsv',\n",
       " '0354.tsv',\n",
       " '0382.tsv',\n",
       " '0337.tsv',\n",
       " '0436.tsv',\n",
       " '0169.tsv',\n",
       " '0430.tsv',\n",
       " '0448.tsv',\n",
       " '0154.tsv',\n",
       " '0202.tsv',\n",
       " '0093.tsv',\n",
       " '0070.tsv',\n",
       " '0210.tsv',\n",
       " '0341.tsv',\n",
       " '0325.tsv',\n",
       " '0440.tsv',\n",
       " '0401.tsv',\n",
       " '0194.tsv',\n",
       " '0434.tsv',\n",
       " '0182.tsv',\n",
       " '0181.tsv',\n",
       " '0398.tsv',\n",
       " '0122.tsv',\n",
       " '0033.tsv',\n",
       " '0002.tsv',\n",
       " '0277.tsv',\n",
       " '0257.tsv',\n",
       " '0361.tsv',\n",
       " '0038.tsv',\n",
       " '0014.tsv',\n",
       " '0158.tsv',\n",
       " '0198.tsv',\n",
       " '0290.tsv',\n",
       " '0418.tsv',\n",
       " '0467.tsv',\n",
       " '0201.tsv',\n",
       " '0334.tsv',\n",
       " '0057.tsv',\n",
       " '0126.tsv',\n",
       " '0443.tsv',\n",
       " '0042.tsv',\n",
       " '0098.tsv',\n",
       " '0451.tsv',\n",
       " '0177.tsv',\n",
       " '0125.tsv',\n",
       " '0189.tsv',\n",
       " '0476.tsv',\n",
       " '0018.tsv',\n",
       " '0472.tsv',\n",
       " '0166.tsv',\n",
       " '0001.tsv',\n",
       " '0022.tsv',\n",
       " '0462.tsv',\n",
       " '0298.tsv',\n",
       " '0258.tsv',\n",
       " '0254.tsv',\n",
       " '0370.tsv',\n",
       " '0458.tsv',\n",
       " '0030.tsv',\n",
       " '0062.tsv',\n",
       " '0213.tsv',\n",
       " '0422.tsv',\n",
       " '0170.tsv',\n",
       " '0226.tsv',\n",
       " '0162.tsv',\n",
       " '0416.tsv',\n",
       " '0278.tsv',\n",
       " '0273.tsv',\n",
       " '0306.tsv',\n",
       " '0419.tsv',\n",
       " '0314.tsv',\n",
       " '0297.tsv',\n",
       " '0381.tsv',\n",
       " '0161.tsv',\n",
       " '0085.tsv',\n",
       " '0069.tsv',\n",
       " '0250.tsv',\n",
       " '0350.tsv',\n",
       " '0281.tsv',\n",
       " '0317.tsv',\n",
       " '0130.tsv',\n",
       " '0218.tsv',\n",
       " '0110.tsv',\n",
       " '0241.tsv',\n",
       " '0413.tsv',\n",
       " '0424.tsv',\n",
       " '0330.tsv',\n",
       " '0326.tsv',\n",
       " '0402.tsv',\n",
       " '0397.tsv',\n",
       " '0178.tsv',\n",
       " '0114.tsv',\n",
       " '0358.tsv',\n",
       " '0045.tsv',\n",
       " '0286.tsv',\n",
       " '0137.tsv',\n",
       " '0006.tsv',\n",
       " '0106.tsv',\n",
       " '0373.tsv',\n",
       " '0471.tsv',\n",
       " '0149.tsv',\n",
       " '0452.tsv',\n",
       " '0145.tsv',\n",
       " '0274.tsv',\n",
       " '0406.tsv',\n",
       " '0021.tsv',\n",
       " '0253.tsv',\n",
       " '0065.tsv',\n",
       " '0206.tsv',\n",
       " '0455.tsv',\n",
       " '0221.tsv',\n",
       " '0097.tsv',\n",
       " '0077.tsv',\n",
       " '0469.tsv',\n",
       " '0412.tsv',\n",
       " '0089.tsv',\n",
       " '0017.tsv',\n",
       " '0353.tsv',\n",
       " '0293.tsv',\n",
       " '0313.tsv',\n",
       " '0010.tsv',\n",
       " '0165.tsv']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(config.INDIVIDUAL_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 socre:\n",
      "1.0\n",
      "\n",
      "Accuracy score:\n",
      "1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     problem     1.0000    1.0000    1.0000         1\n",
      "        test     1.0000    1.0000    1.0000         1\n",
      "   treatment     1.0000    1.0000    1.0000         4\n",
      "\n",
      "   micro avg     1.0000    1.0000    1.0000         6\n",
      "   macro avg     1.0000    1.0000    1.0000         6\n",
      "weighted avg     1.0000    1.0000    1.0000         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"eval_results.txt\", \"r\")\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 2.7.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
