{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40f33c9122440e388be874d90a3d77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 09:23:32 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "========================\n",
      "\n",
      "2022-05-02 09:23:32 INFO: Use device: cpu\n",
      "2022-05-02 09:23:32 INFO: Loading: tokenize\n",
      "2022-05-02 09:23:32 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForTokenClassification, BertTokenizer\n",
    "from termcolor import colored\n",
    "import copy\n",
    "import stanza\n",
    "try:\n",
    "    nlp = stanza.Pipeline(lang='en', processors='tokenize')\n",
    "except Exception:\n",
    "    stanza.download('en')\n",
    "    nlp = stanza.Pipeline(lang='en', processors='tokenize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Admission Date:  [**2118-6-2**]       Discharge Date:  [**2118-6-14**]  Date of Birth:                    Sex:  F  Service:  MICU and then to [**Doctor Last Name **] Medicine  HISTORY OF PRESENT ILLNESS:  This is an 81-year-old female with a history of emphysema (not on home O2), who presents with three days of shortness of breath thought by her primary care doctor to be a COPD flare.  Two days prior to admission, she was started on a prednisone taper and one day prior to admission she required oxygen at home in order to maintain oxygen saturation greater than 90%.  She has also been on levofloxacin and nebulizers, and was not getting better, and presented to the [**Hospital1 18**] Emergency Room.  In the [**Hospital3 **] Emergency Room, her oxygen saturation was 100% on CPAP.  She was not able to be weaned off of this despite nebulizer treatment and Solu-Medrol 125 mg IV x2.  Review of systems is negative for the following:  Fevers, chills, nausea, vomiting, night sweats, change in weight, gastrointestinal complaints, neurologic changes, rashes, palpitations, orthopnea.  Is positive for the following: Chest pressure occasionally with shortness of breath with exertion, some shortness of breath that is positionally related, but is improved with nebulizer treatment.  PAST MEDICAL HISTORY: 1. COPD.  Last pulmonary function tests in [**2117-11-3**] demonstrated a FVC of 52% of predicted, a FEV1 of 54% of predicted, a MMF of 23% of predicted, and a FEV1:FVC ratio of 67% of predicted, that does not improve with bronchodilator treatment.  The FVC, however, does significantly improve with bronchodilator treatment consistent with her known reversible air flow obstruction in addition to an underlying restrictive ventilatory defect.  The patient has never been on home oxygen prior to this recent episode.  She has never been on steroid taper or been intubated in the past. 2. Lacunar CVA.  MRI of the head in [**2114-11-4**] demonstrates \"mild degree of multiple small foci of high T2 signal within the white matter of both cerebral hemispheres as well as the pons, in the latter region predominantly to the right of midline.  The abnormalities, while nonspecific in etiology, are most likely secondary to chronic microvascular infarction.  There is no mass, lesion, shift of the normal midline strictures or hydrocephalus.  The major vascular flow patterns are preserved.  There is moderate right maxillary, moderate bilateral ethmoid, mild left maxillary, minimal right sphenoid, and frontal sinus mucosal thickening.  These abnormalities could represent an allergic or some other type of inflammatory process.  Additionally noted is a moderately enlarged subtotally empty sella turcica\". 3. Angina:  Most recent stress test was in [**2118-1-3**] going for four minutes with a rate pressure product of 10,000, 64% of maximum predicted heart rate without evidence of ischemic EKG changes or symptoms.  The imaging portion of the study demonstrated no evidence of myocardial ischemia and a calculated ejection fraction of 84%.  The patient denies angina at rest and gets angina with walking a few blocks. Are alleviated by sublingual nitroglycerin. 4. Hypothyroidism on Synthroid. 5. Depression on Lexapro. 6. Motor vehicle accident with head injury approximately 10 years ago.  MEDICATIONS ON ADMISSION: 1. Hydrochlorothiazide 25 q.d. 2. Prednisone 60 mg, 50 mg, 40 mg, 20 mg. 3. Levofloxacin 500 mg q.d. 4. Imdur 60 mg q.d. 5. Synthroid 75 mcg q.d. 6. Pulmicort nebulizer b.i.d. 7. Albuterol nebulizer q.4. prn. 8. Lexapro 10 mg q.d. 9. Protonix 40 mg q.d. 10. Aspirin 81 mg q.d.  ALLERGIES:  Norvasc leads to lightheadedness and headache.  FAMILY HISTORY:  Noncontributory.  SOCIAL HISTORY:  Lives with her husband, Dr. [**Known lastname 1809**] an eminent Pediatric Neurologist at [**Hospital3 1810**].  The patient is a prior smoker, but has not smoked in over 10 years.  She has no known alcohol use and she is a full code.  PHYSICAL EXAM AT TIME OF ADMISSION:  Blood pressure 142/76, heart rate 100 and regular, respirations at 17-21, and 97% axillary temperature.  She was saturating at 100% on CPAP with dry mucous membranes.  An elderly female in no apparent distress.  Pupils are equal, round, and reactive to light and accommodation.  Extraocular movements are intact.  Oropharynx difficult to assess due to CPAP machine.  No evidence of jugular venous pressure, however, the strap from the CPAP machine obscures the neck exam.  Cranial nerves II through XII are grossly intact.  Neck is supple without lymphadenopathy.  Heart exam:  Tachycardic, regular, obscured by loud bilateral wheezing with increase in the expiratory phase as well as profuse scattered rhonchi throughout the lung fields.  Positive bowel sounds, soft, nontender, nondistended, obese, no masses.  Mild edema of the lower extremities without clubbing or cyanosis, no rashes.  There is a right hand hematoma.  Strength is assessed as [**5-9**] in the lower extremities, [**5-9**] in the upper extremities with a normal mental status and cognition.  LABORATORY STUDIES:  White count 19, hematocrit 41, platelets 300.  Chem-7:  127, 3.6, 88, 29, 17, 0.6, 143.  Troponin was negative.  CKs were negative times three.  Initial blood gas showed a pH of 7.4, pO2 of 66, pCO2 of 54.  Chest x-ray demonstrates a moderate sized hiatal hernia, segmental atelectasis, left lower lobe infiltrate versus segmental atelectasis.  EKG shows normal sinus rhythm at 113 beats per minute, normal axis, no evidence of ST-T wave changes.  BRIEF SUMMARY OF HOSPITAL COURSE: 1. COPD/dyspnea/pneumonia:  The patient was initially placed on an aggressive steroid taper and admitted to the Medical Intensive Care Unit due to her difficulty with oxygenation despite CPAP machine.  She was also given nebulizer treatments q.4h. as well as chest PT.  The nebulizers were increased to q.1h. due to the fact that she continued to have labored breathing.  Due to persistent respiratory failure and labored breathing, the patient was intubated on [**2118-6-7**] in order to improve oxygenation, ventilation, and ability to suction.  A bronchoscopy was performed on [**2118-6-7**], which demonstrated marked narrowing of the airways with expiration consistent with tracheomalacia.  On [**2118-6-9**], two silicone stents were placed, one in the left main stem (12 x 25 and one in the trachea 16 x 40) by Dr. [**First Name (STitle) **] [**Name (STitle) **] under rigid bronchoscopy with general anesthesia.  On [**2118-6-11**], the patient was extubated to a cool mist shovel mask and her oxygen was titrated down to 2 liters nasal cannula at which time she was transferred to the medical floor.  On the medical floor, the steroids were weaned to off on [**2118-6-14**], and the patient was saturating at 97% on 2 liters, 92% on room air.  On [**2118-6-14**], the patient was seen again by the Interventional Pulmonology service, who agreed that she looked much improved and recommended that she go to pulmonary rehabilitation with followup within six weeks\\cf4 \\\\'\\cf2  time status post placement of stents in respiratory failure.  2. Cardiovascular:  The patient was ruled out for a MI.  She did have another episode on the medical floor of chest pain, which showed no evidence of EKG changes and negative troponin, negative CKs x3.  She was continued on aspirin, Imdur, and diltiazem for rate control per her outpatient regimen.  3. Hypertension:  She was maintained on diltiazem and hydrochlorothiazide with adequate blood pressure control and normalization of electrolytes.  4. Hematuria:  The patient had intermittent hematuria likely secondary to Foley placement.  The Foley catheter was discontinued on [**2118-6-14**].  She had serial urinalyses, which were all negative for signs of infection.  5. Hyperglycemia:  Patient was placed on insulin-sliding scale due to hyperglycemia, which was steroid induced.  This worked quite well and her glucose came back to normal levels once the steroids were tapered to off.  6. Leukocytosis:  Patient did have a profound leukocytosis of 20 to 22 during much of her hospital course.  As the steroids were tapered to off, her white blood cell count on [**2118-6-14**] was 15,000.  It was felt that the leukocytosis was secondary to both steroids as well as question of a left lower lobe pneumonia.  7. For the left lower lobe pneumonia, the patient had initially received a course of levofloxacin 500 p.o. q.d. from [**2118-6-4**] to [**2118-6-10**].  This was restarted on [**2118-6-12**] for an additional seven day course given the fact that she still had the leukocytosis and still had marked rales at the left lower lobe.  8. Hypothyroidism:  The patient was continued on outpatient medical regimen.  9. Depression:  The patient was continued on Lexapro per outpatient regimen.  It is recommended that she follow up with a therapist as an outpatient due to the fact that she did have a blunted affect throughout much of the hospital course, and did appear clinically to be depressed.  10. Prophylaxis:  She was maintained on proton-pump inhibitor with subQ Heparin.  11. Sore throat:  The patient did have a sore throat for much of the hospital course post extubation.  This was treated with Cepacol lozenges as well as KBL liquid (a solution containing Kaopectate, Bismuth, and lidocaine) at bedtime.  12. Communication/code status:  The patient was full code throughout her hospital course, and communication was maintained with the patient and her husband.  13. Muscle weakness:  The patient did have profound muscle weakness and was evaluated by Physical Therapy, and was found to have impaired functional mobility, impaired musculoskeletal performance, impaired gas exchange, impaired endurance, impaired ventilation, and needed help with supine to sit.  However, she was able to tolerate sitting in a chair for approximately one hour.  On motor exam, her flexors and extensors of the lower extremities were [**4-8**] at the knee, [**4-8**] at the ankle, [**4-8**] at the elbows, and [**4-8**] hips.  It was felt that this weakness was most likely due to a combination of steroid myopathy as well as muscle atrophy secondary to deconditioning after a prolonged hospital course.  14. Speech/swallow:  The patient had a Speech and Swallow evaluation showing no evidence of dysphagia, no evidence of vocal cord damage status post tracheal stent placement.  DISCHARGE CONDITION:  The patient was able to oxygenate on room air at 93% at the time of discharge.  She was profoundly weak, but was no longer tachycardic and had a normal blood pressure.  Her respirations were much improved albeit with transmitted upper airway sounds.  DISCHARGE STATUS:  The patient will be discharged to [**Hospital1 **] for both pulmonary and physical rehabilitation.  DISCHARGE MEDICATIONS: 1. Levothyroxine 75 mcg p.o. q.d. 2. Citalopram 10 mg p.o. q.d. 3. Aspirin 81 mg p.o. q.d. 4. Fluticasone 110 mcg two puffs inhaled b.i.d. 5. Salmeterol Diskus one inhalation b.i.d. 6. Acetaminophen 325-650 mg p.o. q.4-6h. prn. 7. Ipratropium bromide MDI two puffs inhaled q.2h. prn. 8. Albuterol 1-2 puffs inhaled q.2h. prn. 9. Zolpidem tartrate 5 mg p.o. q.h.s. prn. 10. Isosorbide dinitrate 10 mg p.o. t.i.d. 11. Diltiazem 60 mg p.o. q.i.d. 12. Pantoprazole 40 mg p.o. q.24h. 13. Trazodone 25 mg p.o. q.h.s. prn. 14. SubQ Heparin 5000 units subcutaneous b.i.d. until such time that the patient is able to get out of bed twice a day. 15. Cepacol lozenges q.2h. prn. 16. Levofloxacin 500 mg p.o. q.d. for a seven day course to be completed on [**2118-6-21**]. 17. Kaopectate/Benadryl/lidocaine 5 mL p.o. b.i.d. prn, not to be given around mealtimes for concern of dysphagia induced by lidocaine. 18. Lorazepam 0.5-2 mg IV q.6h. prn.  FOLLOW-UP PLANS:  The patient is recommended to followup with Dr. [**First Name4 (NamePattern1) **] [**Last Name (NamePattern1) 1407**], [**Telephone/Fax (1) 1408**] within two weeks of leaving of the hospital.  She is also recommended to followup with the Interventional Pulmonary service for followup status post stent placement.  She is also recommended to followup with a neurologist if her muscle weakness does not improve within one week on physical therapy with concern for steroid-induced myopathy.  FINAL DIAGNOSES: 1. Tracheomalacia status post tracheal and left main stem bronchial stent placement. 2. Hypertension. 3. Hypothyroidism. 4. Restrictive lung defect. 5. Depression.                        DR.[**Last Name (STitle) **],[**First Name3 (LF) **] 12-207   Dictated By:[**Last Name (NamePattern1) 1811**] MEDQUIST36  D:  [**2118-6-14**]  11:30 T:  [**2118-6-14**]  11:33 JOB#:  [**Job Number 1812**]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from NER.processor import *\n",
    "from NER.ner_utils import *\n",
    "from NER import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(tag2idx)\n",
    "save_model_address = '../trained_models/NER/C-Bert-test'\n",
    "model = BertForTokenClassification.from_pretrained(save_model_address, num_labels=num_labels)\n",
    "tokenizer = BertTokenizer.from_pretrained(save_model_address, do_lower_case=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_long_text(long_text):\n",
    "    all_sentences = []\n",
    "    all_tags = []\n",
    "    doc = nlp(long_text)\n",
    "    for i, sentence in enumerate(doc.sentences):\n",
    "        # temp_token: tokenized words\n",
    "        # input_ids: convert temp_token to id\n",
    "        temp_token, input_ids, attention_masks = create_query(sentence, tokenizer)\n",
    "        result_list = model_inference(model, input_ids)\n",
    "        result = [tag2name[t] for t in result_list]\n",
    "        pretok_sent = \"\"\n",
    "        pretags = \"\"\n",
    "        for i, tok in enumerate(temp_token):\n",
    "            if tok.startswith(\"##\"):\n",
    "                pretok_sent += tok[2:]\n",
    "            else:\n",
    "                pretok_sent += f\" {tok}\"\n",
    "                pretags += f\" {result[i]}\"\n",
    "        pretok_sent = pretok_sent[1:]\n",
    "        pretags = pretags[1:]\n",
    "        s = pretok_sent.split()\n",
    "        t = pretags.split()\n",
    "        all_sentences.append(s)\n",
    "        all_tags.append(t)\n",
    "    return all_sentences, all_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences, all_tags = predict_long_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_with_problem = []\n",
    "all_problems_in_text_tmp = []\n",
    "all_treatment_in_text = []\n",
    "all_test_in_text = []\n",
    "\n",
    "for n, (s, t) in enumerate(zip(all_sentences, all_tags)):\n",
    "    flag_treatment, flag_problem, flag_test = 0, 0, 0     \n",
    "    problem_in_sentence = ''\n",
    "    treatment_in_sentence = []\n",
    "    test_in_sentence = []\n",
    "    \n",
    "    for i in range(1, len(t)-1):\n",
    "        if t[i] == 'B-problem':\n",
    "            flag_problem = 1\n",
    "            # if there is entities, add the index of sentence to a list\n",
    "            # sentences_with_problem.append(n)\n",
    "            # append the index of entity to a list\n",
    "            if problem_in_sentence: \n",
    "                problem_in_sentence = problem_in_sentence + '| ' + str(i)\n",
    "            else: \n",
    "                problem_in_sentence += str(i)\n",
    "        elif t[i] == 'I-problem' or t[i] == 'X' and flag_problem == 1 :\n",
    "            problem_in_sentence =  problem_in_sentence + ' ' + str(i)\n",
    "\n",
    "        elif t[i] == 'B-test':\n",
    "            flag_test = 1\n",
    "            test_in_sentence.append(i)\n",
    "        elif t[i] == 'I-test' or t[i] == 'X' and flag_test == 1 :\n",
    "            test_in_sentence.append(i)\n",
    "\n",
    "        elif t[i] == 'B-treatment':\n",
    "            flag_treatment = 1\n",
    "            treatment_in_sentence.append(i)\n",
    "        elif t[i] == 'I-treatment' or t[i] == 'X' and flag_treatment == 1 :\n",
    "            treatment_in_sentence.append(i)   \n",
    "            \n",
    "        elif t[i] == 'O' or t[i] == 'X':\n",
    "            flag_treatment, flag_problem, flag_test = 0, 0, 0 \n",
    "            # print(s[i], end=' ')\n",
    "            \n",
    "    all_problems_in_text_tmp.append(problem_in_sentence)\n",
    "    all_treatment_in_text.append(treatment_in_sentence)\n",
    "    all_test_in_text.append(test_in_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_problems_in_text = []\n",
    "for x in all_problems_in_text_tmp:\n",
    "    if x:\n",
    "        index = x.split('|')\n",
    "        tmp = [i.split() for i in index]\n",
    "        all_problems_in_text.append(tmp)\n",
    "    else: \n",
    "        all_problems_in_text.append(x)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " [['14'], ['28', '29', '30'], ['39', '40', '41']],\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " [['10'],\n",
       "  ['12'],\n",
       "  ['14'],\n",
       "  ['16'],\n",
       "  ['18', '19'],\n",
       "  ['21', '22', '23'],\n",
       "  ['25', '26'],\n",
       "  ['28', '29'],\n",
       "  ['31'],\n",
       "  ['33'],\n",
       "  ['35']],\n",
       " [['11', '12', '13'], ['17', '18', '19', '20', '24']],\n",
       " [['7']],\n",
       " '',\n",
       " [['14', '15', '16', '17', '18', '19'], ['23', '24', '25', '26', '27']],\n",
       " [['11', '12', '13']],\n",
       " '',\n",
       " [['3', '4']],\n",
       " [['22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32']],\n",
       " [['1', '2'], ['14', '15', '16']],\n",
       " [['4'], ['6'], ['8', '9', '10', '11', '12', '13'], ['15']],\n",
       " [['3']],\n",
       " [['3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   '13',\n",
       "   '14',\n",
       "   '15',\n",
       "   '16',\n",
       "   '17',\n",
       "   '18',\n",
       "   '19',\n",
       "   '20',\n",
       "   '21',\n",
       "   '22',\n",
       "   '23']],\n",
       " [['1', '2'], ['5', '9', '10', '11', '12', '13']],\n",
       " [['4', '5', '6', '7', '8', '10']],\n",
       " '',\n",
       " [['42', '43', '44'], ['46']],\n",
       " [['11', '12']],\n",
       " [['4'], ['9']],\n",
       " '',\n",
       " [['3']],\n",
       " [['3']],\n",
       " [['7', '8']],\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " [['43']],\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " [['10', '11', '12']],\n",
       " [['6', '7']],\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " [['5', '6']],\n",
       " '',\n",
       " [['5']],\n",
       " [['4'],\n",
       "  ['10', '11', '12', '16', '17', '18'],\n",
       "  ['22', '23', '24', '25', '26', '27', '28']],\n",
       " [['7'], ['9'], ['11'], ['14']],\n",
       " [['1', '2', '3', '4', '5', '6'], ['8'], ['10'], ['13']],\n",
       " [['3', '4', '5', '6']],\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " [['6', '7', '8', '9', '10'],\n",
       "  ['12', '13'],\n",
       "  ['15', '16', '17', '18'],\n",
       "  ['20', '21']],\n",
       " [['18', '19', '20', '21', '22']],\n",
       " [['9'], ['11'], ['13']],\n",
       " [['21', '22', '23', '24']],\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " [['10', '11']],\n",
       " [['3', '4', '5'], ['7', '8']],\n",
       " [['20', '21', '22', '23', '24'], ['29']],\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " [['7', '8']],\n",
       " [['11', '12'], ['19']],\n",
       " '',\n",
       " [['3']],\n",
       " '',\n",
       " [['3']],\n",
       " [['4', '5']],\n",
       " '',\n",
       " [['11', '13']],\n",
       " [['3'], ['15']],\n",
       " '',\n",
       " [['3'], ['8', '9', '10']],\n",
       " '',\n",
       " [['5', '6'], ['17', '18', '19', '20', '21']],\n",
       " [['4', '5', '6', '7', '8']],\n",
       " [['29', '30'], ['34', '35', '36', '37', '38', '39', '40']],\n",
       " [['3']],\n",
       " '',\n",
       " [['3']],\n",
       " '',\n",
       " [['22', '23', '24'], ['38']],\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " [['5', '6', '7']],\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " [['3', '4']],\n",
       " [['5', '6', '7'],\n",
       "  ['20', '21', '22'],\n",
       "  ['24', '25', '26'],\n",
       "  ['28', '29', '30'],\n",
       "  ['32', '33'],\n",
       "  ['35', '36']],\n",
       " '',\n",
       " '',\n",
       " [['5', '6'], ['15', '16'], ['20', '21'], ['24']],\n",
       " '',\n",
       " [['13'], ['18', '19', '20']],\n",
       " '',\n",
       " '',\n",
       " [['3', '4'], ['10']],\n",
       " [['8', '9', '10', '11']],\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " [['31']],\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " [['11', '12', '13'], ['26', '27', '28', '29']],\n",
       " [['6']],\n",
       " [['3']],\n",
       " [['3']],\n",
       " [['3', '4', '5']],\n",
       " [['3']],\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_problems_in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[CLS]',\n",
       "  'Admission',\n",
       "  'Date',\n",
       "  ':',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '2',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Discharge',\n",
       "  'Date',\n",
       "  ':',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '14',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Date',\n",
       "  'of',\n",
       "  'Birth',\n",
       "  ':',\n",
       "  'Sex',\n",
       "  ':',\n",
       "  'F',\n",
       "  'Service',\n",
       "  ':',\n",
       "  'MICU',\n",
       "  'and',\n",
       "  'then',\n",
       "  'to',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Doctor',\n",
       "  'Last',\n",
       "  'Name',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'Medicine', 'HISTORY', 'OF', 'PRESENT', 'ILLNESS', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'This',\n",
       "  'is',\n",
       "  'an',\n",
       "  '81',\n",
       "  '-',\n",
       "  'year',\n",
       "  '-',\n",
       "  'old',\n",
       "  'female',\n",
       "  'with',\n",
       "  'a',\n",
       "  'history',\n",
       "  'of',\n",
       "  'emphysema',\n",
       "  '(',\n",
       "  'not',\n",
       "  'on',\n",
       "  'home',\n",
       "  'O2',\n",
       "  ')',\n",
       "  ',',\n",
       "  'who',\n",
       "  'presents',\n",
       "  'with',\n",
       "  'three',\n",
       "  'days',\n",
       "  'of',\n",
       "  'shortness',\n",
       "  'of',\n",
       "  'breath',\n",
       "  'thought',\n",
       "  'by',\n",
       "  'her',\n",
       "  'primary',\n",
       "  'care',\n",
       "  'doctor',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'COPD',\n",
       "  'flare',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Two',\n",
       "  'days',\n",
       "  'prior',\n",
       "  'to',\n",
       "  'admission',\n",
       "  ',',\n",
       "  'she',\n",
       "  'was',\n",
       "  'started',\n",
       "  'on',\n",
       "  'a',\n",
       "  'prednisone',\n",
       "  'taper',\n",
       "  'and',\n",
       "  'one',\n",
       "  'day',\n",
       "  'prior',\n",
       "  'to',\n",
       "  'admission',\n",
       "  'she',\n",
       "  'required',\n",
       "  'oxygen',\n",
       "  'at',\n",
       "  'home',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'maintain',\n",
       "  'oxygen',\n",
       "  'saturation',\n",
       "  'greater',\n",
       "  'than',\n",
       "  '90',\n",
       "  '%',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'has',\n",
       "  'also',\n",
       "  'been',\n",
       "  'on',\n",
       "  'levofloxacin',\n",
       "  'and',\n",
       "  'nebulizers',\n",
       "  ',',\n",
       "  'and',\n",
       "  'was',\n",
       "  'not',\n",
       "  'getting',\n",
       "  'better',\n",
       "  ',',\n",
       "  'and',\n",
       "  'presented',\n",
       "  'to',\n",
       "  'the',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Hospital1',\n",
       "  '18',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'Emergency', 'Room', '.', '[SEP]'],\n",
       " ['[CLS]', 'In', 'the', '[', '*', '*', 'Hospital3', '*', '*', ']', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Emergency',\n",
       "  'Room',\n",
       "  ',',\n",
       "  'her',\n",
       "  'oxygen',\n",
       "  'saturation',\n",
       "  'was',\n",
       "  '100',\n",
       "  '%',\n",
       "  'on',\n",
       "  'CPAP',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'was',\n",
       "  'not',\n",
       "  'able',\n",
       "  'to',\n",
       "  'be',\n",
       "  'weaned',\n",
       "  'off',\n",
       "  'of',\n",
       "  'this',\n",
       "  'despite',\n",
       "  'nebulizer',\n",
       "  'treatment',\n",
       "  'and',\n",
       "  'Solu',\n",
       "  '-',\n",
       "  'Medrol',\n",
       "  '125',\n",
       "  'mg',\n",
       "  'IV',\n",
       "  'x2',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Review',\n",
       "  'of',\n",
       "  'systems',\n",
       "  'is',\n",
       "  'negative',\n",
       "  'for',\n",
       "  'the',\n",
       "  'following',\n",
       "  ':',\n",
       "  'Fevers',\n",
       "  ',',\n",
       "  'chills',\n",
       "  ',',\n",
       "  'nausea',\n",
       "  ',',\n",
       "  'vomiting',\n",
       "  ',',\n",
       "  'night',\n",
       "  'sweats',\n",
       "  ',',\n",
       "  'change',\n",
       "  'in',\n",
       "  'weight',\n",
       "  ',',\n",
       "  'gastrointestinal',\n",
       "  'complaints',\n",
       "  ',',\n",
       "  'neurologic',\n",
       "  'changes',\n",
       "  ',',\n",
       "  'rashes',\n",
       "  ',',\n",
       "  'palpitations',\n",
       "  ',',\n",
       "  'orthopnea',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Is',\n",
       "  'positive',\n",
       "  'for',\n",
       "  'the',\n",
       "  'following',\n",
       "  ':',\n",
       "  'Chest',\n",
       "  'pressure',\n",
       "  'occasionally',\n",
       "  'with',\n",
       "  'shortness',\n",
       "  'of',\n",
       "  'breath',\n",
       "  'with',\n",
       "  'exertion',\n",
       "  ',',\n",
       "  'some',\n",
       "  'shortness',\n",
       "  'of',\n",
       "  'breath',\n",
       "  'that',\n",
       "  'is',\n",
       "  'positionally',\n",
       "  'related',\n",
       "  ',',\n",
       "  'but',\n",
       "  'is',\n",
       "  'improved',\n",
       "  'with',\n",
       "  'nebulizer',\n",
       "  'treatment',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'PAST', 'MEDICAL', 'HISTORY', ':', '1', '.', 'COPD', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Last',\n",
       "  'pulmonary',\n",
       "  'function',\n",
       "  'tests',\n",
       "  'in',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2117',\n",
       "  '-',\n",
       "  '11',\n",
       "  '-',\n",
       "  '3',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'demonstrated',\n",
       "  'a',\n",
       "  'FVC',\n",
       "  'of',\n",
       "  '52',\n",
       "  '%',\n",
       "  'of',\n",
       "  'predicted',\n",
       "  ',',\n",
       "  'a',\n",
       "  'FEV1',\n",
       "  'of',\n",
       "  '54',\n",
       "  '%',\n",
       "  'of',\n",
       "  'predicted',\n",
       "  ',',\n",
       "  'a',\n",
       "  'MMF',\n",
       "  'of',\n",
       "  '23',\n",
       "  '%',\n",
       "  'of',\n",
       "  'predicted',\n",
       "  ',',\n",
       "  'and',\n",
       "  'a',\n",
       "  'FEV1',\n",
       "  ':',\n",
       "  'FVC',\n",
       "  'ratio',\n",
       "  'of',\n",
       "  '67',\n",
       "  '%',\n",
       "  'of',\n",
       "  'predicted',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'FVC',\n",
       "  ',',\n",
       "  'however',\n",
       "  ',',\n",
       "  'does',\n",
       "  'significantly',\n",
       "  'improve',\n",
       "  'with',\n",
       "  'bronchodilator',\n",
       "  'treatment',\n",
       "  'consistent',\n",
       "  'with',\n",
       "  'her',\n",
       "  'known',\n",
       "  'reversible',\n",
       "  'air',\n",
       "  'flow',\n",
       "  'obstruction',\n",
       "  'in',\n",
       "  'addition',\n",
       "  'to',\n",
       "  'an',\n",
       "  'underlying',\n",
       "  'restrictive',\n",
       "  'ventilatory',\n",
       "  'defect',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'has',\n",
       "  'never',\n",
       "  'been',\n",
       "  'on',\n",
       "  'home',\n",
       "  'oxygen',\n",
       "  'prior',\n",
       "  'to',\n",
       "  'this',\n",
       "  'recent',\n",
       "  'episode',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'has',\n",
       "  'never',\n",
       "  'been',\n",
       "  'on',\n",
       "  'steroid',\n",
       "  'taper',\n",
       "  'or',\n",
       "  'been',\n",
       "  'intubated',\n",
       "  'in',\n",
       "  'the',\n",
       "  'past',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '2', '.', 'Lacunar', 'CVA', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'MRI',\n",
       "  'of',\n",
       "  'the',\n",
       "  'head',\n",
       "  'in',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2114',\n",
       "  '-',\n",
       "  '11',\n",
       "  '-',\n",
       "  '4',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'demonstrates',\n",
       "  '\"',\n",
       "  'mild',\n",
       "  'degree',\n",
       "  'of',\n",
       "  'multiple',\n",
       "  'small',\n",
       "  'foci',\n",
       "  'of',\n",
       "  'high',\n",
       "  'T2',\n",
       "  'signal',\n",
       "  'within',\n",
       "  'the',\n",
       "  'white',\n",
       "  'matter',\n",
       "  'of',\n",
       "  'both',\n",
       "  'cerebral',\n",
       "  'hemispheres',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'the',\n",
       "  'pons',\n",
       "  ',',\n",
       "  'in',\n",
       "  'the',\n",
       "  'latter',\n",
       "  'region',\n",
       "  'predominantly',\n",
       "  'to',\n",
       "  'the',\n",
       "  'right',\n",
       "  'of',\n",
       "  'midline',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'abnormalities',\n",
       "  ',',\n",
       "  'while',\n",
       "  'nonspecific',\n",
       "  'in',\n",
       "  'etiology',\n",
       "  ',',\n",
       "  'are',\n",
       "  'most',\n",
       "  'likely',\n",
       "  'secondary',\n",
       "  'to',\n",
       "  'chronic',\n",
       "  'microvascular',\n",
       "  'infarction',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'There',\n",
       "  'is',\n",
       "  'no',\n",
       "  'mass',\n",
       "  ',',\n",
       "  'lesion',\n",
       "  ',',\n",
       "  'shift',\n",
       "  'of',\n",
       "  'the',\n",
       "  'normal',\n",
       "  'midline',\n",
       "  'strictures',\n",
       "  'or',\n",
       "  'hydrocephalus',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'major',\n",
       "  'vascular',\n",
       "  'flow',\n",
       "  'patterns',\n",
       "  'are',\n",
       "  'preserved',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'There',\n",
       "  'is',\n",
       "  'moderate',\n",
       "  'right',\n",
       "  'maxillary',\n",
       "  ',',\n",
       "  'moderate',\n",
       "  'bilateral',\n",
       "  'ethmoid',\n",
       "  ',',\n",
       "  'mild',\n",
       "  'left',\n",
       "  'maxillary',\n",
       "  ',',\n",
       "  'minimal',\n",
       "  'right',\n",
       "  'sphenoid',\n",
       "  ',',\n",
       "  'and',\n",
       "  'frontal',\n",
       "  'sinus',\n",
       "  'mucosal',\n",
       "  'thickening',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'These',\n",
       "  'abnormalities',\n",
       "  'could',\n",
       "  'represent',\n",
       "  'an',\n",
       "  'allergic',\n",
       "  'or',\n",
       "  'some',\n",
       "  'other',\n",
       "  'type',\n",
       "  'of',\n",
       "  'inflammatory',\n",
       "  'process',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Additionally',\n",
       "  'noted',\n",
       "  'is',\n",
       "  'a',\n",
       "  'moderately',\n",
       "  'enlarged',\n",
       "  'subtotally',\n",
       "  'empty',\n",
       "  'sella',\n",
       "  'turcica',\n",
       "  '\"',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '3', '.', 'Angina', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Most',\n",
       "  'recent',\n",
       "  'stress',\n",
       "  'test',\n",
       "  'was',\n",
       "  'in',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '1',\n",
       "  '-',\n",
       "  '3',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'going',\n",
       "  'for',\n",
       "  'four',\n",
       "  'minutes',\n",
       "  'with',\n",
       "  'a',\n",
       "  'rate',\n",
       "  'pressure',\n",
       "  'product',\n",
       "  'of',\n",
       "  '10',\n",
       "  ',',\n",
       "  '000',\n",
       "  ',',\n",
       "  '64',\n",
       "  '%',\n",
       "  'of',\n",
       "  'maximum',\n",
       "  'predicted',\n",
       "  'heart',\n",
       "  'rate',\n",
       "  'without',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'ischemic',\n",
       "  'EKG',\n",
       "  'changes',\n",
       "  'or',\n",
       "  'symptoms',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'imaging',\n",
       "  'portion',\n",
       "  'of',\n",
       "  'the',\n",
       "  'study',\n",
       "  'demonstrated',\n",
       "  'no',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'myocardial',\n",
       "  'ischemia',\n",
       "  'and',\n",
       "  'a',\n",
       "  'calculated',\n",
       "  'ejection',\n",
       "  'fraction',\n",
       "  'of',\n",
       "  '84',\n",
       "  '%',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'denies',\n",
       "  'angina',\n",
       "  'at',\n",
       "  'rest',\n",
       "  'and',\n",
       "  'gets',\n",
       "  'angina',\n",
       "  'with',\n",
       "  'walking',\n",
       "  'a',\n",
       "  'few',\n",
       "  'blocks',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Are',\n",
       "  'alleviated',\n",
       "  'by',\n",
       "  'sublingual',\n",
       "  'nitroglycerin',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '4', '.', 'Hypothyroidism', 'on', 'Synthroid', '.', '[SEP]'],\n",
       " ['[CLS]', '5', '.', 'Depression', 'on', 'Lexapro', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '6',\n",
       "  '.',\n",
       "  'Motor',\n",
       "  'vehicle',\n",
       "  'accident',\n",
       "  'with',\n",
       "  'head',\n",
       "  'injury',\n",
       "  'approximately',\n",
       "  '10',\n",
       "  'years',\n",
       "  'ago',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'MEDICATIONS',\n",
       "  'ON',\n",
       "  'ADMISSION',\n",
       "  ':',\n",
       "  '1',\n",
       "  '.',\n",
       "  'Hydrochlorothiazide',\n",
       "  '25',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '2',\n",
       "  '.',\n",
       "  'Prednisone',\n",
       "  '60',\n",
       "  'mg',\n",
       "  ',',\n",
       "  '50',\n",
       "  'mg',\n",
       "  ',',\n",
       "  '40',\n",
       "  'mg',\n",
       "  ',',\n",
       "  '20',\n",
       "  'mg',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '3',\n",
       "  '.',\n",
       "  'Levofloxacin',\n",
       "  '500',\n",
       "  'mg',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '4',\n",
       "  '.',\n",
       "  'Imdur',\n",
       "  '60',\n",
       "  'mg',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '5',\n",
       "  '.',\n",
       "  'Synthroid',\n",
       "  '75',\n",
       "  'mcg',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '6',\n",
       "  '.',\n",
       "  'Pulmicort',\n",
       "  'nebulizer',\n",
       "  'b',\n",
       "  '.',\n",
       "  'i',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '7',\n",
       "  '.',\n",
       "  'Albuterol',\n",
       "  'nebulizer',\n",
       "  'q',\n",
       "  '.',\n",
       "  '4',\n",
       "  '.',\n",
       "  'prn',\n",
       "  '.',\n",
       "  '8',\n",
       "  '.',\n",
       "  'Lexapro',\n",
       "  '10',\n",
       "  'mg',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '9',\n",
       "  '.',\n",
       "  'Protonix',\n",
       "  '40',\n",
       "  'mg',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '10',\n",
       "  '.',\n",
       "  'Aspirin',\n",
       "  '81',\n",
       "  'mg',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  'ALLERGIES',\n",
       "  ':',\n",
       "  'Norvasc',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'lightheaded',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'FAMILY', 'HISTORY', ':', 'Noncontributory', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'SOCIAL',\n",
       "  'HISTORY',\n",
       "  ':',\n",
       "  'Lives',\n",
       "  'with',\n",
       "  'her',\n",
       "  'husband',\n",
       "  ',',\n",
       "  'Dr',\n",
       "  '.',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Known',\n",
       "  'lastname',\n",
       "  '1809',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'an',\n",
       "  'eminent',\n",
       "  'Pediatric',\n",
       "  'Neurologist',\n",
       "  'at',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Hospital3',\n",
       "  '1810',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'is',\n",
       "  'a',\n",
       "  'prior',\n",
       "  'smoker',\n",
       "  ',',\n",
       "  'but',\n",
       "  'has',\n",
       "  'not',\n",
       "  'smoked',\n",
       "  'in',\n",
       "  'over',\n",
       "  '10',\n",
       "  'years',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'has',\n",
       "  'no',\n",
       "  'known',\n",
       "  'alcohol',\n",
       "  'use',\n",
       "  'and',\n",
       "  'she',\n",
       "  'is',\n",
       "  'a',\n",
       "  'full',\n",
       "  'code',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'PHYSICAL',\n",
       "  'EXAM',\n",
       "  'AT',\n",
       "  'TIME',\n",
       "  'OF',\n",
       "  'ADMISSION',\n",
       "  ':',\n",
       "  'Blood',\n",
       "  'pressure',\n",
       "  '142',\n",
       "  '/',\n",
       "  '76',\n",
       "  ',',\n",
       "  'heart',\n",
       "  'rate',\n",
       "  '100',\n",
       "  'and',\n",
       "  'regular',\n",
       "  ',',\n",
       "  'respirations',\n",
       "  'at',\n",
       "  '17',\n",
       "  '-',\n",
       "  '21',\n",
       "  ',',\n",
       "  'and',\n",
       "  '97',\n",
       "  '%',\n",
       "  'axillary',\n",
       "  'temperature',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'was',\n",
       "  'saturating',\n",
       "  'at',\n",
       "  '100',\n",
       "  '%',\n",
       "  'on',\n",
       "  'CPAP',\n",
       "  'with',\n",
       "  'dry',\n",
       "  'mucous',\n",
       "  'membranes',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'An',\n",
       "  'elderly',\n",
       "  'female',\n",
       "  'in',\n",
       "  'no',\n",
       "  'apparent',\n",
       "  'distress',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Pupils',\n",
       "  'are',\n",
       "  'equal',\n",
       "  ',',\n",
       "  'round',\n",
       "  ',',\n",
       "  'and',\n",
       "  'reactive',\n",
       "  'to',\n",
       "  'light',\n",
       "  'and',\n",
       "  'accommodation',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'Extraocular', 'movements', 'are', 'intact', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Oropharynx',\n",
       "  'difficult',\n",
       "  'to',\n",
       "  'assess',\n",
       "  'due',\n",
       "  'to',\n",
       "  'CPAP',\n",
       "  'machine',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'No',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'jugular',\n",
       "  'venous',\n",
       "  'pressure',\n",
       "  ',',\n",
       "  'however',\n",
       "  ',',\n",
       "  'the',\n",
       "  'strap',\n",
       "  'from',\n",
       "  'the',\n",
       "  'CPAP',\n",
       "  'machine',\n",
       "  'obscures',\n",
       "  'the',\n",
       "  'neck',\n",
       "  'exam',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Cranial',\n",
       "  'nerves',\n",
       "  'II',\n",
       "  'through',\n",
       "  'XII',\n",
       "  'are',\n",
       "  'grossly',\n",
       "  'intact',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'Neck', 'is', 'supple', 'without', 'lymphadenopathy', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Heart',\n",
       "  'exam',\n",
       "  ':',\n",
       "  'Tachycardic',\n",
       "  ',',\n",
       "  'regular',\n",
       "  ',',\n",
       "  'obscured',\n",
       "  'by',\n",
       "  'loud',\n",
       "  'bilateral',\n",
       "  'wheezing',\n",
       "  'with',\n",
       "  'increase',\n",
       "  'in',\n",
       "  'the',\n",
       "  'expiratory',\n",
       "  'phase',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'profuse',\n",
       "  'scattered',\n",
       "  'rhonchi',\n",
       "  'throughout',\n",
       "  'the',\n",
       "  'lung',\n",
       "  'fields',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Positive',\n",
       "  'bowel',\n",
       "  'sounds',\n",
       "  ',',\n",
       "  'soft',\n",
       "  ',',\n",
       "  'nontender',\n",
       "  ',',\n",
       "  'nondistended',\n",
       "  ',',\n",
       "  'obese',\n",
       "  ',',\n",
       "  'no',\n",
       "  'masses',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Mild',\n",
       "  'edema',\n",
       "  'of',\n",
       "  'the',\n",
       "  'lower',\n",
       "  'extremities',\n",
       "  'without',\n",
       "  'clubbing',\n",
       "  'or',\n",
       "  'cyanosis',\n",
       "  ',',\n",
       "  'no',\n",
       "  'rashes',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'There', 'is', 'a', 'right', 'hand', 'hematoma', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Strength',\n",
       "  'is',\n",
       "  'assessed',\n",
       "  'as',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '5',\n",
       "  '-',\n",
       "  '9',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'in',\n",
       "  'the',\n",
       "  'lower',\n",
       "  'extremities',\n",
       "  ',',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '5',\n",
       "  '-',\n",
       "  '9',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'in',\n",
       "  'the',\n",
       "  'upper',\n",
       "  'extremities',\n",
       "  'with',\n",
       "  'a',\n",
       "  'normal',\n",
       "  'mental',\n",
       "  'status',\n",
       "  'and',\n",
       "  'cognition',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'LABORATORY', 'STUDIES', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'White',\n",
       "  'count',\n",
       "  '19',\n",
       "  ',',\n",
       "  'hematocrit',\n",
       "  '41',\n",
       "  ',',\n",
       "  'platelets',\n",
       "  '300',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Chem',\n",
       "  '-',\n",
       "  '7',\n",
       "  ':',\n",
       "  '127',\n",
       "  ',',\n",
       "  '3',\n",
       "  '.',\n",
       "  '6',\n",
       "  ',',\n",
       "  '88',\n",
       "  ',',\n",
       "  '29',\n",
       "  ',',\n",
       "  '17',\n",
       "  ',',\n",
       "  '0',\n",
       "  '.',\n",
       "  '6',\n",
       "  ',',\n",
       "  '143',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'Troponin', 'was', 'negative', '.', '[SEP]'],\n",
       " ['[CLS]', 'CKs', 'were', 'negative', 'times', 'three', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Initial',\n",
       "  'blood',\n",
       "  'gas',\n",
       "  'showed',\n",
       "  'a',\n",
       "  'pH',\n",
       "  'of',\n",
       "  '7',\n",
       "  '.',\n",
       "  '4',\n",
       "  ',',\n",
       "  'pO2',\n",
       "  'of',\n",
       "  '66',\n",
       "  ',',\n",
       "  'pCO2',\n",
       "  'of',\n",
       "  '54',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Chest',\n",
       "  'x',\n",
       "  '-',\n",
       "  'ray',\n",
       "  'demonstrates',\n",
       "  'a',\n",
       "  'moderate',\n",
       "  'sized',\n",
       "  'hiatal',\n",
       "  'hernia',\n",
       "  ',',\n",
       "  'segmental',\n",
       "  'atelectasis',\n",
       "  ',',\n",
       "  'left',\n",
       "  'lower',\n",
       "  'lobe',\n",
       "  'infiltrate',\n",
       "  'versus',\n",
       "  'segmental',\n",
       "  'atelectasis',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'EKG',\n",
       "  'shows',\n",
       "  'normal',\n",
       "  'sinus',\n",
       "  'rhythm',\n",
       "  'at',\n",
       "  '113',\n",
       "  'beats',\n",
       "  'per',\n",
       "  'minute',\n",
       "  ',',\n",
       "  'normal',\n",
       "  'axis',\n",
       "  ',',\n",
       "  'no',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'ST',\n",
       "  '-',\n",
       "  'T',\n",
       "  'wave',\n",
       "  'changes',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'BRIEF',\n",
       "  'SUMMARY',\n",
       "  'OF',\n",
       "  'HOSPITAL',\n",
       "  'COURSE',\n",
       "  ':',\n",
       "  '1',\n",
       "  '.',\n",
       "  'COPD',\n",
       "  '/',\n",
       "  'dyspnea',\n",
       "  '/',\n",
       "  'pneumonia',\n",
       "  ':',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'initially',\n",
       "  'placed',\n",
       "  'on',\n",
       "  'an',\n",
       "  'aggressive',\n",
       "  'steroid',\n",
       "  'taper',\n",
       "  'and',\n",
       "  'admitted',\n",
       "  'to',\n",
       "  'the',\n",
       "  'Medical',\n",
       "  'Intensive',\n",
       "  'Care',\n",
       "  'Unit',\n",
       "  'due',\n",
       "  'to',\n",
       "  'her',\n",
       "  'difficulty',\n",
       "  'with',\n",
       "  'oxygenation',\n",
       "  'despite',\n",
       "  'CPAP',\n",
       "  'machine',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'was',\n",
       "  'also',\n",
       "  'given',\n",
       "  'nebulizer',\n",
       "  'treatments',\n",
       "  'q',\n",
       "  '.',\n",
       "  '4h',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'as', 'well', 'as', 'chest', 'PT', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'nebulizers',\n",
       "  'were',\n",
       "  'increased',\n",
       "  'to',\n",
       "  'q',\n",
       "  '.',\n",
       "  '1h',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'she',\n",
       "  'continued',\n",
       "  'to',\n",
       "  'have',\n",
       "  'labored',\n",
       "  'breathing',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Due',\n",
       "  'to',\n",
       "  'persistent',\n",
       "  'respiratory',\n",
       "  'failure',\n",
       "  'and',\n",
       "  'labored',\n",
       "  'breathing',\n",
       "  ',',\n",
       "  'the',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'intubated',\n",
       "  'on',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '7',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'improve',\n",
       "  'oxygenation',\n",
       "  ',',\n",
       "  'ventilation',\n",
       "  ',',\n",
       "  'and',\n",
       "  'ability',\n",
       "  'to',\n",
       "  'suction',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'A',\n",
       "  'bronchoscopy',\n",
       "  'was',\n",
       "  'performed',\n",
       "  'on',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '7',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  ',',\n",
       "  'which',\n",
       "  'demonstrated',\n",
       "  'marked',\n",
       "  'narrowing',\n",
       "  'of',\n",
       "  'the',\n",
       "  'airways',\n",
       "  'with',\n",
       "  'expiration',\n",
       "  'consistent',\n",
       "  'with',\n",
       "  'tracheomalacia',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'On',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '9',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  ',',\n",
       "  'two',\n",
       "  'silicone',\n",
       "  'stents',\n",
       "  'were',\n",
       "  'placed',\n",
       "  ',',\n",
       "  'one',\n",
       "  'in',\n",
       "  'the',\n",
       "  'left',\n",
       "  'main',\n",
       "  'stem',\n",
       "  '(',\n",
       "  '12',\n",
       "  'x',\n",
       "  '25',\n",
       "  'and',\n",
       "  'one',\n",
       "  'in',\n",
       "  'the',\n",
       "  'trachea',\n",
       "  '16',\n",
       "  'x',\n",
       "  '40',\n",
       "  ')',\n",
       "  'by',\n",
       "  'Dr',\n",
       "  '.',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'First',\n",
       "  'Name',\n",
       "  '(',\n",
       "  'STitle',\n",
       "  ')',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Name',\n",
       "  '(',\n",
       "  'STitle',\n",
       "  ')',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'under',\n",
       "  'rigid',\n",
       "  'bronchoscopy',\n",
       "  'with',\n",
       "  'general',\n",
       "  'anesthesia',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'On',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '11',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  ',',\n",
       "  'the',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'extubated',\n",
       "  'to',\n",
       "  'a',\n",
       "  'cool',\n",
       "  'mist',\n",
       "  'shovel',\n",
       "  'mask',\n",
       "  'and',\n",
       "  'her',\n",
       "  'oxygen',\n",
       "  'was',\n",
       "  'titrated',\n",
       "  'down',\n",
       "  'to',\n",
       "  '2',\n",
       "  'liters',\n",
       "  'nasal',\n",
       "  'cannula',\n",
       "  'at',\n",
       "  'which',\n",
       "  'time',\n",
       "  'she',\n",
       "  'was',\n",
       "  'transferred',\n",
       "  'to',\n",
       "  'the',\n",
       "  'medical',\n",
       "  'floor',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'On',\n",
       "  'the',\n",
       "  'medical',\n",
       "  'floor',\n",
       "  ',',\n",
       "  'the',\n",
       "  'steroids',\n",
       "  'were',\n",
       "  'weaned',\n",
       "  'to',\n",
       "  'off',\n",
       "  'on',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '14',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  ',',\n",
       "  'and',\n",
       "  'the',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'saturating',\n",
       "  'at',\n",
       "  '97',\n",
       "  '%',\n",
       "  'on',\n",
       "  '2',\n",
       "  'liters',\n",
       "  ',',\n",
       "  '92',\n",
       "  '%',\n",
       "  'on',\n",
       "  'room',\n",
       "  'air',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'On',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '14',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  ',',\n",
       "  'the',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'seen',\n",
       "  'again',\n",
       "  'by',\n",
       "  'the',\n",
       "  'Interventional',\n",
       "  'Pulmonology',\n",
       "  'service',\n",
       "  ',',\n",
       "  'who',\n",
       "  'agreed',\n",
       "  'that',\n",
       "  'she',\n",
       "  'looked',\n",
       "  'much',\n",
       "  'improved',\n",
       "  'and',\n",
       "  'recommended',\n",
       "  'that',\n",
       "  'she',\n",
       "  'go',\n",
       "  'to',\n",
       "  'pulmonary',\n",
       "  'rehabilitation',\n",
       "  'with',\n",
       "  'followup',\n",
       "  'within',\n",
       "  'six',\n",
       "  'weeks',\n",
       "  '\\\\',\n",
       "  'cf4',\n",
       "  '\\\\',\n",
       "  \"'\",\n",
       "  '\\\\',\n",
       "  'cf2',\n",
       "  'time',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '2', '.', 'Cardiovascular', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'ruled',\n",
       "  'out',\n",
       "  'for',\n",
       "  'a',\n",
       "  'MI',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'did',\n",
       "  'have',\n",
       "  'another',\n",
       "  'episode',\n",
       "  'on',\n",
       "  'the',\n",
       "  'medical',\n",
       "  'floor',\n",
       "  'of',\n",
       "  'chest',\n",
       "  'pain',\n",
       "  ',',\n",
       "  'which',\n",
       "  'showed',\n",
       "  'no',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'EKG',\n",
       "  'changes',\n",
       "  'and',\n",
       "  'negative',\n",
       "  'troponin',\n",
       "  ',',\n",
       "  'negative',\n",
       "  'CKs',\n",
       "  'x3',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'was',\n",
       "  'continued',\n",
       "  'on',\n",
       "  'aspirin',\n",
       "  ',',\n",
       "  'Imdur',\n",
       "  ',',\n",
       "  'and',\n",
       "  'diltiazem',\n",
       "  'for',\n",
       "  'rate',\n",
       "  'control',\n",
       "  'per',\n",
       "  'her',\n",
       "  'outpatient',\n",
       "  'regimen',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '3', '.', 'Hypertension', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'was',\n",
       "  'maintained',\n",
       "  'on',\n",
       "  'diltiazem',\n",
       "  'and',\n",
       "  'hydrochlorothiazide',\n",
       "  'with',\n",
       "  'adequate',\n",
       "  'blood',\n",
       "  'pressure',\n",
       "  'control',\n",
       "  'and',\n",
       "  'normalization',\n",
       "  'of',\n",
       "  'electrolytes',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '4', '.', 'Hematuria', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'had',\n",
       "  'intermittent',\n",
       "  'hematuria',\n",
       "  'likely',\n",
       "  'secondary',\n",
       "  'to',\n",
       "  'Foley',\n",
       "  'placement',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'Foley',\n",
       "  'catheter',\n",
       "  'was',\n",
       "  'discontinued',\n",
       "  'on',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '14',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'had',\n",
       "  'serial',\n",
       "  'urinalyses',\n",
       "  ',',\n",
       "  'which',\n",
       "  'were',\n",
       "  'all',\n",
       "  'negative',\n",
       "  'for',\n",
       "  'signs',\n",
       "  'of',\n",
       "  'infection',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '5',\n",
       "  '.',\n",
       "  'Hyperglycemia',\n",
       "  ':',\n",
       "  'Patient',\n",
       "  'was',\n",
       "  'placed',\n",
       "  'on',\n",
       "  'insulin',\n",
       "  '-',\n",
       "  'sliding',\n",
       "  'scale',\n",
       "  'due',\n",
       "  'to',\n",
       "  'hyperglycemia',\n",
       "  ',',\n",
       "  'which',\n",
       "  'was',\n",
       "  'steroid',\n",
       "  'induced',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'This',\n",
       "  'worked',\n",
       "  'quite',\n",
       "  'well',\n",
       "  'and',\n",
       "  'her',\n",
       "  'glucose',\n",
       "  'came',\n",
       "  'back',\n",
       "  'to',\n",
       "  'normal',\n",
       "  'levels',\n",
       "  'once',\n",
       "  'the',\n",
       "  'steroids',\n",
       "  'were',\n",
       "  'tapered',\n",
       "  'to',\n",
       "  'off',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '6',\n",
       "  '.',\n",
       "  'Leukocytosis',\n",
       "  ':',\n",
       "  'Patient',\n",
       "  'did',\n",
       "  'have',\n",
       "  'a',\n",
       "  'profound',\n",
       "  'leukocytosis',\n",
       "  'of',\n",
       "  '20',\n",
       "  'to',\n",
       "  '22',\n",
       "  'during',\n",
       "  'much',\n",
       "  'of',\n",
       "  'her',\n",
       "  'hospital',\n",
       "  'course',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'As',\n",
       "  'the',\n",
       "  'steroids',\n",
       "  'were',\n",
       "  'tapered',\n",
       "  'to',\n",
       "  'off',\n",
       "  ',',\n",
       "  'her',\n",
       "  'white',\n",
       "  'blood',\n",
       "  'cell',\n",
       "  'count',\n",
       "  'on',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '14',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'was',\n",
       "  '15',\n",
       "  ',',\n",
       "  '000',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'It',\n",
       "  'was',\n",
       "  'felt',\n",
       "  'that',\n",
       "  'the',\n",
       "  'leukocytosis',\n",
       "  'was',\n",
       "  'secondary',\n",
       "  'to',\n",
       "  'both',\n",
       "  'steroids',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'question',\n",
       "  'of',\n",
       "  'a',\n",
       "  'left',\n",
       "  'lower',\n",
       "  'lobe',\n",
       "  'pneumonia',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '7',\n",
       "  '.',\n",
       "  'For',\n",
       "  'the',\n",
       "  'left',\n",
       "  'lower',\n",
       "  'lobe',\n",
       "  'pneumonia',\n",
       "  ',',\n",
       "  'the',\n",
       "  'patient',\n",
       "  'had',\n",
       "  'initially',\n",
       "  'received',\n",
       "  'a',\n",
       "  'course',\n",
       "  'of',\n",
       "  'levofloxacin',\n",
       "  '500',\n",
       "  'p',\n",
       "  '.',\n",
       "  'o',\n",
       "  '.',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  'from',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '4',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'to',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '10',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'This',\n",
       "  'was',\n",
       "  'restarted',\n",
       "  'on',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '12',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'for',\n",
       "  'an',\n",
       "  'additional',\n",
       "  'seven',\n",
       "  'day',\n",
       "  'course',\n",
       "  'given',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'she',\n",
       "  'still',\n",
       "  'had',\n",
       "  'the',\n",
       "  'leukocytosis',\n",
       "  'and',\n",
       "  'still',\n",
       "  'had',\n",
       "  'marked',\n",
       "  'rales',\n",
       "  'at',\n",
       "  'the',\n",
       "  'left',\n",
       "  'lower',\n",
       "  'lobe',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '8', '.', 'Hypothyroidism', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'continued',\n",
       "  'on',\n",
       "  'outpatient',\n",
       "  'medical',\n",
       "  'regimen',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '9', '.', 'Depression', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'continued',\n",
       "  'on',\n",
       "  'Lexapro',\n",
       "  'per',\n",
       "  'outpatient',\n",
       "  'regimen',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'It',\n",
       "  'is',\n",
       "  'recommended',\n",
       "  'that',\n",
       "  'she',\n",
       "  'follow',\n",
       "  'up',\n",
       "  'with',\n",
       "  'a',\n",
       "  'therapist',\n",
       "  'as',\n",
       "  'an',\n",
       "  'outpatient',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'she',\n",
       "  'did',\n",
       "  'have',\n",
       "  'a',\n",
       "  'blunted',\n",
       "  'affect',\n",
       "  'throughout',\n",
       "  'much',\n",
       "  'of',\n",
       "  'the',\n",
       "  'hospital',\n",
       "  'course',\n",
       "  ',',\n",
       "  'and',\n",
       "  'did',\n",
       "  'appear',\n",
       "  'clinically',\n",
       "  'to',\n",
       "  'be',\n",
       "  'depressed',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '10', '.', 'Prophylaxis', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'was',\n",
       "  'maintained',\n",
       "  'on',\n",
       "  'proton',\n",
       "  '-',\n",
       "  'pump',\n",
       "  'inhibitor',\n",
       "  'with',\n",
       "  'subQ',\n",
       "  'Heparin',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '11', '.', '[SEP]'],\n",
       " ['[CLS]', 'Sore', 'throat', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'did',\n",
       "  'have',\n",
       "  'a',\n",
       "  'sore',\n",
       "  'throat',\n",
       "  'for',\n",
       "  'much',\n",
       "  'of',\n",
       "  'the',\n",
       "  'hospital',\n",
       "  'course',\n",
       "  'post',\n",
       "  'extubation',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'This',\n",
       "  'was',\n",
       "  'treated',\n",
       "  'with',\n",
       "  'Cepacol',\n",
       "  'lozenges',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'KBL',\n",
       "  'liquid',\n",
       "  '(',\n",
       "  'a',\n",
       "  'solution',\n",
       "  'containing',\n",
       "  'Kaopectate',\n",
       "  ',',\n",
       "  'Bismuth',\n",
       "  ',',\n",
       "  'and',\n",
       "  'lidocaine',\n",
       "  ')',\n",
       "  'at',\n",
       "  'bedtime',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '12', '.', 'Communication', '/', 'code', 'status', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'full',\n",
       "  'code',\n",
       "  'throughout',\n",
       "  'her',\n",
       "  'hospital',\n",
       "  'course',\n",
       "  ',',\n",
       "  'and',\n",
       "  'communication',\n",
       "  'was',\n",
       "  'maintained',\n",
       "  'with',\n",
       "  'the',\n",
       "  'patient',\n",
       "  'and',\n",
       "  'her',\n",
       "  'husband',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '13', '.', 'Muscle', 'weakness', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'did',\n",
       "  'have',\n",
       "  'profound',\n",
       "  'muscle',\n",
       "  'weakness',\n",
       "  'and',\n",
       "  'was',\n",
       "  'evaluated',\n",
       "  'by',\n",
       "  'Physical',\n",
       "  'Therapy',\n",
       "  ',',\n",
       "  'and',\n",
       "  'was',\n",
       "  'found',\n",
       "  'to',\n",
       "  'have',\n",
       "  'impaired',\n",
       "  'functional',\n",
       "  'mobility',\n",
       "  ',',\n",
       "  'impaired',\n",
       "  'musculoskeletal',\n",
       "  'performance',\n",
       "  ',',\n",
       "  'impaired',\n",
       "  'gas',\n",
       "  'exchange',\n",
       "  ',',\n",
       "  'impaired',\n",
       "  'endurance',\n",
       "  ',',\n",
       "  'impaired',\n",
       "  'ventilation',\n",
       "  ',',\n",
       "  'and',\n",
       "  'needed',\n",
       "  'help',\n",
       "  'with',\n",
       "  'supine',\n",
       "  'to',\n",
       "  'sit',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'However',\n",
       "  ',',\n",
       "  'she',\n",
       "  'was',\n",
       "  'able',\n",
       "  'to',\n",
       "  'tolerate',\n",
       "  'sitting',\n",
       "  'in',\n",
       "  'a',\n",
       "  'chair',\n",
       "  'for',\n",
       "  'approximately',\n",
       "  'one',\n",
       "  'hour',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'On',\n",
       "  'motor',\n",
       "  'exam',\n",
       "  ',',\n",
       "  'her',\n",
       "  'flexors',\n",
       "  'and',\n",
       "  'extensors',\n",
       "  'of',\n",
       "  'the',\n",
       "  'lower',\n",
       "  'extremities',\n",
       "  'were',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '4',\n",
       "  '-',\n",
       "  '8',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'at',\n",
       "  'the',\n",
       "  'knee',\n",
       "  ',',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '4',\n",
       "  '-',\n",
       "  '8',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'at',\n",
       "  'the',\n",
       "  'ankle',\n",
       "  ',',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '4',\n",
       "  '-',\n",
       "  '8',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'at',\n",
       "  'the',\n",
       "  'elbows',\n",
       "  ',',\n",
       "  'and',\n",
       "  '[',\n",
       "  '*',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'It',\n",
       "  'was',\n",
       "  'felt',\n",
       "  'that',\n",
       "  'this',\n",
       "  'weakness',\n",
       "  'was',\n",
       "  'most',\n",
       "  'likely',\n",
       "  'due',\n",
       "  'to',\n",
       "  'a',\n",
       "  'combination',\n",
       "  'of',\n",
       "  'steroid',\n",
       "  'myopathy',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'muscle',\n",
       "  'atrophy',\n",
       "  'secondary',\n",
       "  'to',\n",
       "  'deconditioning',\n",
       "  'after',\n",
       "  'a',\n",
       "  'prolonged',\n",
       "  'hospital',\n",
       "  'course',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '14', '.', 'Speech', '/', 'swallow', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'had',\n",
       "  'a',\n",
       "  'Speech',\n",
       "  'and',\n",
       "  'Swallow',\n",
       "  'evaluation',\n",
       "  'showing',\n",
       "  'no',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'dysphagia',\n",
       "  ',',\n",
       "  'no',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'vocal',\n",
       "  'cord',\n",
       "  'damage',\n",
       "  'status',\n",
       "  'post',\n",
       "  'tracheal',\n",
       "  'stent',\n",
       "  'placement',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'DISCHARGE', 'CONDITION', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'able',\n",
       "  'to',\n",
       "  'oxygenate',\n",
       "  'on',\n",
       "  'room',\n",
       "  'air',\n",
       "  'at',\n",
       "  '93',\n",
       "  '%',\n",
       "  'at',\n",
       "  'the',\n",
       "  'time',\n",
       "  'of',\n",
       "  'discharge',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'was',\n",
       "  'profoundly',\n",
       "  'weak',\n",
       "  ',',\n",
       "  'but',\n",
       "  'was',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'tachycardic',\n",
       "  'and',\n",
       "  'had',\n",
       "  'a',\n",
       "  'normal',\n",
       "  'blood',\n",
       "  'pressure',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Her',\n",
       "  'respirations',\n",
       "  'were',\n",
       "  'much',\n",
       "  'improved',\n",
       "  'albeit',\n",
       "  'with',\n",
       "  'transmitted',\n",
       "  'upper',\n",
       "  'airway',\n",
       "  'sounds',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'DISCHARGE', 'STATUS', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'will',\n",
       "  'be',\n",
       "  'discharged',\n",
       "  'to',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Hospital1',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'for',\n",
       "  'both',\n",
       "  'pulmonary',\n",
       "  'and',\n",
       "  'physical',\n",
       "  'rehabilitation',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'DISCHARGE',\n",
       "  'MEDICATIONS',\n",
       "  ':',\n",
       "  '1',\n",
       "  '.',\n",
       "  'Levothyroxine',\n",
       "  '75',\n",
       "  'mcg',\n",
       "  'p',\n",
       "  '.',\n",
       "  'o',\n",
       "  '.',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '2',\n",
       "  '.',\n",
       "  'Citalopram',\n",
       "  '10',\n",
       "  'mg',\n",
       "  'p',\n",
       "  '.',\n",
       "  'o',\n",
       "  '.',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '3',\n",
       "  '.',\n",
       "  'Aspirin',\n",
       "  '81',\n",
       "  'mg',\n",
       "  'p',\n",
       "  '.',\n",
       "  'o',\n",
       "  '.',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '5',\n",
       "  '.',\n",
       "  'Salmeterol',\n",
       "  'Diskus',\n",
       "  'one',\n",
       "  'inhalation',\n",
       "  'b',\n",
       "  '.',\n",
       "  'i',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '6',\n",
       "  '.',\n",
       "  'Acetaminophen',\n",
       "  '325',\n",
       "  '-',\n",
       "  '650',\n",
       "  'mg',\n",
       "  'p',\n",
       "  '.',\n",
       "  'o',\n",
       "  '.',\n",
       "  'q',\n",
       "  '.',\n",
       "  '4',\n",
       "  '-',\n",
       "  '6h',\n",
       "  '.',\n",
       "  'prn',\n",
       "  '.',\n",
       "  '7',\n",
       "  '.',\n",
       "  'Ipratropium',\n",
       "  'bromide',\n",
       "  'MDI',\n",
       "  'two',\n",
       "  'puffs',\n",
       "  'inhaled',\n",
       "  'q',\n",
       "  '.',\n",
       "  '2h',\n",
       "  '.',\n",
       "  'prn',\n",
       "  '.',\n",
       "  '8',\n",
       "  '.',\n",
       "  'Albuterol',\n",
       "  '1',\n",
       "  '-',\n",
       "  '2',\n",
       "  'puffs',\n",
       "  'inhaled',\n",
       "  'q',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '15',\n",
       "  '.',\n",
       "  'Cepacol',\n",
       "  'lozenges',\n",
       "  'q',\n",
       "  '.',\n",
       "  '2h',\n",
       "  '.',\n",
       "  'prn',\n",
       "  '.',\n",
       "  '16',\n",
       "  '.',\n",
       "  'Levofloxacin',\n",
       "  '500',\n",
       "  'mg',\n",
       "  'p',\n",
       "  '.',\n",
       "  'o',\n",
       "  '.',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  'for',\n",
       "  'a',\n",
       "  'seven',\n",
       "  'day',\n",
       "  'course',\n",
       "  'to',\n",
       "  'be',\n",
       "  'completed',\n",
       "  'on',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '21',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '17',\n",
       "  '.',\n",
       "  'Kaopectate',\n",
       "  '/',\n",
       "  'Benadryl',\n",
       "  '/',\n",
       "  'lidocaine',\n",
       "  '5',\n",
       "  'mL',\n",
       "  'p',\n",
       "  '.',\n",
       "  'o',\n",
       "  '.',\n",
       "  'b',\n",
       "  '.',\n",
       "  'i',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  'prn',\n",
       "  ',',\n",
       "  'not',\n",
       "  'to',\n",
       "  'be',\n",
       "  'given',\n",
       "  'around',\n",
       "  'mealtimes',\n",
       "  'for',\n",
       "  'concern',\n",
       "  'of',\n",
       "  'dysphagia',\n",
       "  'induced',\n",
       "  'by',\n",
       "  'lidocaine',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '18',\n",
       "  '.',\n",
       "  'Lorazepam',\n",
       "  '0',\n",
       "  '.',\n",
       "  '5',\n",
       "  '-',\n",
       "  '2',\n",
       "  'mg',\n",
       "  'IV',\n",
       "  'q',\n",
       "  '.',\n",
       "  '6h',\n",
       "  '.',\n",
       "  'prn',\n",
       "  '.',\n",
       "  'FOLLOW',\n",
       "  '-',\n",
       "  'UP',\n",
       "  'PLANS',\n",
       "  ':',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'is',\n",
       "  'recommended',\n",
       "  'to',\n",
       "  'followup',\n",
       "  'with',\n",
       "  'Dr',\n",
       "  '.',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'First',\n",
       "  'Name4',\n",
       "  '(',\n",
       "  'NamePattern1',\n",
       "  ')',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Last',\n",
       "  'Name',\n",
       "  '(',\n",
       "  'NamePattern1',\n",
       "  ')',\n",
       "  '1407',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  ',',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Telephone',\n",
       "  '/',\n",
       "  'Fax',\n",
       "  '(',\n",
       "  '1',\n",
       "  ')',\n",
       "  '1408',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'within',\n",
       "  'two',\n",
       "  'weeks',\n",
       "  'of',\n",
       "  'leaving',\n",
       "  'of',\n",
       "  'the',\n",
       "  'hospital',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'is',\n",
       "  'also',\n",
       "  'recommended',\n",
       "  'to',\n",
       "  'followup',\n",
       "  'with',\n",
       "  'the',\n",
       "  'Interventional',\n",
       "  'Pulmonary',\n",
       "  'service',\n",
       "  'for',\n",
       "  'followup',\n",
       "  'status',\n",
       "  'post',\n",
       "  'stent',\n",
       "  'placement',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'is',\n",
       "  'also',\n",
       "  'recommended',\n",
       "  'to',\n",
       "  'followup',\n",
       "  'with',\n",
       "  'a',\n",
       "  'neurologist',\n",
       "  'if',\n",
       "  'her',\n",
       "  'muscle',\n",
       "  'weakness',\n",
       "  'does',\n",
       "  'not',\n",
       "  'improve',\n",
       "  'within',\n",
       "  'one',\n",
       "  'week',\n",
       "  'on',\n",
       "  'physical',\n",
       "  'therapy',\n",
       "  'with',\n",
       "  'concern',\n",
       "  'for',\n",
       "  'steroid',\n",
       "  '-',\n",
       "  'induced',\n",
       "  'myopathy',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'FINAL',\n",
       "  'DIAGNOSES',\n",
       "  ':',\n",
       "  '1',\n",
       "  '.',\n",
       "  'Tracheomalacia',\n",
       "  'status',\n",
       "  'post',\n",
       "  'tracheal',\n",
       "  'and',\n",
       "  'left',\n",
       "  'main',\n",
       "  'stem',\n",
       "  'bronchial',\n",
       "  'stent',\n",
       "  'placement',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '2', '.', 'Hypertension', '.', '[SEP]'],\n",
       " ['[CLS]', '3', '.', 'Hypothyroidism', '.', '[SEP]'],\n",
       " ['[CLS]', '4', '.', 'Restrictive', 'lung', 'defect', '.', '[SEP]'],\n",
       " ['[CLS]', '5', '.', 'Depression', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'DR',\n",
       "  '.',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Last',\n",
       "  'Name',\n",
       "  '(',\n",
       "  'STitle',\n",
       "  ')',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  ',',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'First',\n",
       "  'Name3',\n",
       "  '(',\n",
       "  'LF',\n",
       "  ')',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '12',\n",
       "  '-',\n",
       "  '207',\n",
       "  'Dictated',\n",
       "  'By',\n",
       "  ':',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Last',\n",
       "  'Name',\n",
       "  '(',\n",
       "  'NamePattern1',\n",
       "  ')',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '1811', '*', '*', ']', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'MEDQUIST36',\n",
       "  'D',\n",
       "  ':',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '14',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '11',\n",
       "  ':',\n",
       "  '30',\n",
       "  'T',\n",
       "  ':',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '14',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '11',\n",
       "  ':',\n",
       "  '33',\n",
       "  'JOB',\n",
       "  '#',\n",
       "  ':',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Job',\n",
       "  'Number',\n",
       "  '1812',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]']]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'This', 'is', 'an', '81', '-', 'year', '-', 'old', 'female', 'with', 'a', 'history', 'of', '[entity]', 'emphysema', '[entity]', '(', 'not', 'on', 'home', 'O2', ')', ',', 'who', 'presents', 'with', 'three', 'days', 'of', 'shortness', 'of', 'breath', 'thought', 'by', 'her', 'primary', 'care', 'doctor', 'to', 'be', 'a', 'COPD', 'flare', '.', '[SEP]']\n",
      "['[CLS]', 'This', 'is', 'an', '81', '-', 'year', '-', 'old', 'female', 'with', 'a', 'history', 'of', '[entity]', 'emphysema', '[entity]', '(', 'not', 'on', 'home', 'O2', ')', ',', 'who', 'presents', 'with', 'three', '[entity]', 'days', 'of', 'shortness', '[entity]', 'of', 'breath', 'thought', 'by', 'her', 'primary', 'care', 'doctor', 'to', 'be', 'a', 'COPD', 'flare', '.', '[SEP]']\n",
      "['[CLS]', 'This', 'is', 'an', '81', '-', 'year', '-', 'old', 'female', 'with', 'a', 'history', 'of', '[entity]', 'emphysema', '[entity]', '(', 'not', 'on', 'home', 'O2', ')', ',', 'who', 'presents', 'with', 'three', '[entity]', 'days', 'of', 'shortness', '[entity]', 'of', 'breath', 'thought', 'by', 'her', 'primary', '[entity]', 'care', 'doctor', 'to', '[entity]', 'be', 'a', 'COPD', 'flare', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "sentences_with_problem = []\n",
    "for sentence, problem_index in zip(all_sentences, all_problems_in_text):\n",
    "    # print(problem_index)\n",
    "    if problem_index:\n",
    "        # print(sentence)\n",
    "        for i_list in problem_index:\n",
    "            s = copy.deepcopy(sentence)\n",
    "        #     # print(i_list)\n",
    "            s.insert(int(i_list[-1])+1, '[entity]')\n",
    "            s.insert(int(i_list[0]), '[entity]')\n",
    "            sentences_with_problem.append(s)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[CLS]',\n",
       "  'Admission',\n",
       "  'Date',\n",
       "  ':',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '2',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Discharge',\n",
       "  'Date',\n",
       "  ':',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '14',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Date',\n",
       "  'of',\n",
       "  'Birth',\n",
       "  ':',\n",
       "  'Sex',\n",
       "  ':',\n",
       "  'F',\n",
       "  'Service',\n",
       "  ':',\n",
       "  'MICU',\n",
       "  'and',\n",
       "  'then',\n",
       "  'to',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Doctor',\n",
       "  'Last',\n",
       "  'Name',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'Medicine', 'HISTORY', 'OF', 'PRESENT', 'ILLNESS', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'This',\n",
       "  'is',\n",
       "  'an',\n",
       "  '81',\n",
       "  '-',\n",
       "  'year',\n",
       "  '-',\n",
       "  'old',\n",
       "  'female',\n",
       "  'with',\n",
       "  'a',\n",
       "  'history',\n",
       "  'of',\n",
       "  '[entity]',\n",
       "  'emphysema',\n",
       "  '[entity]',\n",
       "  '(',\n",
       "  'not',\n",
       "  'on',\n",
       "  'home',\n",
       "  'O2',\n",
       "  ')',\n",
       "  ',',\n",
       "  'who',\n",
       "  'presents',\n",
       "  'with',\n",
       "  'three',\n",
       "  '[entity]',\n",
       "  'days',\n",
       "  'of',\n",
       "  'shortness',\n",
       "  '[entity]',\n",
       "  'of',\n",
       "  'breath',\n",
       "  'thought',\n",
       "  'by',\n",
       "  'her',\n",
       "  'primary',\n",
       "  '[entity]',\n",
       "  'care',\n",
       "  'doctor',\n",
       "  'to',\n",
       "  '[entity]',\n",
       "  'be',\n",
       "  'a',\n",
       "  'COPD',\n",
       "  'flare',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Two',\n",
       "  'days',\n",
       "  'prior',\n",
       "  'to',\n",
       "  'admission',\n",
       "  ',',\n",
       "  'she',\n",
       "  'was',\n",
       "  'started',\n",
       "  'on',\n",
       "  'a',\n",
       "  'prednisone',\n",
       "  'taper',\n",
       "  'and',\n",
       "  'one',\n",
       "  'day',\n",
       "  'prior',\n",
       "  'to',\n",
       "  'admission',\n",
       "  'she',\n",
       "  'required',\n",
       "  'oxygen',\n",
       "  'at',\n",
       "  'home',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'maintain',\n",
       "  'oxygen',\n",
       "  'saturation',\n",
       "  'greater',\n",
       "  'than',\n",
       "  '90',\n",
       "  '%',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'has',\n",
       "  'also',\n",
       "  'been',\n",
       "  'on',\n",
       "  'levofloxacin',\n",
       "  'and',\n",
       "  'nebulizers',\n",
       "  ',',\n",
       "  'and',\n",
       "  'was',\n",
       "  'not',\n",
       "  'getting',\n",
       "  'better',\n",
       "  ',',\n",
       "  'and',\n",
       "  'presented',\n",
       "  'to',\n",
       "  'the',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Hospital1',\n",
       "  '18',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'Emergency', 'Room', '.', '[SEP]'],\n",
       " ['[CLS]', 'In', 'the', '[', '*', '*', 'Hospital3', '*', '*', ']', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Emergency',\n",
       "  'Room',\n",
       "  ',',\n",
       "  'her',\n",
       "  'oxygen',\n",
       "  'saturation',\n",
       "  'was',\n",
       "  '100',\n",
       "  '%',\n",
       "  'on',\n",
       "  'CPAP',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'was',\n",
       "  'not',\n",
       "  'able',\n",
       "  'to',\n",
       "  'be',\n",
       "  'weaned',\n",
       "  'off',\n",
       "  'of',\n",
       "  'this',\n",
       "  'despite',\n",
       "  'nebulizer',\n",
       "  'treatment',\n",
       "  'and',\n",
       "  'Solu',\n",
       "  '-',\n",
       "  'Medrol',\n",
       "  '125',\n",
       "  'mg',\n",
       "  'IV',\n",
       "  'x2',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Review',\n",
       "  'of',\n",
       "  'systems',\n",
       "  'is',\n",
       "  'negative',\n",
       "  'for',\n",
       "  'the',\n",
       "  'following',\n",
       "  ':',\n",
       "  'Fevers',\n",
       "  ',',\n",
       "  'chills',\n",
       "  ',',\n",
       "  'nausea',\n",
       "  ',',\n",
       "  'vomiting',\n",
       "  ',',\n",
       "  'night',\n",
       "  'sweats',\n",
       "  ',',\n",
       "  'change',\n",
       "  'in',\n",
       "  'weight',\n",
       "  ',',\n",
       "  'gastrointestinal',\n",
       "  'complaints',\n",
       "  ',',\n",
       "  'neurologic',\n",
       "  'changes',\n",
       "  ',',\n",
       "  'rashes',\n",
       "  ',',\n",
       "  'palpitations',\n",
       "  ',',\n",
       "  'orthopnea',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Is',\n",
       "  'positive',\n",
       "  'for',\n",
       "  'the',\n",
       "  'following',\n",
       "  ':',\n",
       "  'Chest',\n",
       "  'pressure',\n",
       "  'occasionally',\n",
       "  'with',\n",
       "  'shortness',\n",
       "  'of',\n",
       "  'breath',\n",
       "  'with',\n",
       "  'exertion',\n",
       "  ',',\n",
       "  'some',\n",
       "  'shortness',\n",
       "  'of',\n",
       "  'breath',\n",
       "  'that',\n",
       "  'is',\n",
       "  'positionally',\n",
       "  'related',\n",
       "  ',',\n",
       "  'but',\n",
       "  'is',\n",
       "  'improved',\n",
       "  'with',\n",
       "  'nebulizer',\n",
       "  'treatment',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'PAST', 'MEDICAL', 'HISTORY', ':', '1', '.', 'COPD', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Last',\n",
       "  'pulmonary',\n",
       "  'function',\n",
       "  'tests',\n",
       "  'in',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2117',\n",
       "  '-',\n",
       "  '11',\n",
       "  '-',\n",
       "  '3',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'demonstrated',\n",
       "  'a',\n",
       "  'FVC',\n",
       "  'of',\n",
       "  '52',\n",
       "  '%',\n",
       "  'of',\n",
       "  'predicted',\n",
       "  ',',\n",
       "  'a',\n",
       "  'FEV1',\n",
       "  'of',\n",
       "  '54',\n",
       "  '%',\n",
       "  'of',\n",
       "  'predicted',\n",
       "  ',',\n",
       "  'a',\n",
       "  'MMF',\n",
       "  'of',\n",
       "  '23',\n",
       "  '%',\n",
       "  'of',\n",
       "  'predicted',\n",
       "  ',',\n",
       "  'and',\n",
       "  'a',\n",
       "  'FEV1',\n",
       "  ':',\n",
       "  'FVC',\n",
       "  'ratio',\n",
       "  'of',\n",
       "  '67',\n",
       "  '%',\n",
       "  'of',\n",
       "  'predicted',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'FVC',\n",
       "  ',',\n",
       "  'however',\n",
       "  ',',\n",
       "  'does',\n",
       "  'significantly',\n",
       "  'improve',\n",
       "  'with',\n",
       "  'bronchodilator',\n",
       "  'treatment',\n",
       "  'consistent',\n",
       "  'with',\n",
       "  'her',\n",
       "  'known',\n",
       "  'reversible',\n",
       "  'air',\n",
       "  'flow',\n",
       "  'obstruction',\n",
       "  'in',\n",
       "  'addition',\n",
       "  'to',\n",
       "  'an',\n",
       "  'underlying',\n",
       "  'restrictive',\n",
       "  'ventilatory',\n",
       "  'defect',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'has',\n",
       "  'never',\n",
       "  'been',\n",
       "  'on',\n",
       "  'home',\n",
       "  'oxygen',\n",
       "  'prior',\n",
       "  'to',\n",
       "  'this',\n",
       "  'recent',\n",
       "  'episode',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'has',\n",
       "  'never',\n",
       "  'been',\n",
       "  'on',\n",
       "  'steroid',\n",
       "  'taper',\n",
       "  'or',\n",
       "  'been',\n",
       "  'intubated',\n",
       "  'in',\n",
       "  'the',\n",
       "  'past',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '2', '.', 'Lacunar', 'CVA', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'MRI',\n",
       "  'of',\n",
       "  'the',\n",
       "  'head',\n",
       "  'in',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2114',\n",
       "  '-',\n",
       "  '11',\n",
       "  '-',\n",
       "  '4',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'demonstrates',\n",
       "  '\"',\n",
       "  'mild',\n",
       "  'degree',\n",
       "  'of',\n",
       "  'multiple',\n",
       "  'small',\n",
       "  'foci',\n",
       "  'of',\n",
       "  'high',\n",
       "  'T2',\n",
       "  'signal',\n",
       "  'within',\n",
       "  'the',\n",
       "  'white',\n",
       "  'matter',\n",
       "  'of',\n",
       "  'both',\n",
       "  'cerebral',\n",
       "  'hemispheres',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'the',\n",
       "  'pons',\n",
       "  ',',\n",
       "  'in',\n",
       "  'the',\n",
       "  'latter',\n",
       "  'region',\n",
       "  'predominantly',\n",
       "  'to',\n",
       "  'the',\n",
       "  'right',\n",
       "  'of',\n",
       "  'midline',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'abnormalities',\n",
       "  ',',\n",
       "  'while',\n",
       "  'nonspecific',\n",
       "  'in',\n",
       "  'etiology',\n",
       "  ',',\n",
       "  'are',\n",
       "  'most',\n",
       "  'likely',\n",
       "  'secondary',\n",
       "  'to',\n",
       "  'chronic',\n",
       "  'microvascular',\n",
       "  'infarction',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'There',\n",
       "  'is',\n",
       "  'no',\n",
       "  'mass',\n",
       "  ',',\n",
       "  'lesion',\n",
       "  ',',\n",
       "  'shift',\n",
       "  'of',\n",
       "  'the',\n",
       "  'normal',\n",
       "  'midline',\n",
       "  'strictures',\n",
       "  'or',\n",
       "  'hydrocephalus',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'major',\n",
       "  'vascular',\n",
       "  'flow',\n",
       "  'patterns',\n",
       "  'are',\n",
       "  'preserved',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'There',\n",
       "  'is',\n",
       "  'moderate',\n",
       "  'right',\n",
       "  'maxillary',\n",
       "  ',',\n",
       "  'moderate',\n",
       "  'bilateral',\n",
       "  'ethmoid',\n",
       "  ',',\n",
       "  'mild',\n",
       "  'left',\n",
       "  'maxillary',\n",
       "  ',',\n",
       "  'minimal',\n",
       "  'right',\n",
       "  'sphenoid',\n",
       "  ',',\n",
       "  'and',\n",
       "  'frontal',\n",
       "  'sinus',\n",
       "  'mucosal',\n",
       "  'thickening',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'These',\n",
       "  'abnormalities',\n",
       "  'could',\n",
       "  'represent',\n",
       "  'an',\n",
       "  'allergic',\n",
       "  'or',\n",
       "  'some',\n",
       "  'other',\n",
       "  'type',\n",
       "  'of',\n",
       "  'inflammatory',\n",
       "  'process',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Additionally',\n",
       "  'noted',\n",
       "  'is',\n",
       "  'a',\n",
       "  'moderately',\n",
       "  'enlarged',\n",
       "  'subtotally',\n",
       "  'empty',\n",
       "  'sella',\n",
       "  'turcica',\n",
       "  '\"',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '3', '.', 'Angina', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Most',\n",
       "  'recent',\n",
       "  'stress',\n",
       "  'test',\n",
       "  'was',\n",
       "  'in',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '1',\n",
       "  '-',\n",
       "  '3',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'going',\n",
       "  'for',\n",
       "  'four',\n",
       "  'minutes',\n",
       "  'with',\n",
       "  'a',\n",
       "  'rate',\n",
       "  'pressure',\n",
       "  'product',\n",
       "  'of',\n",
       "  '10',\n",
       "  ',',\n",
       "  '000',\n",
       "  ',',\n",
       "  '64',\n",
       "  '%',\n",
       "  'of',\n",
       "  'maximum',\n",
       "  'predicted',\n",
       "  'heart',\n",
       "  'rate',\n",
       "  'without',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'ischemic',\n",
       "  'EKG',\n",
       "  'changes',\n",
       "  'or',\n",
       "  'symptoms',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'imaging',\n",
       "  'portion',\n",
       "  'of',\n",
       "  'the',\n",
       "  'study',\n",
       "  'demonstrated',\n",
       "  'no',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'myocardial',\n",
       "  'ischemia',\n",
       "  'and',\n",
       "  'a',\n",
       "  'calculated',\n",
       "  'ejection',\n",
       "  'fraction',\n",
       "  'of',\n",
       "  '84',\n",
       "  '%',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'denies',\n",
       "  'angina',\n",
       "  'at',\n",
       "  'rest',\n",
       "  'and',\n",
       "  'gets',\n",
       "  'angina',\n",
       "  'with',\n",
       "  'walking',\n",
       "  'a',\n",
       "  'few',\n",
       "  'blocks',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Are',\n",
       "  'alleviated',\n",
       "  'by',\n",
       "  'sublingual',\n",
       "  'nitroglycerin',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '4', '.', 'Hypothyroidism', 'on', 'Synthroid', '.', '[SEP]'],\n",
       " ['[CLS]', '5', '.', 'Depression', 'on', 'Lexapro', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '6',\n",
       "  '.',\n",
       "  'Motor',\n",
       "  'vehicle',\n",
       "  'accident',\n",
       "  'with',\n",
       "  'head',\n",
       "  'injury',\n",
       "  'approximately',\n",
       "  '10',\n",
       "  'years',\n",
       "  'ago',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'MEDICATIONS',\n",
       "  'ON',\n",
       "  'ADMISSION',\n",
       "  ':',\n",
       "  '1',\n",
       "  '.',\n",
       "  'Hydrochlorothiazide',\n",
       "  '25',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '2',\n",
       "  '.',\n",
       "  'Prednisone',\n",
       "  '60',\n",
       "  'mg',\n",
       "  ',',\n",
       "  '50',\n",
       "  'mg',\n",
       "  ',',\n",
       "  '40',\n",
       "  'mg',\n",
       "  ',',\n",
       "  '20',\n",
       "  'mg',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '3',\n",
       "  '.',\n",
       "  'Levofloxacin',\n",
       "  '500',\n",
       "  'mg',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '4',\n",
       "  '.',\n",
       "  'Imdur',\n",
       "  '60',\n",
       "  'mg',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '5',\n",
       "  '.',\n",
       "  'Synthroid',\n",
       "  '75',\n",
       "  'mcg',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '6',\n",
       "  '.',\n",
       "  'Pulmicort',\n",
       "  'nebulizer',\n",
       "  'b',\n",
       "  '.',\n",
       "  'i',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '7',\n",
       "  '.',\n",
       "  'Albuterol',\n",
       "  'nebulizer',\n",
       "  'q',\n",
       "  '.',\n",
       "  '4',\n",
       "  '.',\n",
       "  'prn',\n",
       "  '.',\n",
       "  '8',\n",
       "  '.',\n",
       "  'Lexapro',\n",
       "  '10',\n",
       "  'mg',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '9',\n",
       "  '.',\n",
       "  'Protonix',\n",
       "  '40',\n",
       "  'mg',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '10',\n",
       "  '.',\n",
       "  'Aspirin',\n",
       "  '81',\n",
       "  'mg',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  'ALLERGIES',\n",
       "  ':',\n",
       "  'Norvasc',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'lightheaded',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'FAMILY', 'HISTORY', ':', 'Noncontributory', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'SOCIAL',\n",
       "  'HISTORY',\n",
       "  ':',\n",
       "  'Lives',\n",
       "  'with',\n",
       "  'her',\n",
       "  'husband',\n",
       "  ',',\n",
       "  'Dr',\n",
       "  '.',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Known',\n",
       "  'lastname',\n",
       "  '1809',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'an',\n",
       "  'eminent',\n",
       "  'Pediatric',\n",
       "  'Neurologist',\n",
       "  'at',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Hospital3',\n",
       "  '1810',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'is',\n",
       "  'a',\n",
       "  'prior',\n",
       "  'smoker',\n",
       "  ',',\n",
       "  'but',\n",
       "  'has',\n",
       "  'not',\n",
       "  'smoked',\n",
       "  'in',\n",
       "  'over',\n",
       "  '10',\n",
       "  'years',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'has',\n",
       "  'no',\n",
       "  'known',\n",
       "  'alcohol',\n",
       "  'use',\n",
       "  'and',\n",
       "  'she',\n",
       "  'is',\n",
       "  'a',\n",
       "  'full',\n",
       "  'code',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'PHYSICAL',\n",
       "  'EXAM',\n",
       "  'AT',\n",
       "  'TIME',\n",
       "  'OF',\n",
       "  'ADMISSION',\n",
       "  ':',\n",
       "  'Blood',\n",
       "  'pressure',\n",
       "  '142',\n",
       "  '/',\n",
       "  '76',\n",
       "  ',',\n",
       "  'heart',\n",
       "  'rate',\n",
       "  '100',\n",
       "  'and',\n",
       "  'regular',\n",
       "  ',',\n",
       "  'respirations',\n",
       "  'at',\n",
       "  '17',\n",
       "  '-',\n",
       "  '21',\n",
       "  ',',\n",
       "  'and',\n",
       "  '97',\n",
       "  '%',\n",
       "  'axillary',\n",
       "  'temperature',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'was',\n",
       "  'saturating',\n",
       "  'at',\n",
       "  '100',\n",
       "  '%',\n",
       "  'on',\n",
       "  'CPAP',\n",
       "  'with',\n",
       "  'dry',\n",
       "  'mucous',\n",
       "  'membranes',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'An',\n",
       "  'elderly',\n",
       "  'female',\n",
       "  'in',\n",
       "  'no',\n",
       "  'apparent',\n",
       "  'distress',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Pupils',\n",
       "  'are',\n",
       "  'equal',\n",
       "  ',',\n",
       "  'round',\n",
       "  ',',\n",
       "  'and',\n",
       "  'reactive',\n",
       "  'to',\n",
       "  'light',\n",
       "  'and',\n",
       "  'accommodation',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'Extraocular', 'movements', 'are', 'intact', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Oropharynx',\n",
       "  'difficult',\n",
       "  'to',\n",
       "  'assess',\n",
       "  'due',\n",
       "  'to',\n",
       "  'CPAP',\n",
       "  'machine',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'No',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'jugular',\n",
       "  'venous',\n",
       "  'pressure',\n",
       "  ',',\n",
       "  'however',\n",
       "  ',',\n",
       "  'the',\n",
       "  'strap',\n",
       "  'from',\n",
       "  'the',\n",
       "  'CPAP',\n",
       "  'machine',\n",
       "  'obscures',\n",
       "  'the',\n",
       "  'neck',\n",
       "  'exam',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Cranial',\n",
       "  'nerves',\n",
       "  'II',\n",
       "  'through',\n",
       "  'XII',\n",
       "  'are',\n",
       "  'grossly',\n",
       "  'intact',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'Neck', 'is', 'supple', 'without', 'lymphadenopathy', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Heart',\n",
       "  'exam',\n",
       "  ':',\n",
       "  'Tachycardic',\n",
       "  ',',\n",
       "  'regular',\n",
       "  ',',\n",
       "  'obscured',\n",
       "  'by',\n",
       "  'loud',\n",
       "  'bilateral',\n",
       "  'wheezing',\n",
       "  'with',\n",
       "  'increase',\n",
       "  'in',\n",
       "  'the',\n",
       "  'expiratory',\n",
       "  'phase',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'profuse',\n",
       "  'scattered',\n",
       "  'rhonchi',\n",
       "  'throughout',\n",
       "  'the',\n",
       "  'lung',\n",
       "  'fields',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Positive',\n",
       "  'bowel',\n",
       "  'sounds',\n",
       "  ',',\n",
       "  'soft',\n",
       "  ',',\n",
       "  'nontender',\n",
       "  ',',\n",
       "  'nondistended',\n",
       "  ',',\n",
       "  'obese',\n",
       "  ',',\n",
       "  'no',\n",
       "  'masses',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Mild',\n",
       "  'edema',\n",
       "  'of',\n",
       "  'the',\n",
       "  'lower',\n",
       "  'extremities',\n",
       "  'without',\n",
       "  'clubbing',\n",
       "  'or',\n",
       "  'cyanosis',\n",
       "  ',',\n",
       "  'no',\n",
       "  'rashes',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'There', 'is', 'a', 'right', 'hand', 'hematoma', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Strength',\n",
       "  'is',\n",
       "  'assessed',\n",
       "  'as',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '5',\n",
       "  '-',\n",
       "  '9',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'in',\n",
       "  'the',\n",
       "  'lower',\n",
       "  'extremities',\n",
       "  ',',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '5',\n",
       "  '-',\n",
       "  '9',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'in',\n",
       "  'the',\n",
       "  'upper',\n",
       "  'extremities',\n",
       "  'with',\n",
       "  'a',\n",
       "  'normal',\n",
       "  'mental',\n",
       "  'status',\n",
       "  'and',\n",
       "  'cognition',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'LABORATORY', 'STUDIES', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'White',\n",
       "  'count',\n",
       "  '19',\n",
       "  ',',\n",
       "  'hematocrit',\n",
       "  '41',\n",
       "  ',',\n",
       "  'platelets',\n",
       "  '300',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Chem',\n",
       "  '-',\n",
       "  '7',\n",
       "  ':',\n",
       "  '127',\n",
       "  ',',\n",
       "  '3',\n",
       "  '.',\n",
       "  '6',\n",
       "  ',',\n",
       "  '88',\n",
       "  ',',\n",
       "  '29',\n",
       "  ',',\n",
       "  '17',\n",
       "  ',',\n",
       "  '0',\n",
       "  '.',\n",
       "  '6',\n",
       "  ',',\n",
       "  '143',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'Troponin', 'was', 'negative', '.', '[SEP]'],\n",
       " ['[CLS]', 'CKs', 'were', 'negative', 'times', 'three', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Initial',\n",
       "  'blood',\n",
       "  'gas',\n",
       "  'showed',\n",
       "  'a',\n",
       "  'pH',\n",
       "  'of',\n",
       "  '7',\n",
       "  '.',\n",
       "  '4',\n",
       "  ',',\n",
       "  'pO2',\n",
       "  'of',\n",
       "  '66',\n",
       "  ',',\n",
       "  'pCO2',\n",
       "  'of',\n",
       "  '54',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Chest',\n",
       "  'x',\n",
       "  '-',\n",
       "  'ray',\n",
       "  'demonstrates',\n",
       "  'a',\n",
       "  'moderate',\n",
       "  'sized',\n",
       "  'hiatal',\n",
       "  'hernia',\n",
       "  ',',\n",
       "  'segmental',\n",
       "  'atelectasis',\n",
       "  ',',\n",
       "  'left',\n",
       "  'lower',\n",
       "  'lobe',\n",
       "  'infiltrate',\n",
       "  'versus',\n",
       "  'segmental',\n",
       "  'atelectasis',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'EKG',\n",
       "  'shows',\n",
       "  'normal',\n",
       "  'sinus',\n",
       "  'rhythm',\n",
       "  'at',\n",
       "  '113',\n",
       "  'beats',\n",
       "  'per',\n",
       "  'minute',\n",
       "  ',',\n",
       "  'normal',\n",
       "  'axis',\n",
       "  ',',\n",
       "  'no',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'ST',\n",
       "  '-',\n",
       "  'T',\n",
       "  'wave',\n",
       "  'changes',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'BRIEF',\n",
       "  'SUMMARY',\n",
       "  'OF',\n",
       "  'HOSPITAL',\n",
       "  'COURSE',\n",
       "  ':',\n",
       "  '1',\n",
       "  '.',\n",
       "  'COPD',\n",
       "  '/',\n",
       "  'dyspnea',\n",
       "  '/',\n",
       "  'pneumonia',\n",
       "  ':',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'initially',\n",
       "  'placed',\n",
       "  'on',\n",
       "  'an',\n",
       "  'aggressive',\n",
       "  'steroid',\n",
       "  'taper',\n",
       "  'and',\n",
       "  'admitted',\n",
       "  'to',\n",
       "  'the',\n",
       "  'Medical',\n",
       "  'Intensive',\n",
       "  'Care',\n",
       "  'Unit',\n",
       "  'due',\n",
       "  'to',\n",
       "  'her',\n",
       "  'difficulty',\n",
       "  'with',\n",
       "  'oxygenation',\n",
       "  'despite',\n",
       "  'CPAP',\n",
       "  'machine',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'was',\n",
       "  'also',\n",
       "  'given',\n",
       "  'nebulizer',\n",
       "  'treatments',\n",
       "  'q',\n",
       "  '.',\n",
       "  '4h',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'as', 'well', 'as', 'chest', 'PT', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'nebulizers',\n",
       "  'were',\n",
       "  'increased',\n",
       "  'to',\n",
       "  'q',\n",
       "  '.',\n",
       "  '1h',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'she',\n",
       "  'continued',\n",
       "  'to',\n",
       "  'have',\n",
       "  'labored',\n",
       "  'breathing',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Due',\n",
       "  'to',\n",
       "  'persistent',\n",
       "  'respiratory',\n",
       "  'failure',\n",
       "  'and',\n",
       "  'labored',\n",
       "  'breathing',\n",
       "  ',',\n",
       "  'the',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'intubated',\n",
       "  'on',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '7',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'improve',\n",
       "  'oxygenation',\n",
       "  ',',\n",
       "  'ventilation',\n",
       "  ',',\n",
       "  'and',\n",
       "  'ability',\n",
       "  'to',\n",
       "  'suction',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'A',\n",
       "  'bronchoscopy',\n",
       "  'was',\n",
       "  'performed',\n",
       "  'on',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '7',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  ',',\n",
       "  'which',\n",
       "  'demonstrated',\n",
       "  'marked',\n",
       "  'narrowing',\n",
       "  'of',\n",
       "  'the',\n",
       "  'airways',\n",
       "  'with',\n",
       "  'expiration',\n",
       "  'consistent',\n",
       "  'with',\n",
       "  'tracheomalacia',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'On',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '9',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  ',',\n",
       "  'two',\n",
       "  'silicone',\n",
       "  'stents',\n",
       "  'were',\n",
       "  'placed',\n",
       "  ',',\n",
       "  'one',\n",
       "  'in',\n",
       "  'the',\n",
       "  'left',\n",
       "  'main',\n",
       "  'stem',\n",
       "  '(',\n",
       "  '12',\n",
       "  'x',\n",
       "  '25',\n",
       "  'and',\n",
       "  'one',\n",
       "  'in',\n",
       "  'the',\n",
       "  'trachea',\n",
       "  '16',\n",
       "  'x',\n",
       "  '40',\n",
       "  ')',\n",
       "  'by',\n",
       "  'Dr',\n",
       "  '.',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'First',\n",
       "  'Name',\n",
       "  '(',\n",
       "  'STitle',\n",
       "  ')',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Name',\n",
       "  '(',\n",
       "  'STitle',\n",
       "  ')',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'under',\n",
       "  'rigid',\n",
       "  'bronchoscopy',\n",
       "  'with',\n",
       "  'general',\n",
       "  'anesthesia',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'On',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '11',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  ',',\n",
       "  'the',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'extubated',\n",
       "  'to',\n",
       "  'a',\n",
       "  'cool',\n",
       "  'mist',\n",
       "  'shovel',\n",
       "  'mask',\n",
       "  'and',\n",
       "  'her',\n",
       "  'oxygen',\n",
       "  'was',\n",
       "  'titrated',\n",
       "  'down',\n",
       "  'to',\n",
       "  '2',\n",
       "  'liters',\n",
       "  'nasal',\n",
       "  'cannula',\n",
       "  'at',\n",
       "  'which',\n",
       "  'time',\n",
       "  'she',\n",
       "  'was',\n",
       "  'transferred',\n",
       "  'to',\n",
       "  'the',\n",
       "  'medical',\n",
       "  'floor',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'On',\n",
       "  'the',\n",
       "  'medical',\n",
       "  'floor',\n",
       "  ',',\n",
       "  'the',\n",
       "  'steroids',\n",
       "  'were',\n",
       "  'weaned',\n",
       "  'to',\n",
       "  'off',\n",
       "  'on',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '14',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  ',',\n",
       "  'and',\n",
       "  'the',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'saturating',\n",
       "  'at',\n",
       "  '97',\n",
       "  '%',\n",
       "  'on',\n",
       "  '2',\n",
       "  'liters',\n",
       "  ',',\n",
       "  '92',\n",
       "  '%',\n",
       "  'on',\n",
       "  'room',\n",
       "  'air',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'On',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '14',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  ',',\n",
       "  'the',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'seen',\n",
       "  'again',\n",
       "  'by',\n",
       "  'the',\n",
       "  'Interventional',\n",
       "  'Pulmonology',\n",
       "  'service',\n",
       "  ',',\n",
       "  'who',\n",
       "  'agreed',\n",
       "  'that',\n",
       "  'she',\n",
       "  'looked',\n",
       "  'much',\n",
       "  'improved',\n",
       "  'and',\n",
       "  'recommended',\n",
       "  'that',\n",
       "  'she',\n",
       "  'go',\n",
       "  'to',\n",
       "  'pulmonary',\n",
       "  'rehabilitation',\n",
       "  'with',\n",
       "  'followup',\n",
       "  'within',\n",
       "  'six',\n",
       "  'weeks',\n",
       "  '\\\\',\n",
       "  'cf4',\n",
       "  '\\\\',\n",
       "  \"'\",\n",
       "  '\\\\',\n",
       "  'cf2',\n",
       "  'time',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '2', '.', 'Cardiovascular', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'ruled',\n",
       "  'out',\n",
       "  'for',\n",
       "  'a',\n",
       "  'MI',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'did',\n",
       "  'have',\n",
       "  'another',\n",
       "  'episode',\n",
       "  'on',\n",
       "  'the',\n",
       "  'medical',\n",
       "  'floor',\n",
       "  'of',\n",
       "  'chest',\n",
       "  'pain',\n",
       "  ',',\n",
       "  'which',\n",
       "  'showed',\n",
       "  'no',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'EKG',\n",
       "  'changes',\n",
       "  'and',\n",
       "  'negative',\n",
       "  'troponin',\n",
       "  ',',\n",
       "  'negative',\n",
       "  'CKs',\n",
       "  'x3',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'was',\n",
       "  'continued',\n",
       "  'on',\n",
       "  'aspirin',\n",
       "  ',',\n",
       "  'Imdur',\n",
       "  ',',\n",
       "  'and',\n",
       "  'diltiazem',\n",
       "  'for',\n",
       "  'rate',\n",
       "  'control',\n",
       "  'per',\n",
       "  'her',\n",
       "  'outpatient',\n",
       "  'regimen',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '3', '.', 'Hypertension', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'was',\n",
       "  'maintained',\n",
       "  'on',\n",
       "  'diltiazem',\n",
       "  'and',\n",
       "  'hydrochlorothiazide',\n",
       "  'with',\n",
       "  'adequate',\n",
       "  'blood',\n",
       "  'pressure',\n",
       "  'control',\n",
       "  'and',\n",
       "  'normalization',\n",
       "  'of',\n",
       "  'electrolytes',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '4', '.', 'Hematuria', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'had',\n",
       "  'intermittent',\n",
       "  'hematuria',\n",
       "  'likely',\n",
       "  'secondary',\n",
       "  'to',\n",
       "  'Foley',\n",
       "  'placement',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'Foley',\n",
       "  'catheter',\n",
       "  'was',\n",
       "  'discontinued',\n",
       "  'on',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '14',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'had',\n",
       "  'serial',\n",
       "  'urinalyses',\n",
       "  ',',\n",
       "  'which',\n",
       "  'were',\n",
       "  'all',\n",
       "  'negative',\n",
       "  'for',\n",
       "  'signs',\n",
       "  'of',\n",
       "  'infection',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '5',\n",
       "  '.',\n",
       "  'Hyperglycemia',\n",
       "  ':',\n",
       "  'Patient',\n",
       "  'was',\n",
       "  'placed',\n",
       "  'on',\n",
       "  'insulin',\n",
       "  '-',\n",
       "  'sliding',\n",
       "  'scale',\n",
       "  'due',\n",
       "  'to',\n",
       "  'hyperglycemia',\n",
       "  ',',\n",
       "  'which',\n",
       "  'was',\n",
       "  'steroid',\n",
       "  'induced',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'This',\n",
       "  'worked',\n",
       "  'quite',\n",
       "  'well',\n",
       "  'and',\n",
       "  'her',\n",
       "  'glucose',\n",
       "  'came',\n",
       "  'back',\n",
       "  'to',\n",
       "  'normal',\n",
       "  'levels',\n",
       "  'once',\n",
       "  'the',\n",
       "  'steroids',\n",
       "  'were',\n",
       "  'tapered',\n",
       "  'to',\n",
       "  'off',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '6',\n",
       "  '.',\n",
       "  'Leukocytosis',\n",
       "  ':',\n",
       "  'Patient',\n",
       "  'did',\n",
       "  'have',\n",
       "  'a',\n",
       "  'profound',\n",
       "  'leukocytosis',\n",
       "  'of',\n",
       "  '20',\n",
       "  'to',\n",
       "  '22',\n",
       "  'during',\n",
       "  'much',\n",
       "  'of',\n",
       "  'her',\n",
       "  'hospital',\n",
       "  'course',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'As',\n",
       "  'the',\n",
       "  'steroids',\n",
       "  'were',\n",
       "  'tapered',\n",
       "  'to',\n",
       "  'off',\n",
       "  ',',\n",
       "  'her',\n",
       "  'white',\n",
       "  'blood',\n",
       "  'cell',\n",
       "  'count',\n",
       "  'on',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '14',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'was',\n",
       "  '15',\n",
       "  ',',\n",
       "  '000',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'It',\n",
       "  'was',\n",
       "  'felt',\n",
       "  'that',\n",
       "  'the',\n",
       "  'leukocytosis',\n",
       "  'was',\n",
       "  'secondary',\n",
       "  'to',\n",
       "  'both',\n",
       "  'steroids',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'question',\n",
       "  'of',\n",
       "  'a',\n",
       "  'left',\n",
       "  'lower',\n",
       "  'lobe',\n",
       "  'pneumonia',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '7',\n",
       "  '.',\n",
       "  'For',\n",
       "  'the',\n",
       "  'left',\n",
       "  'lower',\n",
       "  'lobe',\n",
       "  'pneumonia',\n",
       "  ',',\n",
       "  'the',\n",
       "  'patient',\n",
       "  'had',\n",
       "  'initially',\n",
       "  'received',\n",
       "  'a',\n",
       "  'course',\n",
       "  'of',\n",
       "  'levofloxacin',\n",
       "  '500',\n",
       "  'p',\n",
       "  '.',\n",
       "  'o',\n",
       "  '.',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  'from',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '4',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'to',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '10',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'This',\n",
       "  'was',\n",
       "  'restarted',\n",
       "  'on',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '12',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'for',\n",
       "  'an',\n",
       "  'additional',\n",
       "  'seven',\n",
       "  'day',\n",
       "  'course',\n",
       "  'given',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'she',\n",
       "  'still',\n",
       "  'had',\n",
       "  'the',\n",
       "  'leukocytosis',\n",
       "  'and',\n",
       "  'still',\n",
       "  'had',\n",
       "  'marked',\n",
       "  'rales',\n",
       "  'at',\n",
       "  'the',\n",
       "  'left',\n",
       "  'lower',\n",
       "  'lobe',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '8', '.', 'Hypothyroidism', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'continued',\n",
       "  'on',\n",
       "  'outpatient',\n",
       "  'medical',\n",
       "  'regimen',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '9', '.', 'Depression', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'continued',\n",
       "  'on',\n",
       "  'Lexapro',\n",
       "  'per',\n",
       "  'outpatient',\n",
       "  'regimen',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'It',\n",
       "  'is',\n",
       "  'recommended',\n",
       "  'that',\n",
       "  'she',\n",
       "  'follow',\n",
       "  'up',\n",
       "  'with',\n",
       "  'a',\n",
       "  'therapist',\n",
       "  'as',\n",
       "  'an',\n",
       "  'outpatient',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'she',\n",
       "  'did',\n",
       "  'have',\n",
       "  'a',\n",
       "  'blunted',\n",
       "  'affect',\n",
       "  'throughout',\n",
       "  'much',\n",
       "  'of',\n",
       "  'the',\n",
       "  'hospital',\n",
       "  'course',\n",
       "  ',',\n",
       "  'and',\n",
       "  'did',\n",
       "  'appear',\n",
       "  'clinically',\n",
       "  'to',\n",
       "  'be',\n",
       "  'depressed',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '10', '.', 'Prophylaxis', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'was',\n",
       "  'maintained',\n",
       "  'on',\n",
       "  'proton',\n",
       "  '-',\n",
       "  'pump',\n",
       "  'inhibitor',\n",
       "  'with',\n",
       "  'subQ',\n",
       "  'Heparin',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '11', '.', '[SEP]'],\n",
       " ['[CLS]', 'Sore', 'throat', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'did',\n",
       "  'have',\n",
       "  'a',\n",
       "  'sore',\n",
       "  'throat',\n",
       "  'for',\n",
       "  'much',\n",
       "  'of',\n",
       "  'the',\n",
       "  'hospital',\n",
       "  'course',\n",
       "  'post',\n",
       "  'extubation',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'This',\n",
       "  'was',\n",
       "  'treated',\n",
       "  'with',\n",
       "  'Cepacol',\n",
       "  'lozenges',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'KBL',\n",
       "  'liquid',\n",
       "  '(',\n",
       "  'a',\n",
       "  'solution',\n",
       "  'containing',\n",
       "  'Kaopectate',\n",
       "  ',',\n",
       "  'Bismuth',\n",
       "  ',',\n",
       "  'and',\n",
       "  'lidocaine',\n",
       "  ')',\n",
       "  'at',\n",
       "  'bedtime',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '12', '.', 'Communication', '/', 'code', 'status', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'full',\n",
       "  'code',\n",
       "  'throughout',\n",
       "  'her',\n",
       "  'hospital',\n",
       "  'course',\n",
       "  ',',\n",
       "  'and',\n",
       "  'communication',\n",
       "  'was',\n",
       "  'maintained',\n",
       "  'with',\n",
       "  'the',\n",
       "  'patient',\n",
       "  'and',\n",
       "  'her',\n",
       "  'husband',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '13', '.', 'Muscle', 'weakness', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'did',\n",
       "  'have',\n",
       "  'profound',\n",
       "  'muscle',\n",
       "  'weakness',\n",
       "  'and',\n",
       "  'was',\n",
       "  'evaluated',\n",
       "  'by',\n",
       "  'Physical',\n",
       "  'Therapy',\n",
       "  ',',\n",
       "  'and',\n",
       "  'was',\n",
       "  'found',\n",
       "  'to',\n",
       "  'have',\n",
       "  'impaired',\n",
       "  'functional',\n",
       "  'mobility',\n",
       "  ',',\n",
       "  'impaired',\n",
       "  'musculoskeletal',\n",
       "  'performance',\n",
       "  ',',\n",
       "  'impaired',\n",
       "  'gas',\n",
       "  'exchange',\n",
       "  ',',\n",
       "  'impaired',\n",
       "  'endurance',\n",
       "  ',',\n",
       "  'impaired',\n",
       "  'ventilation',\n",
       "  ',',\n",
       "  'and',\n",
       "  'needed',\n",
       "  'help',\n",
       "  'with',\n",
       "  'supine',\n",
       "  'to',\n",
       "  'sit',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'However',\n",
       "  ',',\n",
       "  'she',\n",
       "  'was',\n",
       "  'able',\n",
       "  'to',\n",
       "  'tolerate',\n",
       "  'sitting',\n",
       "  'in',\n",
       "  'a',\n",
       "  'chair',\n",
       "  'for',\n",
       "  'approximately',\n",
       "  'one',\n",
       "  'hour',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'On',\n",
       "  'motor',\n",
       "  'exam',\n",
       "  ',',\n",
       "  'her',\n",
       "  'flexors',\n",
       "  'and',\n",
       "  'extensors',\n",
       "  'of',\n",
       "  'the',\n",
       "  'lower',\n",
       "  'extremities',\n",
       "  'were',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '4',\n",
       "  '-',\n",
       "  '8',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'at',\n",
       "  'the',\n",
       "  'knee',\n",
       "  ',',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '4',\n",
       "  '-',\n",
       "  '8',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'at',\n",
       "  'the',\n",
       "  'ankle',\n",
       "  ',',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '4',\n",
       "  '-',\n",
       "  '8',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'at',\n",
       "  'the',\n",
       "  'elbows',\n",
       "  ',',\n",
       "  'and',\n",
       "  '[',\n",
       "  '*',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'It',\n",
       "  'was',\n",
       "  'felt',\n",
       "  'that',\n",
       "  'this',\n",
       "  'weakness',\n",
       "  'was',\n",
       "  'most',\n",
       "  'likely',\n",
       "  'due',\n",
       "  'to',\n",
       "  'a',\n",
       "  'combination',\n",
       "  'of',\n",
       "  'steroid',\n",
       "  'myopathy',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'muscle',\n",
       "  'atrophy',\n",
       "  'secondary',\n",
       "  'to',\n",
       "  'deconditioning',\n",
       "  'after',\n",
       "  'a',\n",
       "  'prolonged',\n",
       "  'hospital',\n",
       "  'course',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '14', '.', 'Speech', '/', 'swallow', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'had',\n",
       "  'a',\n",
       "  'Speech',\n",
       "  'and',\n",
       "  'Swallow',\n",
       "  'evaluation',\n",
       "  'showing',\n",
       "  'no',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'dysphagia',\n",
       "  ',',\n",
       "  'no',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'vocal',\n",
       "  'cord',\n",
       "  'damage',\n",
       "  'status',\n",
       "  'post',\n",
       "  'tracheal',\n",
       "  'stent',\n",
       "  'placement',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'DISCHARGE', 'CONDITION', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'was',\n",
       "  'able',\n",
       "  'to',\n",
       "  'oxygenate',\n",
       "  'on',\n",
       "  'room',\n",
       "  'air',\n",
       "  'at',\n",
       "  '93',\n",
       "  '%',\n",
       "  'at',\n",
       "  'the',\n",
       "  'time',\n",
       "  'of',\n",
       "  'discharge',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'was',\n",
       "  'profoundly',\n",
       "  'weak',\n",
       "  ',',\n",
       "  'but',\n",
       "  'was',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'tachycardic',\n",
       "  'and',\n",
       "  'had',\n",
       "  'a',\n",
       "  'normal',\n",
       "  'blood',\n",
       "  'pressure',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'Her',\n",
       "  'respirations',\n",
       "  'were',\n",
       "  'much',\n",
       "  'improved',\n",
       "  'albeit',\n",
       "  'with',\n",
       "  'transmitted',\n",
       "  'upper',\n",
       "  'airway',\n",
       "  'sounds',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'DISCHARGE', 'STATUS', ':', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'will',\n",
       "  'be',\n",
       "  'discharged',\n",
       "  'to',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Hospital1',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'for',\n",
       "  'both',\n",
       "  'pulmonary',\n",
       "  'and',\n",
       "  'physical',\n",
       "  'rehabilitation',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'DISCHARGE',\n",
       "  'MEDICATIONS',\n",
       "  ':',\n",
       "  '1',\n",
       "  '.',\n",
       "  'Levothyroxine',\n",
       "  '75',\n",
       "  'mcg',\n",
       "  'p',\n",
       "  '.',\n",
       "  'o',\n",
       "  '.',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '2',\n",
       "  '.',\n",
       "  'Citalopram',\n",
       "  '10',\n",
       "  'mg',\n",
       "  'p',\n",
       "  '.',\n",
       "  'o',\n",
       "  '.',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '3',\n",
       "  '.',\n",
       "  'Aspirin',\n",
       "  '81',\n",
       "  'mg',\n",
       "  'p',\n",
       "  '.',\n",
       "  'o',\n",
       "  '.',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '5',\n",
       "  '.',\n",
       "  'Salmeterol',\n",
       "  'Diskus',\n",
       "  'one',\n",
       "  'inhalation',\n",
       "  'b',\n",
       "  '.',\n",
       "  'i',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '6',\n",
       "  '.',\n",
       "  'Acetaminophen',\n",
       "  '325',\n",
       "  '-',\n",
       "  '650',\n",
       "  'mg',\n",
       "  'p',\n",
       "  '.',\n",
       "  'o',\n",
       "  '.',\n",
       "  'q',\n",
       "  '.',\n",
       "  '4',\n",
       "  '-',\n",
       "  '6h',\n",
       "  '.',\n",
       "  'prn',\n",
       "  '.',\n",
       "  '7',\n",
       "  '.',\n",
       "  'Ipratropium',\n",
       "  'bromide',\n",
       "  'MDI',\n",
       "  'two',\n",
       "  'puffs',\n",
       "  'inhaled',\n",
       "  'q',\n",
       "  '.',\n",
       "  '2h',\n",
       "  '.',\n",
       "  'prn',\n",
       "  '.',\n",
       "  '8',\n",
       "  '.',\n",
       "  'Albuterol',\n",
       "  '1',\n",
       "  '-',\n",
       "  '2',\n",
       "  'puffs',\n",
       "  'inhaled',\n",
       "  'q',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '15',\n",
       "  '.',\n",
       "  'Cepacol',\n",
       "  'lozenges',\n",
       "  'q',\n",
       "  '.',\n",
       "  '2h',\n",
       "  '.',\n",
       "  'prn',\n",
       "  '.',\n",
       "  '16',\n",
       "  '.',\n",
       "  'Levofloxacin',\n",
       "  '500',\n",
       "  'mg',\n",
       "  'p',\n",
       "  '.',\n",
       "  'o',\n",
       "  '.',\n",
       "  'q',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  'for',\n",
       "  'a',\n",
       "  'seven',\n",
       "  'day',\n",
       "  'course',\n",
       "  'to',\n",
       "  'be',\n",
       "  'completed',\n",
       "  'on',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '21',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '17',\n",
       "  '.',\n",
       "  'Kaopectate',\n",
       "  '/',\n",
       "  'Benadryl',\n",
       "  '/',\n",
       "  'lidocaine',\n",
       "  '5',\n",
       "  'mL',\n",
       "  'p',\n",
       "  '.',\n",
       "  'o',\n",
       "  '.',\n",
       "  'b',\n",
       "  '.',\n",
       "  'i',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  'prn',\n",
       "  ',',\n",
       "  'not',\n",
       "  'to',\n",
       "  'be',\n",
       "  'given',\n",
       "  'around',\n",
       "  'mealtimes',\n",
       "  'for',\n",
       "  'concern',\n",
       "  'of',\n",
       "  'dysphagia',\n",
       "  'induced',\n",
       "  'by',\n",
       "  'lidocaine',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '18',\n",
       "  '.',\n",
       "  'Lorazepam',\n",
       "  '0',\n",
       "  '.',\n",
       "  '5',\n",
       "  '-',\n",
       "  '2',\n",
       "  'mg',\n",
       "  'IV',\n",
       "  'q',\n",
       "  '.',\n",
       "  '6h',\n",
       "  '.',\n",
       "  'prn',\n",
       "  '.',\n",
       "  'FOLLOW',\n",
       "  '-',\n",
       "  'UP',\n",
       "  'PLANS',\n",
       "  ':',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'The',\n",
       "  'patient',\n",
       "  'is',\n",
       "  'recommended',\n",
       "  'to',\n",
       "  'followup',\n",
       "  'with',\n",
       "  'Dr',\n",
       "  '.',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'First',\n",
       "  'Name4',\n",
       "  '(',\n",
       "  'NamePattern1',\n",
       "  ')',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Last',\n",
       "  'Name',\n",
       "  '(',\n",
       "  'NamePattern1',\n",
       "  ')',\n",
       "  '1407',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  ',',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Telephone',\n",
       "  '/',\n",
       "  'Fax',\n",
       "  '(',\n",
       "  '1',\n",
       "  ')',\n",
       "  '1408',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  'within',\n",
       "  'two',\n",
       "  'weeks',\n",
       "  'of',\n",
       "  'leaving',\n",
       "  'of',\n",
       "  'the',\n",
       "  'hospital',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'is',\n",
       "  'also',\n",
       "  'recommended',\n",
       "  'to',\n",
       "  'followup',\n",
       "  'with',\n",
       "  'the',\n",
       "  'Interventional',\n",
       "  'Pulmonary',\n",
       "  'service',\n",
       "  'for',\n",
       "  'followup',\n",
       "  'status',\n",
       "  'post',\n",
       "  'stent',\n",
       "  'placement',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'She',\n",
       "  'is',\n",
       "  'also',\n",
       "  'recommended',\n",
       "  'to',\n",
       "  'followup',\n",
       "  'with',\n",
       "  'a',\n",
       "  'neurologist',\n",
       "  'if',\n",
       "  'her',\n",
       "  'muscle',\n",
       "  'weakness',\n",
       "  'does',\n",
       "  'not',\n",
       "  'improve',\n",
       "  'within',\n",
       "  'one',\n",
       "  'week',\n",
       "  'on',\n",
       "  'physical',\n",
       "  'therapy',\n",
       "  'with',\n",
       "  'concern',\n",
       "  'for',\n",
       "  'steroid',\n",
       "  '-',\n",
       "  'induced',\n",
       "  'myopathy',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'FINAL',\n",
       "  'DIAGNOSES',\n",
       "  ':',\n",
       "  '1',\n",
       "  '.',\n",
       "  'Tracheomalacia',\n",
       "  'status',\n",
       "  'post',\n",
       "  'tracheal',\n",
       "  'and',\n",
       "  'left',\n",
       "  'main',\n",
       "  'stem',\n",
       "  'bronchial',\n",
       "  'stent',\n",
       "  'placement',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '2', '.', 'Hypertension', '.', '[SEP]'],\n",
       " ['[CLS]', '3', '.', 'Hypothyroidism', '.', '[SEP]'],\n",
       " ['[CLS]', '4', '.', 'Restrictive', 'lung', 'defect', '.', '[SEP]'],\n",
       " ['[CLS]', '5', '.', 'Depression', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'DR',\n",
       "  '.',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Last',\n",
       "  'Name',\n",
       "  '(',\n",
       "  'STitle',\n",
       "  ')',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  ',',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'First',\n",
       "  'Name3',\n",
       "  '(',\n",
       "  'LF',\n",
       "  ')',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '12',\n",
       "  '-',\n",
       "  '207',\n",
       "  'Dictated',\n",
       "  'By',\n",
       "  ':',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Last',\n",
       "  'Name',\n",
       "  '(',\n",
       "  'NamePattern1',\n",
       "  ')',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', '1811', '*', '*', ']', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'MEDQUIST36',\n",
       "  'D',\n",
       "  ':',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '14',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '11',\n",
       "  ':',\n",
       "  '30',\n",
       "  'T',\n",
       "  ':',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  '2118',\n",
       "  '-',\n",
       "  '6',\n",
       "  '-',\n",
       "  '14',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  '11',\n",
       "  ':',\n",
       "  '33',\n",
       "  'JOB',\n",
       "  '#',\n",
       "  ':',\n",
       "  '[',\n",
       "  '*',\n",
       "  '*',\n",
       "  'Job',\n",
       "  'Number',\n",
       "  '1812',\n",
       "  '*',\n",
       "  '*',\n",
       "  ']',\n",
       "  '[SEP]']]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_text = [['He',\n",
    " 'was',\n",
    " 'admitted',\n",
    " ',',\n",
    " 'taken',\n",
    " 'to',\n",
    " 'the',\n",
    " 'operating',\n",
    " 'room',\n",
    " 'where',\n",
    " 'he',\n",
    " 'underwent',\n",
    " 'L5-S1',\n",
    " 'right',\n",
    " 'hemilaminectomy',\n",
    " 'and',\n",
    " 'discectomy',\n",
    " '.']\n",
    ", \n",
    "['Over',\n",
    " 'the',\n",
    " 'next',\n",
    " 'three',\n",
    " 'days',\n",
    " 'he',\n",
    " 'increased',\n",
    " 'his',\n",
    " 'activity',\n",
    " 'gradually',\n",
    " ',',\n",
    " 'was',\n",
    " 'able',\n",
    " 'to',\n",
    " 'do',\n",
    " 'stairs',\n",
    " 'with',\n",
    " 'Physical',\n",
    " 'Therapy',\n",
    " 'and',\n",
    " 'had',\n",
    " 'pain',\n",
    " 'which',\n",
    " 'could',\n",
    " 'be',\n",
    " 'controlled',\n",
    " 'with',\n",
    " 'oral',\n",
    " 'analgesics',\n",
    " '.'],\n",
    "\n",
    "['However', ',', 'her', 'creatinine', 'continued', 'to', 'increase', '.']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_list = [[[4, 5], [8]], [[15, 16, 17]], [[2, 3], [6,7]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5]\n",
      "=====\n",
      "['He', 'was', 'admitted', ',', '[entity]', 'taken', 'to', '[entity]', 'the', 'operating', 'room', 'where', 'he', 'underwent', 'L5-S1', 'right', 'hemilaminectomy', 'and', 'discectomy', '.']\n",
      "[8]\n",
      "=====\n",
      "['He', 'was', 'admitted', ',', '[entity]', 'taken', 'to', '[entity]', '[entity]', 'the', '[entity]', 'operating', 'room', 'where', 'he', 'underwent', 'L5-S1', 'right', 'hemilaminectomy', 'and', 'discectomy', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence, problem_index in zip(clinical_text, problem_list):\n",
    "    # print(sentence)\n",
    "    if problem_index:\n",
    "        for i_list in problem_index:\n",
    "            s = sentence\n",
    "            print(i_list)\n",
    "            print(\"=====\")\n",
    "            # print(i_list)\n",
    "            s.insert(int(i_list[-1])+1, '[entity]')\n",
    "            s.insert(int(i_list[0]), '[entity]')\n",
    "            print(s)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['He',\n",
       "  'was',\n",
       "  'admitted',\n",
       "  ',',\n",
       "  '[entity]',\n",
       "  'taken',\n",
       "  'to',\n",
       "  '[entity]',\n",
       "  '[entity]',\n",
       "  'the',\n",
       "  '[entity]',\n",
       "  'operating',\n",
       "  'room',\n",
       "  'where',\n",
       "  'he',\n",
       "  'underwent',\n",
       "  'L5-S1',\n",
       "  'right',\n",
       "  'hemilaminectomy',\n",
       "  'and',\n",
       "  'discectomy',\n",
       "  '.'],\n",
       " ['Over',\n",
       "  'the',\n",
       "  'next',\n",
       "  'three',\n",
       "  'days',\n",
       "  'he',\n",
       "  'increased',\n",
       "  'his',\n",
       "  'activity',\n",
       "  'gradually',\n",
       "  ',',\n",
       "  'was',\n",
       "  'able',\n",
       "  'to',\n",
       "  'do',\n",
       "  'stairs',\n",
       "  'with',\n",
       "  'Physical',\n",
       "  'Therapy',\n",
       "  'and',\n",
       "  'had',\n",
       "  'pain',\n",
       "  'which',\n",
       "  'could',\n",
       "  'be',\n",
       "  'controlled',\n",
       "  'with',\n",
       "  'oral',\n",
       "  'analgesics',\n",
       "  '.'],\n",
       " ['However', ',', 'her', 'creatinine', 'continued', 'to', 'increase', '.']]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_tags = [['O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'B-treatment',\n",
    " 'I-treatment',\n",
    " 'I-treatment',\n",
    " 'O',\n",
    " 'B-treatment',\n",
    " 'O'],\n",
    "                 \n",
    " ['O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'B-treatment',\n",
    " 'I-treatment',\n",
    " 'O',\n",
    " 'O',\n",
    " 'B-problem',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'O',\n",
    " 'B-treatment',\n",
    " 'I-treatment',\n",
    " 'O'],\n",
    " \n",
    " ['O', 'O', 'B-test', 'I-test', 'O', 'O', 'O', 'O']                \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_input_ids, query_input_tags, query_attention_masks = process_data(clinical_text, clinical_tags, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_inputs = torch.tensor(query_input_ids)\n",
    "query_tags = torch.tensor(query_input_tags)\n",
    "query_masks = torch.tensor(query_attention_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(input_ids, label_ids, input_mask):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, token_type_ids=None,\n",
    "        attention_mask=input_mask)\n",
    "        # For eval mode, the first result of outputs is logits\n",
    "        logits = outputs[0] \n",
    "    # Get NER predict result\n",
    "    logits = torch.argmax(F.log_softmax(logits, dim=2), dim=2)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    # Get NER true result\n",
    "    label_ids = label_ids.to('cpu').numpy()\n",
    "    # Only predict the real word, mark=0, will not calculate\n",
    "    input_mask = input_mask.to('cpu').numpy()\n",
    "    # Compare the valuable predict result\n",
    "    for i, mask in enumerate(input_mask):\n",
    "        # Real one\n",
    "        temp_1 = []\n",
    "        # Predict one\n",
    "        temp_2 = []\n",
    "        for j, m in enumerate(mask):\n",
    "            # Mark=0, meaning its a pad word, dont compare\n",
    "            if m:\n",
    "                if tag2name[label_ids[i][j]] != \"X\" and tag2name[label_ids[i][j]] != \"[CLS]\" and tag2name[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n",
    "                    # print(tag2name[logits[i][j]])\n",
    "                    temp_1.append(tag2name[label_ids[i][j]])\n",
    "                    temp_2.append(tag2name[logits[i][j]])\n",
    "            else:\n",
    "                break\n",
    "        y_true.append(temp_1)\n",
    "        y_pred.append(temp_2)\n",
    "\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = model_evaluation(query_inputs, query_tags, query_masks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, digits=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     problem     1.0000    1.0000    1.0000         1\n",
      "        test     1.0000    1.0000    1.0000         1\n",
      "   treatment     1.0000    1.0000    1.0000         4\n",
      "\n",
      "   micro avg     1.0000    1.0000    1.0000         6\n",
      "   macro avg     1.0000    1.0000    1.0000         6\n",
      "weighted avg     1.0000    1.0000    1.0000         6\n",
      "\n",
      "f1 socre: 1.000000\n",
      "Accuracy score: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Get acc , recall, F1 result report\n",
    "report = classification_report(y_true, y_pred, digits=4)\n",
    "\n",
    "# Save the report into file\n",
    "output_eval_file = \"eval_results.txt\"\n",
    "\n",
    "with open(output_eval_file, \"w\") as writer:\n",
    "    print(\"***** Eval results *****\")\n",
    "    print(\"\\n%s\"%(report))\n",
    "    print(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\n",
    "    print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
    "    \n",
    "    writer.write(\"f1 socre:\\n\")\n",
    "    writer.write(str(f1_score(y_true, y_pred)))\n",
    "    writer.write(\"\\n\\nAccuracy score:\\n\")\n",
    "    writer.write(str(accuracy_score(y_true, y_pred)))\n",
    "    writer.write(\"\\n\\n\")  \n",
    "    writer.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['              precision    recall  f1-score   support',\n",
       " '',\n",
       " '     problem     1.0000    1.0000    1.0000         1',\n",
       " '        test     1.0000    1.0000    1.0000         1',\n",
       " '   treatment     1.0000    1.0000    1.0000         4',\n",
       " '',\n",
       " '   micro avg     1.0000    1.0000    1.0000         6',\n",
       " '   macro avg     1.0000    1.0000    1.0000         6',\n",
       " 'weighted avg     1.0000    1.0000    1.0000         6',\n",
       " '']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(bert_out_address, num_labels=len(tag2idx))\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_out_address, do_lower_case=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = ' '.join(test_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Over the next three days he increased his activity gradually , was able to do stairs with Physical Therapy and had pain which could be controlled with oral analgesics .'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = []\n",
    "temp_token = []\n",
    "temp_token.append('[CLS]')\n",
    "token_list = tokenizer.tokenize(test_query)\n",
    "temp_token.extend(token_list)\n",
    "temp_token = temp_token[:max_len-1]\n",
    "temp_token.append('[SEP]')\n",
    "input_id = tokenizer.convert_tokens_to_ids(temp_token)\n",
    "padding_len = max_len - len(input_id)\n",
    "input_id = input_id + ([0] * padding_len)\n",
    "tokenized_texts = []\n",
    "tokenized_texts.append(input_id)\n",
    "attention_masks = [[int(i>0) for i in input_id]]\n",
    "\n",
    "tokenized_texts = torch.tensor(tokenized_texts)\n",
    "attention_masks = torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set save model to Evalue loop\n",
    "model.eval()\n",
    "# Get model predict result\n",
    "with torch.no_grad():\n",
    "        outputs = model(tokenized_texts, token_type_ids=None,\n",
    "        attention_mask=None,)\n",
    "        # For eval mode, the first result of outputs is logits\n",
    "        logits = outputs[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_results = logits.detach().cpu().numpy()\n",
    "result_arrays_soft = softmax(predict_results[0])\n",
    "result_list = np.argmax(result_arrays_soft,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [tag2name[t] for t in result_list]\n",
    "pretok_sent = \"\"\n",
    "pretags = \"\"\n",
    "for i, tok in enumerate(temp_token):\n",
    "     if tok.startswith(\"##\"):\n",
    "         pretok_sent += tok[2:]\n",
    "     else:\n",
    "         pretok_sent += \" \" + tok\n",
    "         pretags += \" \" + result[i]\n",
    "pretok_sent = pretok_sent[1:]\n",
    "pretags = pretags[1:]\n",
    "\n",
    "s = pretok_sent.split()\n",
    "t = pretags.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:[CLS]\n",
      "Predict_Tag:[CLS]\n",
      "\n",
      "Token:Over\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:the\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:next\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:three\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:days\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:he\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:increased\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:his\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:activity\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:gradually\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:,\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:was\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:able\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:to\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:do\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:stairs\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:with\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:Physical\n",
      "Predict_Tag:B-treatment\n",
      "\n",
      "Token:Therapy\n",
      "Predict_Tag:I-treatment\n",
      "\n",
      "Token:and\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:had\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:pain\n",
      "Predict_Tag:B-problem\n",
      "\n",
      "Token:which\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:could\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:be\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:controlled\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:with\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:oral\n",
      "Predict_Tag:B-treatment\n",
      "\n",
      "Token:anal\n",
      "Predict_Tag:I-treatment\n",
      "\n",
      "Token:##ges\n",
      "Predict_Tag:X\n",
      "\n",
      "Token:##ics\n",
      "Predict_Tag:X\n",
      "\n",
      "Token:.\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:[SEP]\n",
      "Predict_Tag:[SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, mark in enumerate(attention_masks[0]):\n",
    "    if mark>0:\n",
    "        print(\"Token:%s\"%(temp_token[i]))\n",
    "#         print(\"Tag:%s\"%(result_list[i]))\n",
    "        print(\"Predict_Tag:%s\"%(tag2name[result_list[i]]))\n",
    "        #print(\"Posibility:%f\"%(result_array[i][result_list[i]]))\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(temp_token)\n",
    "re = ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "from docx.enum.text import WD_COLOR_INDEX\n",
    "# Create an instance of a word document\n",
    "doc = docx.Document()\n",
    "\n",
    "# Add a Title to the document \n",
    "doc.add_heading('Results', 0)\n",
    "\n",
    "# Creating paragraph with some content\n",
    "para = doc.add_paragraph(''' ''')\n",
    "  \n",
    "flag_treatment, flag_problem, flag_test = 0, 0, 0 \n",
    "for i in range(1, len(t)-1):\n",
    "    if t[i] == 'B-treatment':\n",
    "        flag_treatment = 1\n",
    "        para.add_run(s[i]+' ').font.highlight_color = WD_COLOR_INDEX.RED\n",
    "        # print(print_treatment(s[i]), end=' ')\n",
    "    elif (t[i] == 'I-treatment' or t[i] == 'X') and flag_treatment == 1 :\n",
    "        para.add_run(s[i]+' ').font.highlight_color = WD_COLOR_INDEX.RED\n",
    "    elif t[i] == 'B-test':\n",
    "        flag_test = 1\n",
    "        para.add_run(s[i]+' ').font.highlight_color = WD_COLOR_INDEX.PINK\n",
    "    elif (t[i] == 'I-test' or t[i] == 'X') and flag_test == 1 :\n",
    "        para.add_run(s[i]+' ').font.highlight_color = WD_COLOR_INDEX.PINK\n",
    "    elif t[i] == 'B-problem':\n",
    "        flag_problem = 1\n",
    "        para.add_run(s[i]+' ').font.highlight_color = WD_COLOR_INDEX.TURQUOISE\n",
    "    elif (t[i] == 'I-problem' or t[i] == 'X') and flag_problem == 1 :\n",
    "        para.add_run(s[i]+' ').font.highlight_color = WD_COLOR_INDEX.TURQUOISE    \n",
    "    elif t[i] == 'O':\n",
    "        flag_treatment, flag_problem, flag_test = 0, 0, 0 \n",
    "        para.add_run(s[i]+' ').font.highlight_color = WD_COLOR_INDEX.AUTO\n",
    "        \n",
    "\n",
    "# # Adding more content to paragraph and highlighting them\n",
    "# para.add_run(''' It contains well written, well thought and well-explained '''\n",
    "#             ).font.highlight_color = WD_COLOR_INDEX.YELLOW\n",
    "  \n",
    "# # Adding more content to paragraph\n",
    "# para.add_run('''computer science and programming articles, quizzes etc.''')\n",
    "  \n",
    "# Now save the document to a location \n",
    "doc.save('result.docx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "def print_treatment(word):\n",
    "    return colored(word,'white','on_red', attrs=['underline'])\n",
    "def print_test(word):\n",
    "    return colored(word, 'white','on_magenta')\n",
    "def print_problem(word):\n",
    "    return colored(word, 'magenta','on_cyan', attrs=['reverse', 'bold'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[7m\u001b[46m\u001b[35mproblem\u001b[0m\n",
      "\u001b[4m\u001b[41m\u001b[37mtreatment\u001b[0m\n",
      "\u001b[45m\u001b[37mtest\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(print_problem('problem'))\n",
    "print(print_treatment('treatment'))\n",
    "print(print_test('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the next three days he increased his activity gradually , was able to do stairs with \u001b[4m\u001b[41m\u001b[37mPhysical\u001b[0m \u001b[4m\u001b[41m\u001b[37mTherapy\u001b[0m and had \u001b[1m\u001b[7m\u001b[46m\u001b[35mpain\u001b[0m which could be controlled with \u001b[4m\u001b[41m\u001b[37moral\u001b[0m \u001b[4m\u001b[41m\u001b[37manalgesics\u001b[0m . "
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "location = {}\n",
    "flag_treatment, flag_problem, flag_test = 0, 0, 0 \n",
    "for i in range(1, len(t)-1):\n",
    "    if t[i] == 'B-treatment':\n",
    "        flag_treatment = 1\n",
    "        print(print_treatment(s[i]), end=' ')\n",
    "    elif (t[i] == 'I-treatment' or t[i] == 'X') and flag_treatment == 1 :\n",
    "        print(print_treatment(s[i]), end=' ')\n",
    "    elif t[i] == 'B-test':\n",
    "        flag_test = 1\n",
    "        print(print_test(s[i]), end=' ')\n",
    "    elif (t[i] == 'I-test' or t[i] == 'X') and flag_test == 1 :\n",
    "        print(print_test(s[i]), end=' ')\n",
    "    elif t[i] == 'B-problem':\n",
    "        flag_problem = 1\n",
    "        print(print_problem(s[i]), end=' ')\n",
    "    elif (t[i] == 'I-problem' or t[i] == 'X') and flag_problem == 1 :\n",
    "        print(print_problem(s[i]), end=' ')    \n",
    "    elif t[i] == 'O':\n",
    "        flag_treatment, flag_problem, flag_test = 0, 0, 0 \n",
    "        print(s[i], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_lable = []\n",
    "temp_token = []\n",
    "\n",
    "# Add [CLS] at the front \n",
    "temp_lable.append('[CLS]')\n",
    "temp_token.append('[CLS]')\n",
    "\n",
    "# Tokenize words\n",
    "# [lidocaine patch] -> lid ##oc ##aine patch\n",
    "# [B-treatment I-treatment] -> B-treatment X X I-treatment\n",
    "for word, lab in zip(word_list, label):\n",
    "    token_list = tokenizer.tokenize(word)\n",
    "    for m, token in enumerate(token_list):\n",
    "        temp_token.append(token)\n",
    "        if m == 0:\n",
    "            temp_lable.append(lab)\n",
    "        else:\n",
    "            temp_lable.append('X')  \n",
    "            \n",
    "# Add [SEP] at the end\n",
    "temp_lable.append('[SEP]')\n",
    "temp_token.append('[SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object) :\n",
    "    \"\"\"\n",
    "    input a dataframe\n",
    "    \n",
    "    \n",
    "    Generate sets of words and tags.\n",
    "    self.sentence:\n",
    "    Each sentence is a list\n",
    "    [('Supraventricular', 'B-problem'),\n",
    "    ('tachycardia', 'I-problem'),\n",
    "    ('(', 'O'),\n",
    "    ('on', 'O'),\n",
    "    ('a', 'B-treatment'),\n",
    "    ('beta', 'I-treatment'),\n",
    "    ('blocker', 'I-treatment'),\n",
    "    (')', 'O')]\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"].values.tolist(),\n",
    "                                                        #    s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def get_examples(self):\n",
    "        return random.sample(self.sentences, 10)\n",
    "    \n",
    "    def get_sentences(self):\n",
    "        return[[s[0] for s in sent] for sent in self.sentences]\n",
    "        \n",
    "    def get_labels(self):\n",
    "        return [[s[1] for s in sent] for sent in self.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputGenerater(object):\n",
    "    def __init__(self, sentences, labels) -> None:\n",
    "        self.tokenized_texts = []\n",
    "        self.word_piece_labels = []\n",
    "        i_inc = 0\n",
    "        for word_list,label in (zip(sentences,labels)):\n",
    "            temp_lable = []\n",
    "            temp_token = []\n",
    "            \n",
    "            # Add [CLS] at the front \n",
    "            temp_lable.append('[CLS]')\n",
    "            temp_token.append('[CLS]')\n",
    "            \n",
    "            for word,lab in zip(word_list,label):\n",
    "                token_list = tokenizer.tokenize(word)\n",
    "                for m,token in enumerate(token_list):\n",
    "                    temp_token.append(token)\n",
    "                    if m==0:\n",
    "                        temp_lable.append(lab)\n",
    "                    else:\n",
    "                        temp_lable.append('X')  \n",
    "                        \n",
    "            # Add [SEP] at the end\n",
    "            temp_lable.append('[SEP]')\n",
    "            temp_token.append('[SEP]')\n",
    "            \n",
    "            self.tokenized_texts.append(temp_token)\n",
    "            self.word_piece_labels.append(temp_lable)\n",
    "            \n",
    "            if 5 > i_inc:\n",
    "                print(\"No.%d,len:%d\"%(i_inc,len(temp_token)))\n",
    "                print(\"texts:%s\"%(\" \".join(temp_token)))\n",
    "                print(\"No.%d,len:%d\"%(i_inc,len(temp_lable)))\n",
    "                print(\"lables:%s\"%(\" \".join(temp_lable)))\n",
    "            i_inc +=1\n",
    "            \n",
    "        self.input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in self.tokenized_texts],\n",
    "                    maxlen=config.MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "            \n",
    "    def get_input_ids(self):    \n",
    "        return self.input_ids\n",
    "    \n",
    "    def get_tags(self):\n",
    "        tags = pad_sequences([[get_tag2idx().get(l) for l in lab] for lab in self.word_piece_labels],\n",
    "                        maxlen=config.MAX_LEN, value=get_tag2idx()[\"O\"], padding=\"post\",\n",
    "                        dtype=\"long\", truncating=\"post\")\n",
    "        return tags\n",
    "    def get_attention_masks(self):\n",
    "        attention_masks = [[int(i>0) for i in ii] for ii in self.input_ids]\n",
    "        return attention_masks\n",
    "    def get_segment_ids(self):\n",
    "        segment_ids = [[0] * len(input_id) for input_id in self.input_ids]\n",
    "        return segment_ids\n",
    "\n",
    "\n",
    "def convert_to_tensor(*inputs, drop_last=False):\n",
    "    data = TensorDataset(*tuple(torch.tensor(inputs)))\n",
    "    data_sampler = RandomSampler(data)\n",
    "    # Drop last can make batch training better for the last one\n",
    "    dataloader = DataLoader(data, sampler=data_sampler, batch_size=config.BATCH_NUM, drop_last=drop_last)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.0,len:5\n",
      "texts:[CLS] admission date : [SEP]\n",
      "No.0,len:5\n",
      "lables:[CLS] O O O [SEP]\n",
      "No.1,len:7\n",
      "texts:[CLS] 2014 - 12 - 29 [SEP]\n",
      "No.1,len:7\n",
      "lables:[CLS] O X X X X [SEP]\n",
      "No.2,len:6\n",
      "texts:[CLS] all ##er ##gies : [SEP]\n",
      "No.2,len:6\n",
      "lables:[CLS] O X X O [SEP]\n",
      "No.3,len:4\n",
      "texts:[CLS] 17 units [SEP]\n",
      "No.3,len:4\n",
      "lables:[CLS] O O [SEP]\n",
      "No.4,len:22\n",
      "texts:[CLS] includes a history of at ##rial fi ##bri ##lla ##tion with good heart rate control on dig ##ox ##in . [SEP]\n",
      "No.4,len:22\n",
      "lables:[CLS] O O O O B-problem X I-problem X X X O O B-treatment I-treatment I-treatment O B-treatment X X O [SEP]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pad_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b054d79cb97e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputGenerater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-dec2e08486b9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, labels)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mi_inc\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         self.input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in self.tokenized_texts],\n\u001b[0m\u001b[1;32m     38\u001b[0m                     maxlen=config.MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pad_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(config.data_path_test, sep=\"\\t\").astype(str)\n",
    "sg = SentenceGetter(df_test)\n",
    "sentences = sg.get_sentences()\n",
    "tags = sg.get_labels()\n",
    "test_sets = InputGenerater(sentences=sentences, labels=tags)\n",
    "\n",
    "test_inputs = test_sets.get_input_ids()\n",
    "test_tags = test_sets.get_tags()\n",
    "test_attetion_masks = test_sets.get_attention_masks()\n",
    "\n",
    "test_dataloader = utils.convert_to_tensor(test_inputs, test_attetion_masks, test_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = glob.glob('processed/test/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0289.tsv',\n",
       " '0090.tsv',\n",
       " '0246.tsv',\n",
       " '0390.tsv',\n",
       " '0365.tsv',\n",
       " '0174.tsv',\n",
       " '0282.tsv',\n",
       " '0305.tsv',\n",
       " '0150.tsv',\n",
       " '0101.tsv',\n",
       " '0086.tsv',\n",
       " '0357.tsv',\n",
       " '0230.tsv',\n",
       " '0294.tsv',\n",
       " '0377.tsv',\n",
       " '0266.tsv',\n",
       " '0050.tsv',\n",
       " '0026.tsv',\n",
       " '0049.tsv',\n",
       " '0029.tsv',\n",
       " '0005.tsv',\n",
       " '0081.tsv',\n",
       " '0466.tsv',\n",
       " '0245.tsv',\n",
       " '0378.tsv',\n",
       " '0463.tsv',\n",
       " '0445.tsv',\n",
       " '0053.tsv',\n",
       " '0477.tsv',\n",
       " '0461.tsv',\n",
       " '0362.tsv',\n",
       " '0473.tsv',\n",
       " '0309.tsv',\n",
       " '0415.tsv',\n",
       " '0222.tsv',\n",
       " '0329.tsv',\n",
       " '0474.tsv',\n",
       " '0393.tsv',\n",
       " '0345.tsv',\n",
       " '0109.tsv',\n",
       " '0129.tsv',\n",
       " '0454.tsv',\n",
       " '0366.tsv',\n",
       " '0082.tsv',\n",
       " '0439.tsv',\n",
       " '0173.tsv',\n",
       " '0094.tsv',\n",
       " '0025.tsv',\n",
       " '0270.tsv',\n",
       " '0133.tsv',\n",
       " '0261.tsv',\n",
       " '0153.tsv',\n",
       " '0237.tsv',\n",
       " '0074.tsv',\n",
       " '0046.tsv',\n",
       " '0066.tsv',\n",
       " '0037.tsv',\n",
       " '0338.tsv',\n",
       " '0285.tsv',\n",
       " '0425.tsv',\n",
       " '0322.tsv',\n",
       " '0385.tsv',\n",
       " '0446.tsv',\n",
       " '0141.tsv',\n",
       " '0138.tsv',\n",
       " '0121.tsv',\n",
       " '0421.tsv',\n",
       " '0389.tsv',\n",
       " '0186.tsv',\n",
       " '0233.tsv',\n",
       " '0134.tsv',\n",
       " '0054.tsv',\n",
       " '0013.tsv',\n",
       " '0190.tsv',\n",
       " '0185.tsv',\n",
       " '0409.tsv',\n",
       " '0205.tsv',\n",
       " '0442.tsv',\n",
       " '0433.tsv',\n",
       " '0321.tsv',\n",
       " '0374.tsv',\n",
       " '0342.tsv',\n",
       " '0465.tsv',\n",
       " '0009.tsv',\n",
       " '0229.tsv',\n",
       " '0437.tsv',\n",
       " '0427.tsv',\n",
       " '0318.tsv',\n",
       " '0073.tsv',\n",
       " '0214.tsv',\n",
       " '0431.tsv',\n",
       " '0333.tsv',\n",
       " '0405.tsv',\n",
       " '0457.tsv',\n",
       " '0310.tsv',\n",
       " '0460.tsv',\n",
       " '0146.tsv',\n",
       " '0041.tsv',\n",
       " '0234.tsv',\n",
       " '0193.tsv',\n",
       " '0269.tsv',\n",
       " '0102.tsv',\n",
       " '0349.tsv',\n",
       " '0301.tsv',\n",
       " '0394.tsv',\n",
       " '0386.tsv',\n",
       " '0238.tsv',\n",
       " '0157.tsv',\n",
       " '0061.tsv',\n",
       " '0428.tsv',\n",
       " '0117.tsv',\n",
       " '0078.tsv',\n",
       " '0262.tsv',\n",
       " '0464.tsv',\n",
       " '0468.tsv',\n",
       " '0249.tsv',\n",
       " '0265.tsv',\n",
       " '0470.tsv',\n",
       " '0225.tsv',\n",
       " '0369.tsv',\n",
       " '0302.tsv',\n",
       " '0058.tsv',\n",
       " '0105.tsv',\n",
       " '0197.tsv',\n",
       " '0118.tsv',\n",
       " '0217.tsv',\n",
       " '0346.tsv',\n",
       " '0209.tsv',\n",
       " '0113.tsv',\n",
       " '0242.tsv',\n",
       " '0142.tsv',\n",
       " '0410.tsv',\n",
       " '0449.tsv',\n",
       " '0034.tsv',\n",
       " '0475.tsv',\n",
       " '0354.tsv',\n",
       " '0382.tsv',\n",
       " '0337.tsv',\n",
       " '0436.tsv',\n",
       " '0169.tsv',\n",
       " '0430.tsv',\n",
       " '0448.tsv',\n",
       " '0154.tsv',\n",
       " '0202.tsv',\n",
       " '0093.tsv',\n",
       " '0070.tsv',\n",
       " '0210.tsv',\n",
       " '0341.tsv',\n",
       " '0325.tsv',\n",
       " '0440.tsv',\n",
       " '0401.tsv',\n",
       " '0194.tsv',\n",
       " '0434.tsv',\n",
       " '0182.tsv',\n",
       " '0181.tsv',\n",
       " '0398.tsv',\n",
       " '0122.tsv',\n",
       " '0033.tsv',\n",
       " '0002.tsv',\n",
       " '0277.tsv',\n",
       " '0257.tsv',\n",
       " '0361.tsv',\n",
       " '0038.tsv',\n",
       " '0014.tsv',\n",
       " '0158.tsv',\n",
       " '0198.tsv',\n",
       " '0290.tsv',\n",
       " '0418.tsv',\n",
       " '0467.tsv',\n",
       " '0201.tsv',\n",
       " '0334.tsv',\n",
       " '0057.tsv',\n",
       " '0126.tsv',\n",
       " '0443.tsv',\n",
       " '0042.tsv',\n",
       " '0098.tsv',\n",
       " '0451.tsv',\n",
       " '0177.tsv',\n",
       " '0125.tsv',\n",
       " '0189.tsv',\n",
       " '0476.tsv',\n",
       " '0018.tsv',\n",
       " '0472.tsv',\n",
       " '0166.tsv',\n",
       " '0001.tsv',\n",
       " '0022.tsv',\n",
       " '0462.tsv',\n",
       " '0298.tsv',\n",
       " '0258.tsv',\n",
       " '0254.tsv',\n",
       " '0370.tsv',\n",
       " '0458.tsv',\n",
       " '0030.tsv',\n",
       " '0062.tsv',\n",
       " '0213.tsv',\n",
       " '0422.tsv',\n",
       " '0170.tsv',\n",
       " '0226.tsv',\n",
       " '0162.tsv',\n",
       " '0416.tsv',\n",
       " '0278.tsv',\n",
       " '0273.tsv',\n",
       " '0306.tsv',\n",
       " '0419.tsv',\n",
       " '0314.tsv',\n",
       " '0297.tsv',\n",
       " '0381.tsv',\n",
       " '0161.tsv',\n",
       " '0085.tsv',\n",
       " '0069.tsv',\n",
       " '0250.tsv',\n",
       " '0350.tsv',\n",
       " '0281.tsv',\n",
       " '0317.tsv',\n",
       " '0130.tsv',\n",
       " '0218.tsv',\n",
       " '0110.tsv',\n",
       " '0241.tsv',\n",
       " '0413.tsv',\n",
       " '0424.tsv',\n",
       " '0330.tsv',\n",
       " '0326.tsv',\n",
       " '0402.tsv',\n",
       " '0397.tsv',\n",
       " '0178.tsv',\n",
       " '0114.tsv',\n",
       " '0358.tsv',\n",
       " '0045.tsv',\n",
       " '0286.tsv',\n",
       " '0137.tsv',\n",
       " '0006.tsv',\n",
       " '0106.tsv',\n",
       " '0373.tsv',\n",
       " '0471.tsv',\n",
       " '0149.tsv',\n",
       " '0452.tsv',\n",
       " '0145.tsv',\n",
       " '0274.tsv',\n",
       " '0406.tsv',\n",
       " '0021.tsv',\n",
       " '0253.tsv',\n",
       " '0065.tsv',\n",
       " '0206.tsv',\n",
       " '0455.tsv',\n",
       " '0221.tsv',\n",
       " '0097.tsv',\n",
       " '0077.tsv',\n",
       " '0469.tsv',\n",
       " '0412.tsv',\n",
       " '0089.tsv',\n",
       " '0017.tsv',\n",
       " '0353.tsv',\n",
       " '0293.tsv',\n",
       " '0313.tsv',\n",
       " '0010.tsv',\n",
       " '0165.tsv']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(config.INDIVIDUAL_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 socre:\n",
      "1.0\n",
      "\n",
      "Accuracy score:\n",
      "1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     problem     1.0000    1.0000    1.0000         1\n",
      "        test     1.0000    1.0000    1.0000         1\n",
      "   treatment     1.0000    1.0000    1.0000         4\n",
      "\n",
      "   micro avg     1.0000    1.0000    1.0000         6\n",
      "   macro avg     1.0000    1.0000    1.0000         6\n",
      "weighted avg     1.0000    1.0000    1.0000         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"eval_results.txt\", \"r\")\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 2.7.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
