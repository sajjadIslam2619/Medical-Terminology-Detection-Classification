{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0e69fd80-6684-4cac-b87c-2a2b2287bdee",
   "metadata": {},
   "source": [
    "# Load 'Assertion Model' from directory and evaluate the model. \n",
    "# Input of the model will be the output of NER model. NER model extracts the entity from sentence. \n",
    "# Enclose the entity with [entity] tag. One example is shown here. This model takes imput in as a sentecne list.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d8ebb7-e248-4b42-a726-f539422d20f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from seqeval) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from seqeval) (1.22.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.8.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: transformers in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (4.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: sacremoses in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: filelock in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: joblib in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from sacremoses->transformers) (8.1.2)\n",
      "Requirement already satisfied: six in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb8150e0-bd70-40c9-8fbf-e55a460b6a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "from transformers import AdamW\n",
    "from transformers import AutoModelForSequenceClassification, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99824eb0-e138-4dca-9977-48030aac6ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# no of classifier: present, possible, conditional, associated_with_someone_else, hypothetical, absent\n",
    "num_labels = 6\n",
    "MODEL_CLASSES = {\n",
    "  'bert': (AutoConfig, BertForSequenceClassification, AutoTokenizer),\n",
    "}\n",
    "MODEL_ADDRESS = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES['bert']\n",
    "model_config = config_class.from_pretrained(MODEL_ADDRESS, num_labels=num_labels)\n",
    "tokenizer = tokenizer_class.from_pretrained(MODEL_ADDRESS, do_lower_case=False)\n",
    "model = model_class.from_pretrained(MODEL_ADDRESS, config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31526be5-2928-4ece-81c5-3fd4f3dcef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../trained_models/Assertion/6_label_model_oversampling/'\n",
    "model = model_class.from_pretrained(output_dir)\n",
    "tokenizer = tokenizer_class.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6707b008-1ad0-4a77-9865-232f1bed2be5",
   "metadata": {},
   "source": [
    "# Insert input as sentence in the list with [entity] tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e36f5217-1f19-4883-a73c-7ebaca8f609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['He had no [entity] cardiac murmur [entity] .']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fd3fb49-d817-4568-a9ea-5091ed19f9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/var/folders/p3/s4n39zb50rb2l96w9n054ch80000gn/T/ipykernel_7538/2377604682.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(input_ids)\n",
      "/var/folders/p3/s4n39zb50rb2l96w9n054ch80000gn/T/ipykernel_7538/2377604682.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_masks = torch.tensor(attention_masks)\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "      \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "# labels = torch.tensor(labels)\n",
    "\n",
    "input_ids = torch.tensor(input_ids)\n",
    "attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "predictions = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    result = model(input_ids, token_type_ids=None, attention_mask=attention_masks, return_dict=True)\n",
    "\n",
    "logits = result.logits\n",
    "logits = logits.detach().cpu().numpy()\n",
    "predictions.append(logits)\n",
    "\n",
    "# print('sentences: ', sentences)\n",
    "pred_labels_i = np.argmax(logits, axis=1).flatten()\n",
    "# print('Label prediction: ', pred_labels_i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "948a3ef6-639c-4876-b790-e8196724e64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He had no [entity] cardiac murmur [entity] .\n",
      "Absent\n"
     ]
    }
   ],
   "source": [
    "for index, sentence in enumerate(sentences):\n",
    "  print(sentence)\n",
    "  if pred_labels_i[index] == 0:\n",
    "    print ('Present')\n",
    "  elif pred_labels_i[index] == 1:\n",
    "    print ('Possible')\n",
    "  elif pred_labels_i[index] == 2:\n",
    "    print ('Conditional')\n",
    "  elif pred_labels_i[index] == 3:\n",
    "    print ('associated with someone else')\n",
    "  elif pred_labels_i[index] == 4:\n",
    "    print ('hypothetical')\n",
    "  elif pred_labels_i[index] == 5:\n",
    "    print ('Absent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba8596-1cc9-4f08-9951-fe5d3b7898a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "33fa62565346c5b00f7c01ac7dab8740690287f5b700f97087b1b874bc66ae30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
