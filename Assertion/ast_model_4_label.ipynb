{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23305,"status":"ok","timestamp":1652507728737,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"rhikf-Vjezzh","outputId":"10d11c18-dfb0-4464-adaf-c599e6a22129"},"outputs":[],"source":["!pip install seqeval\n","!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4941,"status":"ok","timestamp":1652507786526,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"W7-j5WcdYRdj"},"outputs":[],"source":["import os\n","import pandas as pd\n","import math\n","import numpy as np\n","from tqdm import tqdm, trange\n","from seqeval.metrics import classification_report, accuracy_score, f1_score\n","import torch\n","import torch.nn.functional as F\n","from torch.optim import Adam\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import AutoModel, AutoConfig, AutoTokenizer\n","from transformers import AdamW\n","from transformers import AutoModelForSequenceClassification, BertForSequenceClassification"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":135,"status":"ok","timestamp":1652507804354,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"StDym7jWhfJE","outputId":"7a6ca6df-5c17-4cd1-bd18-7174c54b61c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found GPU at: /device:GPU:0\n","There are 1 GPU(s) available.\n","Use the GPU: Tesla T4\n"]}],"source":["import tensorflow as tf\n","import torch\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    print('GPU device not found')\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('Use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222,"referenced_widgets":["94e276cf898e46c394b6467e455d4248","1ac8411e08ea486cb98199364167d6ff","e3d7f5c7a0c446beac2a488743b0147b","8ed1472a0725440cb582e86cfae3ab47","a5bc062ef8c346f0baab3dd0b7232c5d","182f528655364f968dd7f49804fd15f3","db4243ebbd3d45d28dbc412b03d5b5a1","ec862b54a6af41af99c21584202551f2","1d16bf3353f748db9571476de85bb70e","8831f331e58d41d59629be1618b94c02","c623ace7fb834b7cac3e617d089c1e6a","80925588703041ea87979883e66da9e9","e9a5c2bdf57f4e2ba288fc6148ff4bef","8f37e7d2c5e4419c9f9e5b0bac94f384","953010fa7e774f869cd7e9dd1852a540","0129045eeccb4964bd5eb009ce5de523","1d2cd7aac3c2425489526ed20b1abf9d","28477c7e0ace4959ad0a207108472d35","fa008467424240ebb9bf7f1863279201","00bec3be53644cf4939e4d5c971686fd","1370eb191fb74bfd977c80830936130a","7f22a262c9aa4f94af433d1049332d54","ebd14fe3a62445f5b502342b3bc83981","b3a28f7807a34885ae301f2d90a97ad0","4f32197d947c45d9a0dc137ed949f11f","3bdd5c111b9244188c772c0f9ce4751a","5d0f58dd39d84e1db6a1bee5ded3283f","2e4bc3f1e2be401fbf84f5cf04225734","44b4a626553646099966d3faf7acb99b","699c4b88d4424ddd870ae6699eea8119","8e2203eca33d41b6b537a1c47f5f6274","c869244ad42243d2b749f1ec49934e0b","f32ddf142ee24daea17e91c6e751af44"]},"executionInfo":{"elapsed":11830,"status":"ok","timestamp":1652507847847,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"la3lM8PAfit4","outputId":"66961d11-e4fa-48d0-94fb-79e31521ca8e"},"outputs":[],"source":["# no of classifier: present, possible, conditional, not-present\n","num_labels = 4\n","MODEL_CLASSES = {\n","  'bert': (AutoConfig, BertForSequenceClassification, AutoTokenizer),\n","}\n","MODEL_ADDRESS = 'emilyalsentzer/Bio_ClinicalBERT'\n","config_class, model_class, tokenizer_class = MODEL_CLASSES['bert']\n","model_config = config_class.from_pretrained(MODEL_ADDRESS, num_labels=num_labels)\n","tokenizer = tokenizer_class.from_pretrained(MODEL_ADDRESS, do_lower_case=False)\n","model = model_class.from_pretrained(MODEL_ADDRESS, config=model_config)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":108,"status":"ok","timestamp":1652507901042,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"IiQLq2MZglIk"},"outputs":[],"source":["def modify_label(label):\n","    if label == 'present':\n","        return int(0)\n","    elif label == 'possible':\n","        return int(1)\n","    elif label == 'conditional':\n","        return int(2)\n","    elif label == 'not-present':\n","        return int(3)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"executionInfo":{"elapsed":355,"status":"ok","timestamp":1652507906244,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"1aeedeDsYqdz","outputId":"5d2c2da1-dbfb-407d-d728-b7dd67059e64"},"outputs":[{"name":"stdout","output_type":"stream","text":["(6365, 3)\n"]},{"data":{"text/html":["\n","  <div id=\"df-9e32b3c1-42f4-4d7e-b249-a40d30cdef83\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1711</th>\n","      <td>1711</td>\n","      <td>Abdomen soft and [entity] non-tender [entity] .</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>5045</th>\n","      <td>5045</td>\n","      <td>No [entity] m,r,g [entity] .</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3092</th>\n","      <td>3092</td>\n","      <td>[entity] Hypotension [entity] - On the night o...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e32b3c1-42f4-4d7e-b249-a40d30cdef83')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9e32b3c1-42f4-4d7e-b249-a40d30cdef83 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9e32b3c1-42f4-4d7e-b249-a40d30cdef83');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     Unnamed: 0                                           sentence  label\n","1711       1711    Abdomen soft and [entity] non-tender [entity] .      3\n","5045       5045                       No [entity] m,r,g [entity] .      3\n","3092       3092  [entity] Hypotension [entity] - On the night o...      0"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["data_path_train_url = \"https://raw.githubusercontent.com/sajjadIslam2619/sample_files/main/processed/merged/assertion_4_label_modified_train.tsv\"\n","#data_path_train_url = 'https://raw.githubusercontent.com/sajjadIslam2619/sample_files/main/processed/merged/assertion_label_modified_train_small.tsv'\n","df_data_train = pd.read_csv(data_path_train_url, sep=\"\\t\").astype(str)\n","\n","df_data_train['label'] = df_data_train['label'].apply(modify_label)\n","\n","sentences_train = df_data_train.sentence.values\n","labels_train = df_data_train.label.values\n","#print(sentences_train[0])\n","#print(labels_train[:10])\n","print(df_data_train.shape)\n","df_data_train.sample(3)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112,"status":"ok","timestamp":1652507909574,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"5VA_1n-5hCPe","outputId":"c3e30bf4-2fc8-4c28-bb73-7a1fb2e5318d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original:  Her 05-27 CXR post procedure w/o PNX , [entity] effusion [entity] much improved , yet her 05-28 CXR worse than 05-27 with some reaccumulation of right pleural effusion .\n","Tokenized:  ['Her', '05', '-', '27', 'C', '##X', '##R', 'post', 'procedure', 'w', '/', 'o', 'P', '##N', '##X', ',', '[', 'entity', ']', 'e', '##ff', '##usion', '[', 'entity', ']', 'much', 'improved', ',', 'yet', 'her', '05', '-', '28', 'C', '##X', '##R', 'worse', 'than', '05', '-', '27', 'with', 'some', 're', '##ac', '##cum', '##ulation', 'of', 'right', 'p', '##le', '##ural', 'e', '##ff', '##usion', '.']\n","Token IDs:  [1430, 4991, 118, 1765, 140, 3190, 2069, 2112, 7791, 192, 120, 184, 153, 2249, 3190, 117, 164, 9127, 166, 174, 3101, 17268, 164, 9127, 166, 1277, 4725, 117, 1870, 1123, 4991, 118, 1743, 140, 3190, 2069, 4146, 1190, 4991, 118, 1765, 1114, 1199, 1231, 7409, 19172, 6856, 1104, 1268, 185, 1513, 12602, 174, 3101, 17268, 119]\n"]}],"source":["# Print the original sentence.\n","print('Original: ', sentences_train[0])\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(sentences_train[0]))\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_train[0])))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1735,"status":"ok","timestamp":1652507917791,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"eWY23-J0mlIN","outputId":"1b0764a4-8eae-43a5-89f7-46edab6ada20"},"outputs":[],"source":["input_ids = []\n","attention_masks = []\n","\n","for sent in sentences_train:\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels_train)\n","\n","# print('Original: ', sentences_train[0])\n","# print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":101,"status":"ok","timestamp":1652507922361,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"X_UHum0upLzO"},"outputs":[],"source":["train_dataset = TensorDataset(input_ids, attention_masks, labels)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"executionInfo":{"elapsed":227,"status":"ok","timestamp":1652507928617,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"vWNNpL0Yp6ZB","outputId":"24325eba-da9f-4e6b-c7e2-e24c037d8234"},"outputs":[{"name":"stdout","output_type":"stream","text":["(708, 3)\n"]},{"data":{"text/html":["\n","  <div id=\"df-a47d384d-ea8a-43ba-8aa8-fcdf451b0574\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>319</th>\n","      <td>319</td>\n","      <td>Psychiatry Service saw her on 6/28 and recomme...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>430</th>\n","      <td>430</td>\n","      <td>[entity] Mild swelling [entity] was noted in t...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>46</td>\n","      <td>The pt continued to have [entity] low urine ou...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a47d384d-ea8a-43ba-8aa8-fcdf451b0574')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a47d384d-ea8a-43ba-8aa8-fcdf451b0574 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a47d384d-ea8a-43ba-8aa8-fcdf451b0574');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    Unnamed: 0                                           sentence  label\n","319        319  Psychiatry Service saw her on 6/28 and recomme...      0\n","430        430  [entity] Mild swelling [entity] was noted in t...      0\n","46          46  The pt continued to have [entity] low urine ou...      0"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["data_path_dev_url = \"https://raw.githubusercontent.com/sajjadIslam2619/sample_files/main/processed/merged/assertion_4_label_modified_dev.tsv\"\n","# data_path_dev_url = 'https://raw.githubusercontent.com/sajjadIslam2619/sample_files/main/processed/merged/assertion_label_modified_test_small.tsv'\n","df_data_dev = pd.read_csv(data_path_dev_url, sep=\"\\t\").astype(str)\n","\n","df_data_dev['label'] = df_data_dev['label'].apply(modify_label)\n","\n","sentences_dev = df_data_dev.sentence.values\n","labels_dev = df_data_dev.label.values\n","#print(sentences_dev[0])\n","#print(labels_dev[:10])\n","print(df_data_dev.shape)\n","df_data_dev.sample(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234,"status":"ok","timestamp":1652507935720,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"3CNAd8L3qflq","outputId":"57aeabce-bf99-4c33-e3fa-2c4bc80aaa71"},"outputs":[],"source":["input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences_dev:\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    input_ids.append(encoded_dict['input_ids'])\n","\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels_dev)\n","\n","# print('Original: ', sentences_test[0])\n","# print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":121,"status":"ok","timestamp":1652507941558,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"_kuNjX5Fq6aB"},"outputs":[],"source":["val_dataset = TensorDataset(input_ids, attention_masks, labels)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":104,"status":"ok","timestamp":1652507944010,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"nlwiexEPrH0K"},"outputs":[],"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","batch_size = 32 \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":667,"status":"ok","timestamp":1652507948430,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"ElqkDc6OrQtJ","outputId":"161a8d04-8570-4099-8b86-31ae9c96e618"},"outputs":[],"source":["# Tell pytorch to run this model on the GPU.\n","model.cuda()"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103,"status":"ok","timestamp":1652507953184,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"fRdtF1nZrSy9","outputId":"a36c7fdc-63b7-4869-f987-ec6f2f469566"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}],"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5.\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":108,"status":"ok","timestamp":1652507957137,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"KgCsv7Torq0O"},"outputs":[],"source":["from transformers import get_linear_schedule_with_warmup\n","epochs = 4\n","total_steps = len(train_dataloader) * epochs\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":101,"status":"ok","timestamp":1652507961228,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"gRr4WfK9r5Rv"},"outputs":[],"source":["import numpy as np\n","\n","# Function to calculate the accuracy of predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":102,"status":"ok","timestamp":1652507964585,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"_HMqXjNor9ye"},"outputs":[],"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"]},{"cell_type":"markdown","metadata":{"id":"16uzF3zmhtT9"},"source":["**Model train and validation**"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":515569,"status":"ok","timestamp":1652508523783,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"u9sTXc0CsMcE","outputId":"8d331e5e-019f-4c34-e64a-0ca051900436"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Batch    40  of    199.    Elapsed: 0:00:24.\n","  Batch    80  of    199.    Elapsed: 0:00:47.\n","  Batch   120  of    199.    Elapsed: 0:01:11.\n","  Batch   160  of    199.    Elapsed: 0:01:35.\n","\n","  Average training loss: 0.42\n","  Training epcoh took: 0:01:59\n","\n","Running Validation...\n","  Accuracy: 0.93\n","  Validation Loss: 0.26\n","  Validation took: 0:00:05\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    40  of    199.    Elapsed: 0:00:25.\n","  Batch    80  of    199.    Elapsed: 0:00:50.\n","  Batch   120  of    199.    Elapsed: 0:01:15.\n","  Batch   160  of    199.    Elapsed: 0:01:40.\n","\n","  Average training loss: 0.16\n","  Training epcoh took: 0:02:04\n","\n","Running Validation...\n","  Accuracy: 0.95\n","  Validation Loss: 0.21\n","  Validation took: 0:00:05\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","  Batch    40  of    199.    Elapsed: 0:00:25.\n","  Batch    80  of    199.    Elapsed: 0:00:51.\n","  Batch   120  of    199.    Elapsed: 0:01:16.\n","  Batch   160  of    199.    Elapsed: 0:01:42.\n","\n","  Average training loss: 0.10\n","  Training epcoh took: 0:02:06\n","\n","Running Validation...\n","  Accuracy: 0.95\n","  Validation Loss: 0.20\n","  Validation took: 0:00:05\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","  Batch    40  of    199.    Elapsed: 0:00:25.\n","  Batch    80  of    199.    Elapsed: 0:00:51.\n","  Batch   120  of    199.    Elapsed: 0:01:16.\n","  Batch   160  of    199.    Elapsed: 0:01:41.\n","\n","  Average training loss: 0.06\n","  Training epcoh took: 0:02:06\n","\n","Running Validation...\n","  Accuracy: 0.95\n","  Validation Loss: 0.20\n","  Validation took: 0:00:05\n","\n","Training complete!\n","Total training took 0:08:35 (h:mm:ss)\n"]}],"source":["import random\n","import numpy as np\n","\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","training_stats = []\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    t0 = time.time()\n","    total_train_loss = 0\n","\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()        \n","\n","        result = model(b_input_ids, \n","                       token_type_ids=None, \n","                       attention_mask=b_input_mask, \n","                       labels=b_labels,\n","                       return_dict=True)\n","\n","        loss = result.loss\n","        logits = result.logits\n","        total_train_loss += loss.item()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure performance on validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","    model.eval()\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        with torch.no_grad():        \n","\n","            result = model(b_input_ids, \n","                           token_type_ids=None, \n","                           attention_mask=b_input_mask,\n","                           labels=b_labels,\n","                           return_dict=True)\n","\n","        loss = result.loss\n","        logits = result.logits\n","\n","        total_eval_loss += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # predictions.append(logits)\n","        # true_labels.append(label_ids)\n","\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":111,"status":"ok","timestamp":1652508530625,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"MMczdJclvz2H","outputId":"d6bc721c-d1bb-4d59-e7d4-e6ea1297f924"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-ea484df4-b7c3-4e20-b5ac-b91930c1e599\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.42</td>\n","      <td>0.26</td>\n","      <td>0.93</td>\n","      <td>0:01:59</td>\n","      <td>0:00:05</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.16</td>\n","      <td>0.21</td>\n","      <td>0.95</td>\n","      <td>0:02:04</td>\n","      <td>0:00:05</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.10</td>\n","      <td>0.20</td>\n","      <td>0.95</td>\n","      <td>0:02:06</td>\n","      <td>0:00:05</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.06</td>\n","      <td>0.20</td>\n","      <td>0.95</td>\n","      <td>0:02:06</td>\n","      <td>0:00:05</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea484df4-b7c3-4e20-b5ac-b91930c1e599')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ea484df4-b7c3-4e20-b5ac-b91930c1e599 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ea484df4-b7c3-4e20-b5ac-b91930c1e599');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.42         0.26           0.93       0:01:59         0:00:05\n","2               0.16         0.21           0.95       0:02:04         0:00:05\n","3               0.10         0.20           0.95       0:02:06         0:00:05\n","4               0.06         0.20           0.95       0:02:06         0:00:05"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","pd.set_option('precision', 2)\n","df_stats = pd.DataFrame(data=training_stats)\n","df_stats = df_stats.set_index('epoch')\n","\n","# Display the table.\n","df_stats"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"executionInfo":{"elapsed":368,"status":"ok","timestamp":1652508540494,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"B4fxKWNvx1bT","outputId":"8326dcca-2ff0-4e68-e66b-2527c76288a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["(11118, 3)\n"]},{"data":{"text/html":["\n","  <div id=\"df-3116627d-3a55-4527-a104-2c5525eb01ba\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1864</th>\n","      <td>1864</td>\n","      <td>Pt is a 78 yo male with h/o A fib , s/p multip...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3353</th>\n","      <td>3353</td>\n","      <td>4. [entity] Paroxysmal atrial fibrillation [en...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4684</th>\n","      <td>4684</td>\n","      <td>Chief Complaint : [entity] abdominal pain [ent...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3116627d-3a55-4527-a104-2c5525eb01ba')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3116627d-3a55-4527-a104-2c5525eb01ba button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3116627d-3a55-4527-a104-2c5525eb01ba');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     Unnamed: 0                                           sentence  label\n","1864       1864  Pt is a 78 yo male with h/o A fib , s/p multip...      0\n","3353       3353  4. [entity] Paroxysmal atrial fibrillation [en...      0\n","4684       4684  Chief Complaint : [entity] abdominal pain [ent...      0"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["data_path_test_url = \"https://raw.githubusercontent.com/sajjadIslam2619/sample_files/main/processed/merged/assertion_4_label_modified_test.tsv\"\n","# data_path_test_url = 'https://raw.githubusercontent.com/sajjadIslam2619/sample_files/main/processed/merged/assertion_label_modified_dev_small.tsv'\n","df_data_test = pd.read_csv(data_path_test_url, sep=\"\\t\").astype(str)\n","\n","df_data_test['label'] = df_data_test['label'].apply(modify_label)\n","\n","sentences_test = df_data_test.sentence.values\n","labels_test = df_data_test.label.values\n","#print(sentences_test[0])\n","#print(labels_test[:10])\n","print(df_data_test.shape)\n","df_data_test.sample(3)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3414,"status":"ok","timestamp":1652508623677,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"mECbFlnSyvXT","outputId":"721058f0-ea82-4f5a-dfba-d3902f4aab93"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}],"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences_test:\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","      \n","    input_ids.append(encoded_dict['input_ids'])\n","\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels_test)\n","\n","# Print sentence 0, now as a list of IDs.\n","# print('Original: ', sentences_dev[0])\n","# print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":183,"status":"ok","timestamp":1652508627738,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"5pHXmEOdzDTV"},"outputs":[],"source":["prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":124,"status":"ok","timestamp":1652508630079,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"02CB71sCHjPn"},"outputs":[],"source":["# To calculate F1 score and accurecy and generate classification report.\n","y_true = []\n","y_pred = []\n","predictions , true_labels = [], []"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73224,"status":"ok","timestamp":1652508724446,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"VNKhBtyBz9fQ","outputId":"a56eeb38-b32b-4831-b471-fd0d688471e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicting labels for 11,118 test sentences...\n","DONE.\n"]}],"source":["# Prediction on test set\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","model.eval()\n","predictions , true_labels = [], []\n","\n","for batch in prediction_dataloader:\n","  batch = tuple(t.to(device) for t in batch)\n","  b_input_ids, b_input_mask, b_labels = batch\n","  with torch.no_grad():\n","      result = model(b_input_ids, \n","                     token_type_ids=None, \n","                     attention_mask=b_input_mask,\n","                     return_dict=True)\n","\n","  logits = result.logits\n","\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","\n","print('DONE.')"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110,"status":"ok","timestamp":1652508730343,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"iRynePqr0DQz","outputId":"398fb7db-634c-4c96-fe21-69bf16738b10"},"outputs":[{"name":"stdout","output_type":"stream","text":["Positive samples: 9203 of 11118 (82.78%)\n"]}],"source":["print('Positive samples: %d of %d (%.2f%%)' % (df_data_test.label.sum(), len(df_data_test.label), (df_data_test.label.sum() / len(df_data_test.label) * 100.0)))"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":445,"status":"ok","timestamp":1652508745449,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"gFKo3ew-1Cax","outputId":"03910512-4d7b-4fe5-9738-7a17aa3a589e"},"outputs":[{"name":"stdout","output_type":"stream","text":["f1 socre: 0.951700\n","Accuracy score: 0.951700\n","***** Eval results *****\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.9576    0.9798    0.9685      7622\n","           1     0.8137    0.7230    0.7657       574\n","           2     0.9000    0.2628    0.4068       137\n","           3     0.9614    0.9558    0.9586      2785\n","\n","    accuracy                         0.9517     11118\n","   macro avg     0.9082    0.7304    0.7749     11118\n","weighted avg     0.9504    0.9517    0.9487     11118\n","\n"]}],"source":["from sklearn.metrics import matthews_corrcoef\n","import numpy as np\n","from sklearn.metrics import f1_score,accuracy_score, classification_report\n","\n","matthews_set = []\n","# Calculating Matthews Corr. Coef. for each batch...\n","# For each input batch...\n","for i in range(len(true_labels)):\n","  pred_labels_i = np.argmax(predictions[i], axis=1).flatten() \n","  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n","  y_true.extend(true_labels[i])\n","  y_pred.extend(pred_labels_i)         \n","  matthews_set.append(matthews)\n","\n","\n","print(\"f1 socre: %f\"%(f1_score(y_true, y_pred, average='micro')))\n","print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n","report = classification_report(y_true, y_pred,digits=4)\n","print(\"***** Eval results *****\")\n","print(\"\\n%s\"%(report))"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":102,"status":"ok","timestamp":1652508773790,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"KmfXNLLM1RVp","outputId":"75860968-f9b2-47f3-f52b-8c8b961b1c8a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total MCC: 0.894\n"]}],"source":["flat_predictions = np.concatenate(predictions, axis=0)\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","flat_true_labels = np.concatenate(true_labels, axis=0)\n","mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","\n","print('Total MCC: %.3f' % mcc)"]},{"cell_type":"markdown","metadata":{"id":"djyuYuBpg6eM"},"source":["**Save model**"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1356,"status":"ok","timestamp":1652508789851,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"MHOOpG1Ag-Uj","outputId":"8e1242e1-f49e-4679-b21b-9a67610ab5ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving model to ./model_save/\n"]},{"data":{"text/plain":["('./model_save/tokenizer_config.json',\n"," './model_save/special_tokens_map.json',\n"," './model_save/vocab.txt',\n"," './model_save/added_tokens.json',\n"," './model_save/tokenizer.json')"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = './model_save/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":402,"status":"ok","timestamp":1652508794511,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"-yx3ELR8hJ7b","outputId":"d6eae30f-06b6-4c4b-c6c7-74cafde79a5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 424052K\n","-rw-r--r-- 1 root root      1K May 14 06:13 config.json\n","-rw-r--r-- 1 root root 423169K May 14 06:13 pytorch_model.bin\n","-rw-r--r-- 1 root root      1K May 14 06:13 special_tokens_map.json\n","-rw-r--r-- 1 root root      1K May 14 06:13 tokenizer_config.json\n","-rw-r--r-- 1 root root    654K May 14 06:13 tokenizer.json\n","-rw-r--r-- 1 root root    209K May 14 06:13 vocab.txt\n"]}],"source":["!ls -l --block-size=K ./model_save/"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":247,"status":"ok","timestamp":1652508806132,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"56PKHGJ9kT6T","outputId":"e5ed27ef-c3d4-457b-e3b3-4175778038e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["-rw-r--r-- 1 root root 414M May 14 06:13 ./model_save/pytorch_model.bin\n"]}],"source":["!ls -l --block-size=M ./model_save/pytorch_model.bin"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16863,"status":"ok","timestamp":1652508831058,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"G2kK4MFXkbVf","outputId":"4a478d91-d65c-4295-f35a-97ece0433061"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Mount Google Drive to this Notebook instance.\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":2084,"status":"ok","timestamp":1652508839847,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"NDROp7cLk6fJ"},"outputs":[],"source":["!cp -r ./model_save/ \"./drive/My Drive/MU/NMDSI/ast_model_save/4_label_model/\""]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":1123,"status":"ok","timestamp":1652508990747,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"Jtj5KcloltQT"},"outputs":[],"source":["# Load a trained model and vocabulary that you have fine-tuned\n","output_dir = './trained_models/4_label_model/'\n","# output_dir = './model_save/'\n","model = model_class.from_pretrained(output_dir)\n","tokenizer = tokenizer_class.from_pretrained(output_dir)\n","\n","# Copy the model to the GPU.\n","# model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"0t1dqY1BglAQ"},"source":["**Predict with model**"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":174,"status":"ok","timestamp":1652509008120,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"SeW-GTxjMoVF","outputId":"39bc8eb9-0db6-44d1-f4c6-860e4d7e6112"},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}],"source":["sentence = 'This could be due to internal hernia or could be [entity] stricture [entity] related .'\n","sentences = []\n","sentences.append(sentence)\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","      \n","    input_ids.append(encoded_dict['input_ids'])\n","\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","# labels = torch.tensor(labels)\n"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100,"status":"ok","timestamp":1652509012290,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"DD5KJwxWULSS","outputId":"e1a8f18a-b296-4645-fe16-b15169744eae"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n"]}],"source":["input_ids = torch.tensor(input_ids)\n","attention_masks = torch.tensor(attention_masks)"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":560,"status":"ok","timestamp":1652511154929,"user":{"displayName":"sajjad islam","userId":"16503418985020638021"},"user_tz":300},"id":"4MEG12tsUhAv","outputId":"e2cefa27-0a29-46fb-bee0-cb39862b4dda"},"outputs":[{"name":"stdout","output_type":"stream","text":["sentence:  This could be due to internal hernia or could be [entity] stricture [entity] related .\n","Label prediction:  [1]\n","Possible\n"]}],"source":["model.eval()\n","\n","with torch.no_grad():\n","    result = model(input_ids, token_type_ids=None, attention_mask=attention_masks, return_dict=True)\n","\n","logits = result.logits\n","logits = logits.detach().cpu().numpy()\n","predictions.append(logits)\n","\n","print('sentence: ', sentence)\n","pred_labels_i = np.argmax(logits, axis=1).flatten()\n","print('Label prediction: ', pred_labels_i) \n","\n","if pred_labels_i[0] == 0:\n","  print ('Present')\n","elif pred_labels_i[0] == 1:\n","  print ('Possible')\n","elif pred_labels_i[0] == 2:\n","  print ('Conditional')\n","elif pred_labels_i[0] == 3:\n","  print ('Not-present')\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"ast_model_4_label.ipynb","provenance":[]},"interpreter":{"hash":"33fa62565346c5b00f7c01ac7dab8740690287f5b700f97087b1b874bc66ae30"},"kernelspec":{"display_name":"Python 3.8.13 ('py_venv_nmdsi')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00bec3be53644cf4939e4d5c971686fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0129045eeccb4964bd5eb009ce5de523":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1370eb191fb74bfd977c80830936130a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"182f528655364f968dd7f49804fd15f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ac8411e08ea486cb98199364167d6ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_182f528655364f968dd7f49804fd15f3","placeholder":"","style":"IPY_MODEL_db4243ebbd3d45d28dbc412b03d5b5a1","value":"Downloading: 100%"}},"1d16bf3353f748db9571476de85bb70e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d2cd7aac3c2425489526ed20b1abf9d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28477c7e0ace4959ad0a207108472d35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e4bc3f1e2be401fbf84f5cf04225734":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bdd5c111b9244188c772c0f9ce4751a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c869244ad42243d2b749f1ec49934e0b","placeholder":"","style":"IPY_MODEL_f32ddf142ee24daea17e91c6e751af44","value":" 416M/416M [00:09&lt;00:00, 45.4MB/s]"}},"44b4a626553646099966d3faf7acb99b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f32197d947c45d9a0dc137ed949f11f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_699c4b88d4424ddd870ae6699eea8119","max":435778770,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e2203eca33d41b6b537a1c47f5f6274","value":435778770}},"5d0f58dd39d84e1db6a1bee5ded3283f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"699c4b88d4424ddd870ae6699eea8119":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f22a262c9aa4f94af433d1049332d54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80925588703041ea87979883e66da9e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9a5c2bdf57f4e2ba288fc6148ff4bef","IPY_MODEL_8f37e7d2c5e4419c9f9e5b0bac94f384","IPY_MODEL_953010fa7e774f869cd7e9dd1852a540"],"layout":"IPY_MODEL_0129045eeccb4964bd5eb009ce5de523"}},"8831f331e58d41d59629be1618b94c02":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e2203eca33d41b6b537a1c47f5f6274":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ed1472a0725440cb582e86cfae3ab47":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8831f331e58d41d59629be1618b94c02","placeholder":"","style":"IPY_MODEL_c623ace7fb834b7cac3e617d089c1e6a","value":" 385/385 [00:00&lt;00:00, 11.4kB/s]"}},"8f37e7d2c5e4419c9f9e5b0bac94f384":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa008467424240ebb9bf7f1863279201","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_00bec3be53644cf4939e4d5c971686fd","value":213450}},"94e276cf898e46c394b6467e455d4248":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ac8411e08ea486cb98199364167d6ff","IPY_MODEL_e3d7f5c7a0c446beac2a488743b0147b","IPY_MODEL_8ed1472a0725440cb582e86cfae3ab47"],"layout":"IPY_MODEL_a5bc062ef8c346f0baab3dd0b7232c5d"}},"953010fa7e774f869cd7e9dd1852a540":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1370eb191fb74bfd977c80830936130a","placeholder":"","style":"IPY_MODEL_7f22a262c9aa4f94af433d1049332d54","value":" 208k/208k [00:00&lt;00:00, 4.97MB/s]"}},"a5bc062ef8c346f0baab3dd0b7232c5d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3a28f7807a34885ae301f2d90a97ad0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e4bc3f1e2be401fbf84f5cf04225734","placeholder":"","style":"IPY_MODEL_44b4a626553646099966d3faf7acb99b","value":"Downloading: 100%"}},"c623ace7fb834b7cac3e617d089c1e6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c869244ad42243d2b749f1ec49934e0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db4243ebbd3d45d28dbc412b03d5b5a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3d7f5c7a0c446beac2a488743b0147b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec862b54a6af41af99c21584202551f2","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d16bf3353f748db9571476de85bb70e","value":385}},"e9a5c2bdf57f4e2ba288fc6148ff4bef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d2cd7aac3c2425489526ed20b1abf9d","placeholder":"","style":"IPY_MODEL_28477c7e0ace4959ad0a207108472d35","value":"Downloading: 100%"}},"ebd14fe3a62445f5b502342b3bc83981":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b3a28f7807a34885ae301f2d90a97ad0","IPY_MODEL_4f32197d947c45d9a0dc137ed949f11f","IPY_MODEL_3bdd5c111b9244188c772c0f9ce4751a"],"layout":"IPY_MODEL_5d0f58dd39d84e1db6a1bee5ded3283f"}},"ec862b54a6af41af99c21584202551f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f32ddf142ee24daea17e91c6e751af44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa008467424240ebb9bf7f1863279201":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
