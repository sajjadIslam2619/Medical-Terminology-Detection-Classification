{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assertion model load from directory and evaluate the model. Input of the model will be the output of NER model.\n",
    "# NER model extracts the entity from sentence. Enclose the entity with [entity] tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6106,
     "status": "ok",
     "timestamp": 1650230226851,
     "user": {
      "displayName": "sajjad islam",
      "userId": "16503418985020638021"
     },
     "user_tz": 300
    },
    "id": "rhikf-Vjezzh",
    "outputId": "a7aa73e6-7a84-4bb9-e53d-ddac7926f79d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from seqeval) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from seqeval) (1.22.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.1; however, version 22.2.1 is available.\n",
      "You should consider upgrading via the '/Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: transformers in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (4.18.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: filelock in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: sacremoses in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: click in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from sacremoses->transformers) (8.1.2)\n",
      "Requirement already satisfied: six in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.1; however, version 22.2.1 is available.\n",
      "You should consider upgrading via the '/Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1650232545460,
     "user": {
      "displayName": "sajjad islam",
      "userId": "16503418985020638021"
     },
     "user_tz": 300
    },
    "id": "W7-j5WcdYRdj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "from transformers import AdamW\n",
    "from transformers import AutoModelForSequenceClassification, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of classifier: present, not-present\n",
    "num_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of classifier: present, possible, not-present\n",
    "num_labels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of classifier: present, possible, conditional, not-present\n",
    "num_labels = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of classifier: present, possible, conditional, associated_with_someone_else, not-present\n",
    "num_labels = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of classifier: present, possible, conditional, associated_with_someone_else, hypothetical, absent\n",
    "num_labels = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12598,
     "status": "ok",
     "timestamp": 1650230251077,
     "user": {
      "displayName": "sajjad islam",
      "userId": "16503418985020638021"
     },
     "user_tz": 300
    },
    "id": "la3lM8PAfit4",
    "outputId": "c2164a0e-8631-4612-ff8c-6dffd18d5050"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_CLASSES = {\n",
    "  'bert': (AutoConfig, BertForSequenceClassification, AutoTokenizer),\n",
    "}\n",
    "MODEL_ADDRESS = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES['bert']\n",
    "model_config = config_class.from_pretrained(MODEL_ADDRESS, num_labels=num_labels)\n",
    "tokenizer = tokenizer_class.from_pretrained(MODEL_ADDRESS, do_lower_case=False)\n",
    "model = model_class.from_pretrained(MODEL_ADDRESS, config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "executionInfo": {
     "elapsed": 475,
     "status": "error",
     "timestamp": 1650232892722,
     "user": {
      "displayName": "sajjad islam",
      "userId": "16503418985020638021"
     },
     "user_tz": 300
    },
    "id": "Jtj5KcloltQT",
    "outputId": "9c7ae962-ffdd-470f-af70-f8fabed969f9"
   },
   "outputs": [],
   "source": [
    "output_dir = './trained_models/2_label_model/'\n",
    "model = model_class.from_pretrained(output_dir)\n",
    "tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
    "\n",
    "# Copy the model to the GPU.\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './trained_models/3_label_model/'\n",
    "model = model_class.from_pretrained(output_dir)\n",
    "tokenizer = tokenizer_class.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './trained_models/4_label_model/'\n",
    "model = model_class.from_pretrained(output_dir)\n",
    "tokenizer = tokenizer_class.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './trained_models/5_label_model/'\n",
    "model = model_class.from_pretrained(output_dir)\n",
    "tokenizer = tokenizer_class.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './trained_models/6_label_model/'\n",
    "model = model_class.from_pretrained(output_dir)\n",
    "tokenizer = tokenizer_class.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './trained_models/6_label_model_weight_balance/'\n",
    "model = model_class.from_pretrained(output_dir)\n",
    "tokenizer = tokenizer_class.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './trained_models/6_label_model_oversampling/'\n",
    "model = model_class.from_pretrained(output_dir)\n",
    "tokenizer = tokenizer_class.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0t1dqY1BglAQ"
   },
   "source": [
    "**Predict with model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['Patient has [entity] fever [entity].', 'Patient denies [entity] fever [entity].']\n",
    "\n",
    "sentences = ['Patient has fever.', 'Patient denies fever.']\n",
    "\n",
    "sentences = ['There was an initial murmur on admission likely secondary to [entity] severe anemia [entity] which has since resolved .']\n",
    "\n",
    "sentences = ['He denies a history of [entity] aspiration events [entity] or choking with food intake .']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "sentences = ['She had [entity] a functioning arteriovenous fistula [entity] with a thrill and a bruit in her left arm .', #present\n",
    "    'This could be due to internal hernia or could be [entity] stricture [entity] related .', #possible\n",
    "    'Her heart is regular without [entity] murmurs [entity] , rubs or gallops , slightly tachycardic .\t', #absent\n",
    "    'Call your doctor immediately if any new symptoms develop including fevers , [entity] rash [entity],'+\n",
    "    'increase in bloody urine in nephrostomy or urostomy bags , etc .', #hypothetical\n",
    "    'He has has [entity] stable , mild angina [entity] , subsequently , mostly in the setting of stress .', #conditional\n",
    "    'She has a son who is [entity] mentally handicapped [entity] .' #associated_with_someone_else\n",
    "    ]\n",
    "\n",
    "print(type(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read input from file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('../Data/Test_ast_model_3_label.xlsx', engine='openpyxl')\n",
    "df_test_present = pd.read_excel(xls, 'present')\n",
    "df_test_absent = pd.read_excel(xls, 'absent')\n",
    "df_test_possible = pd.read_excel(xls, 'possible')\n",
    "df_test_conditional = pd.read_excel(xls, 'conditional')\n",
    "df_test_hyphothetical = pd.read_excel(xls, 'hyphothetical')\n",
    "df_test_associated = pd.read_excel(xls, 'associated with someone else')\n",
    "\n",
    "present_list = df_test_present['Sentence'].tolist()\n",
    "absent_list = df_test_absent['Sentence'].tolist()\n",
    "possible_list = df_test_possible['Sentence'].tolist()\n",
    "conditional_list = df_test_conditional['Sentence'].tolist()\n",
    "hyphothetical_list = df_test_hyphothetical['Sentence'].tolist()\n",
    "associated_list = df_test_associated['Sentence'].tolist()\n",
    "\n",
    "sentences = conditional_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('../Data/Test_ast_model_4_label.xlsx', engine='openpyxl')\n",
    "df_test_present = pd.read_excel(xls, 'present')\n",
    "df_test_absent = pd.read_excel(xls, 'absent')\n",
    "df_test_possible = pd.read_excel(xls, 'possible')\n",
    "df_test_conditional = pd.read_excel(xls, 'conditional')\n",
    "df_test_hyphothetical = pd.read_excel(xls, 'hyphothetical')\n",
    "df_test_associated = pd.read_excel(xls, 'associated with someone else')\n",
    "\n",
    "present_list = df_test_present['Sentence'].tolist()\n",
    "absent_list = df_test_absent['Sentence'].tolist()\n",
    "possible_list = df_test_possible['Sentence'].tolist()\n",
    "conditional_list = df_test_conditional['Sentence'].tolist()\n",
    "hyphothetical_list = df_test_hyphothetical['Sentence'].tolist()\n",
    "associated_list = df_test_associated['Sentence'].tolist()\n",
    "\n",
    "sentences = associated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('../Data/Test_ast_model_5_label.xlsx', engine='openpyxl')\n",
    "df_test_present = pd.read_excel(xls, 'present')\n",
    "df_test_absent = pd.read_excel(xls, 'absent')\n",
    "df_test_possible = pd.read_excel(xls, 'possible')\n",
    "df_test_conditional = pd.read_excel(xls, 'conditional')\n",
    "df_test_hyphothetical = pd.read_excel(xls, 'hyphothetical')\n",
    "df_test_associated = pd.read_excel(xls, 'associated with someone else')\n",
    "\n",
    "present_list = df_test_present['Sentence'].tolist()\n",
    "absent_list = df_test_absent['Sentence'].tolist()\n",
    "possible_list = df_test_possible['Sentence'].tolist()\n",
    "conditional_list = df_test_conditional['Sentence'].tolist()\n",
    "hyphothetical_list = df_test_hyphothetical['Sentence'].tolist()\n",
    "associated_list = df_test_associated['Sentence'].tolist()\n",
    "\n",
    "sentences = hyphothetical_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/Test_ast_model_6_label.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p3/s4n39zb50rb2l96w9n054ch80000gn/T/ipykernel_5679/1278817341.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Data/Test_ast_model_6_label.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'openpyxl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test_present\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'present'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_test_absent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'absent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_test_possible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'possible'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_test_conditional\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conditional'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \"\"\"\n\u001b[1;32m    521\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"openpyxl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m    408\u001b[0m         )\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workbook_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m    411\u001b[0m                 \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/Test_ast_model_6_label.xlsx'"
     ]
    }
   ],
   "source": [
    "xls = pd.ExcelFile('../Data/Test_ast_model_6_label.xlsx', engine='openpyxl')\n",
    "df_test_present = pd.read_excel(xls, 'present')\n",
    "df_test_absent = pd.read_excel(xls, 'absent')\n",
    "df_test_possible = pd.read_excel(xls, 'possible')\n",
    "df_test_conditional = pd.read_excel(xls, 'conditional')\n",
    "df_test_hyphothetical = pd.read_excel(xls, 'hyphothetical')\n",
    "df_test_associated = pd.read_excel(xls, 'associated with someone else')\n",
    "\n",
    "present_list = df_test_present['Sentence'].tolist()\n",
    "absent_list = df_test_absent['Sentence'].tolist()\n",
    "possible_list = df_test_possible['Sentence'].tolist()\n",
    "conditional_list = df_test_conditional['Sentence'].tolist()\n",
    "hyphothetical_list = df_test_hyphothetical['Sentence'].tolist()\n",
    "associated_list = df_test_associated['Sentence'].tolist()\n",
    "\n",
    "sentences = conditional_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1650231814561,
     "user": {
      "displayName": "sajjad islam",
      "userId": "16503418985020638021"
     },
     "user_tz": 300
    },
    "id": "SeW-GTxjMoVF",
    "outputId": "20a9eec9-0d18-4391-cf5c-474fb173456f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/sajjadislam/opt/anaconda3/envs/py_venv_nmdsi/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "      \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "# labels = torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1650231820004,
     "user": {
      "displayName": "sajjad islam",
      "userId": "16503418985020638021"
     },
     "user_tz": 300
    },
    "id": "DD5KJwxWULSS",
    "outputId": "a9656fd7-251b-4d66-db5a-a1d64f7c5f61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p3/s4n39zb50rb2l96w9n054ch80000gn/T/ipykernel_6619/2464600030.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(input_ids)\n",
      "/var/folders/p3/s4n39zb50rb2l96w9n054ch80000gn/T/ipykernel_6619/2464600030.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_masks = torch.tensor(attention_masks)\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor(input_ids)\n",
    "attention_masks = torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4MEG12tsUhAv"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    result = model(input_ids, token_type_ids=None, attention_mask=attention_masks, return_dict=True)\n",
    "\n",
    "logits = result.logits\n",
    "logits = logits.detach().cpu().numpy()\n",
    "predictions.append(logits)\n",
    "\n",
    "# print('sentences: ', sentences)\n",
    "pred_labels_i = np.argmax(logits, axis=1).flatten()\n",
    "# print('Label prediction: ', pred_labels_i) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sentence in enumerate(sentences):\n",
    "  print(sentence)\n",
    "  print(pred_labels_i[index])\n",
    "  if pred_labels_i[index] == 0:\n",
    "    print ('Present')\n",
    "  elif pred_labels_i[index] == 1:\n",
    "    print ('Not-present')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('Test_output.txt', 'w')\n",
    "for index, sentence in enumerate(sentences):\n",
    "  print(sentence)\n",
    "  file.write(sentence)\n",
    "  file.write('\\n')\n",
    "  if pred_labels_i[index] == 0:\n",
    "    print ('Present')\n",
    "    file.write('Present')\n",
    "  elif pred_labels_i[index] == 1:\n",
    "    print ('Possible')\n",
    "    file.write('Possible')\n",
    "  elif pred_labels_i[index] == 2:\n",
    "    print ('Not-present')\n",
    "    file.write('Not-present')\n",
    "  file.write('\\n')\n",
    "  \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index, sentence in enumerate(sentences):\n",
    "  print(sentence)\n",
    "  if pred_labels_i[index] == 0:\n",
    "    print ('Present')\n",
    "  elif pred_labels_i[index] == 1:\n",
    "    print ('Possible')\n",
    "  elif pred_labels_i[index] == 2:\n",
    "    print ('Conditional')\n",
    "  elif pred_labels_i[index] == 3:\n",
    "    print ('Not-present')\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sentence in enumerate(sentences):\n",
    "  print(sentence)\n",
    "  if pred_labels_i[index] == 0:\n",
    "    print ('Present')\n",
    "  elif pred_labels_i[index] == 1:\n",
    "    print ('Possible')\n",
    "  elif pred_labels_i[index] == 2:\n",
    "    print ('Conditional')\n",
    "  elif pred_labels_i[index] == 3:\n",
    "    print ('associated with someone else')\n",
    "  elif pred_labels_i[index] == 4:\n",
    "    print ('Not-present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She had [entity] a functioning arteriovenous fistula [entity] with a thrill and a bruit in her left arm .\n",
      "Present\n",
      "This could be due to internal hernia or could be [entity] stricture [entity] related .\n",
      "Possible\n",
      "Her heart is regular without [entity] murmurs [entity] , rubs or gallops , slightly tachycardic .\t\n",
      "Absent\n",
      "Call your doctor immediately if any new symptoms develop including fevers , [entity] rash [entity],increase in bloody urine in nephrostomy or urostomy bags , etc .\n",
      "hypothetical\n",
      "He has has [entity] stable , mild angina [entity] , subsequently , mostly in the setting of stress .\n",
      "Present\n",
      "She has a son who is [entity] mentally handicapped [entity] .\n",
      "associated with someone else\n"
     ]
    }
   ],
   "source": [
    "for index, sentence in enumerate(sentences):\n",
    "  print(sentence)\n",
    "  if pred_labels_i[index] == 0:\n",
    "    print ('Present')\n",
    "  elif pred_labels_i[index] == 1:\n",
    "    print ('Possible')\n",
    "  elif pred_labels_i[index] == 2:\n",
    "    print ('Conditional')\n",
    "  elif pred_labels_i[index] == 3:\n",
    "    print ('associated with someone else')\n",
    "  elif pred_labels_i[index] == 4:\n",
    "    print ('hypothetical')\n",
    "  elif pred_labels_i[index] == 5:\n",
    "    print ('Absent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOm5EQlIC4X4+jo4CBS0FNF",
   "collapsed_sections": [],
   "name": "ast_model.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "33fa62565346c5b00f7c01ac7dab8740690287f5b700f97087b1b874bc66ae30"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
