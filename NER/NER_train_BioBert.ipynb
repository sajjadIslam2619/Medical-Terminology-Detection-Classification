{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,1\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: torch in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\nipua\\appdata\\local\\anaconda3\\envs\\ner_ast\\lib\\site-packages (5.28.3)\n"
     ]
    }
   ],
   "source": [
    "# required libraries\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install protobuf --upgrade\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nipua\\AppData\\Local\\anaconda3\\envs\\ner_ast\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import BertTokenizer, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_train = \"../Data/processed/merged/train.tsv\" \n",
    "train_data = pd.read_csv(data_path_train, sep=\"\\t\").astype(str)\n",
    "\n",
    "data_path_dev= \"../Data/processed/merged/dev.tsv\" \n",
    "dev_data = pd.read_csv(data_path_dev, sep=\"\\t\").astype(str)\n",
    "\n",
    "data_path_test= \"../Data/processed/merged/test.tsv\" \n",
    "test_data = pd.read_csv(data_path_test, sep=\"\\t\").astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134254, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take top 50 rows from each DataFrame\n",
    "train_data = train_data.head(500)\n",
    "dev_data = dev_data.head(500)\n",
    "test_data = test_data.head(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"].values.tolist(),\n",
    "                                                        #    s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    # def get_next(self):\n",
    "    #     try:\n",
    "    #         s = self.grouped[\"sentence: {}\".format(self.n_sent)]\n",
    "    #         self.n_sent += 1\n",
    "    #         return s\n",
    "    #     except:\n",
    "    #         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nipua\\AppData\\Local\\Temp\\ipykernel_12060\\2688801345.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  self.grouped = self.data.groupby(\"sentence #\").apply(agg_func)\n"
     ]
    }
   ],
   "source": [
    "# Get full document data struce\n",
    "train_getter = SentenceGetter(train_data)\n",
    "# Get sentence data\n",
    "train_sentences = [[s[0] for s in sent] for sent in train_getter.sentences]\n",
    "train_labels = [[s[1] for s in sent] for sent in train_getter.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nipua\\AppData\\Local\\Temp\\ipykernel_12060\\2688801345.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  self.grouped = self.data.groupby(\"sentence #\").apply(agg_func)\n"
     ]
    }
   ],
   "source": [
    "# Get full document data struce\n",
    "dev_getter = SentenceGetter(dev_data)\n",
    "# Get sentence data\n",
    "dev_sentences = [[s[0] for s in sent] for sent in dev_getter.sentences]\n",
    "dev_labels = [[s[1] for s in sent] for sent in dev_getter.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nipua\\AppData\\Local\\Temp\\ipykernel_12060\\2688801345.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  self.grouped = self.data.groupby(\"sentence #\").apply(agg_func)\n"
     ]
    }
   ],
   "source": [
    "# Get full document data struce\n",
    "test_getter = SentenceGetter(test_data)\n",
    "# Get sentence data\n",
    "test_sentences = [[s[0] for s in sent] for sent in test_getter.sentences]\n",
    "test_labels = [[s[1] for s in sent] for sent in test_getter.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a dict for mapping id to tag name\n",
    "#tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
    "\n",
    "# Recommend to set it by manual define, good for reusing\n",
    "tag2idx={'B-problem': 0,\n",
    " 'B-test': 1,\n",
    " 'B-treatment': 2,\n",
    " 'I-problem': 3,\n",
    " 'I-test': 4,\n",
    " 'I-treatment': 5,\n",
    " 'O': 6,\n",
    " 'X': 7,\n",
    " '[CLS]': 8,\n",
    " '[SEP]': 9\n",
    " }\n",
    "# Mapping index to name\n",
    "tag2name = {tag2idx[key]: key for key in tag2idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-problem': 0,\n",
       " 'B-test': 1,\n",
       " 'B-treatment': 2,\n",
       " 'I-problem': 3,\n",
       " 'I-test': 4,\n",
       " 'I-treatment': 5,\n",
       " 'O': 6,\n",
       " 'X': 7,\n",
       " '[CLS]': 8,\n",
       " '[SEP]': 9}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'B-problem',\n",
       " 1: 'B-test',\n",
       " 2: 'B-treatment',\n",
       " 3: 'I-problem',\n",
       " 4: 'I-test',\n",
       " 5: 'I-treatment',\n",
       " 6: 'O',\n",
       " 7: 'X',\n",
       " 8: '[CLS]',\n",
       " 9: '[SEP]'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make raw data into trainable data for BERT, including:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set gpu environment\n",
    "- Load tokenizer and tokenize\n",
    "- Set 3 embedding, token embedding, mask word embedding, segmentation embedding\n",
    "- Split data set into train and validate, then send them to dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up gpu environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the tokenizer file into local folder first :\n",
    "- [vocab.txt](https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Len of the sentence must be not bigger than the training model\n",
    "# See model's 'max_position_embeddings' = 512\n",
    "max_len  = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "# model_name = \"google-bert/bert-base-uncased\"\n",
    "model_name = \"dmis-lab/biobert-base-cased-v1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenizer text**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In hunggieface for bert, when come across OOV, will word piece the word\n",
    "- We need to adjust the labels base on the tokenize result, “##abc” need to set label \"X\" \n",
    "- Need to set \"[CLS]\" at front and \"[SEP]\" at the end, as what the paper do, [BERT indexer should add [CLS] and [SEP] tokens](https://github.com/allenai/allennlp/issues/2141)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(sentences, labels):\n",
    "    tokenized_texts = []\n",
    "    word_piece_labels = []\n",
    "    i_inc = 0\n",
    "    for word_list,label in (zip(sentences,labels)):\n",
    "        temp_lable = []\n",
    "        temp_token = []\n",
    "        \n",
    "        # # Add [CLS] at the front \n",
    "        # temp_lable.append('[CLS]')\n",
    "        # temp_token.append('[CLS]')\n",
    "        \n",
    "        for word, lab in zip(word_list,label):\n",
    "            token_list = tokenizer.tokenize(word)\n",
    "            for m,token in enumerate(token_list):\n",
    "                temp_token.append(token)\n",
    "                if m==0:\n",
    "                    temp_lable.append(lab)\n",
    "                else:\n",
    "                    temp_lable.append('X')  \n",
    "                    \n",
    "        # # Add [SEP] at the end\n",
    "        # temp_lable.append('[SEP]')\n",
    "        # temp_token.append('[SEP]')\n",
    "        \n",
    "        tokenized_texts.append(temp_token)\n",
    "        word_piece_labels.append(temp_lable)\n",
    "    \n",
    "    id_list = []\n",
    "    target_list = [] \n",
    "    attention_mask_list = []   \n",
    "        \n",
    "    # PADING        \n",
    "    for text, label in zip(tokenized_texts, word_piece_labels):\n",
    "        \n",
    "        # Add [CLS] and [SEP], \n",
    "        # Truncate seq if it is too long\n",
    "        text = ['[CLS]'] + text[:max_len-2] + ['[SEP]']\n",
    "        label = ['[CLS]'] + label[:max_len-2] + ['[SEP]']\n",
    "        \n",
    "        # convert to ids\n",
    "        ids = tokenizer.convert_tokens_to_ids(text)\n",
    "        target_tag =[tag2idx.get(t) for t in label]\n",
    "        \n",
    "        # padding \n",
    "        # Label [PAD] with O (other)\n",
    "        padding_len = max_len - len(ids)\n",
    "        ids = ids + [0] * padding_len\n",
    "        target_tag = target_tag + [tag2idx['O']] * padding_len\n",
    "        \n",
    "        # create masks\n",
    "        attention_masks = [int(i>0) for i in ids]\n",
    "        \n",
    "        id_list.append(ids)\n",
    "        target_list.append(target_tag)\n",
    "        attention_mask_list.append(attention_masks)\n",
    "    \n",
    "    return id_list, target_list, attention_mask_list\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids, train_input_tags, train_attention_masks = process_data(train_sentences, train_labels)\n",
    "dev_input_ids, dev_input_tags, dev_attention_masks = process_data(dev_sentences, dev_labels)\n",
    "test_input_ids, test_input_tags, test_attention_masks = process_data(test_sentences, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_input_ids)\n",
    "dev_inputs = torch.tensor(dev_input_ids)\n",
    "test_inputs = torch.tensor(test_input_ids)\n",
    "train_tags = torch.tensor(train_input_tags)\n",
    "dev_tags = torch.tensor(dev_input_tags)\n",
    "test_tags = torch.tensor(test_input_tags)\n",
    "train_masks = torch.tensor(train_attention_masks)\n",
    "dev_masks = torch.tensor(dev_attention_masks)\n",
    "test_masks = torch.tensor(test_attention_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put data into data loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch num\n",
    "batch_num = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only set token embedding, attention embedding, no segment embedding\n",
    "train_dataset = TensorDataset(train_inputs, train_masks, train_tags)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "# Drop last can make batch training better for the last one\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_num, drop_last=True)\n",
    "\n",
    "dev_dataset = TensorDataset(dev_inputs, dev_masks, dev_tags)\n",
    "dev_sampler = SequentialSampler(dev_dataset)\n",
    "dev_dataloader = DataLoader(dev_dataset, sampler=dev_sampler, batch_size=batch_num)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_tags)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load BERT model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this folder, contain model confg(json) and model weight(bin) files\n",
    "# pytorch_model.bin, download from: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin\n",
    "# config.json, downlaod from: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json\n",
    "model_file_address = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Will load config and weight with from_pretrained()\n",
    "#model = BertForTokenClassification.from_pretrained(model_file_address, num_labels=len(tag2idx))\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(model_file_address, num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model to GPU,if you are using GPU machine\n",
    "# model.cuda();\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add multi GPU support\n",
    "if n_gpu >1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set epoch and grad max num\n",
    "epochs = 5\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cacluate train optimiazaion num\n",
    "num_train_optimization_steps = int(math.ceil(len(train_inputs) / batch_num) / 1) * epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set fine tuning method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True: fine tuning all the layers \n",
    "# False: only fine tuning the classifier layers\n",
    "FULL_FINETUNING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer setup\n",
    "param_optimizer = list(model.named_parameters())\n",
    "if FULL_FINETUNING:\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters())\n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN loop\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 81\n",
      "  Batch size = 32\n",
      "  Num steps = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 1/5 [00:43<02:55, 43.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9677584767341614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 2/5 [01:23<02:04, 41.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.767440676689148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 3/5 [01:56<01:15, 37.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.5597438216209412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 4/5 [02:28<00:35, 35.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.367362380027771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [03:01<00:00, 36.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.1403502225875854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"***** Running training *****\")\n",
    "print(\"  Num examples = %d\"%(len(train_inputs)))\n",
    "print(\"  Batch size = %d\"%(batch_num))\n",
    "print(\"  Num steps = %d\"%(num_train_optimization_steps))\n",
    "for _ in trange(epochs,desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for batch in train_dataloader:\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss  # Loss is explicitly available in newer versions\n",
    "        scores = outputs.logits  # Access logits for predictions\n",
    "\n",
    "        if n_gpu > 1:\n",
    "            # When using multiple GPUs, average the loss\n",
    "            loss = loss.mean()\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # print train loss per epoch\n",
    "    print(f\"Train loss: {tr_loss / nb_tr_steps}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the base model name (remove any slashes or paths)\n",
    "model_base_name = model_name.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output address based on the model name\n",
    "bert_out_address = f\"../trained_models/NER/{model_base_name}-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(bert_out_address):\n",
    "    # Delete the directory and its contents\n",
    "    shutil.rmtree(bert_out_address)\n",
    "\n",
    "# Now create the directory\n",
    "os.makedirs(bert_out_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a trained model, configuration and tokenizer\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we save using the predefined names, we can load using `from_pretrained`\n",
    "output_model_file = os.path.join(bert_out_address, \"pytorch_model.bin\")\n",
    "output_config_file = os.path.join(bert_out_address, \"config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../trained_models/NER/biobert-base-cased-v1.1-test\\\\vocab.txt',)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model into file\n",
    "torch.save(model_to_save.state_dict(), output_model_file)\n",
    "model_to_save.config.to_json_file(output_config_file)\n",
    "tokenizer.save_vocabulary(bert_out_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(bert_out_address, num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model to GPU\n",
    "# model.cuda();\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_gpu >1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalue loop\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "  Num examples = 60\n",
      "  Batch size = 32\n",
      "f1 socre: 0.000000\n",
      "Accuracy score: 0.732000\n"
     ]
    }
   ],
   "source": [
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "print(\"***** Running evaluation *****\")\n",
    "print(f\"  Num examples = {len(test_inputs)}\")\n",
    "print(f\"  Batch size = {batch_num}\")\n",
    "for batch in test_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, input_mask, label_ids = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, token_type_ids=None,\n",
    "        attention_mask=input_mask,)\n",
    "        # For eval mode, the first result of outputs is logits\n",
    "        logits = outputs[0] \n",
    "\n",
    "    # Get NER predict result\n",
    "    logits = torch.argmax(F.log_softmax(logits, dim=2),dim=2)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    # Get NER true result\n",
    "    label_ids = label_ids.to('cpu').numpy()\n",
    "    # Only predict the real word, mark=0, will not calculate\n",
    "    input_mask = input_mask.to('cpu').numpy()\n",
    "    # Compare the valuable predict result\n",
    "    for i,mask in enumerate(input_mask):\n",
    "        # Real one\n",
    "        temp_1 = []\n",
    "        # Predict one\n",
    "        temp_2 = []\n",
    "\n",
    "        for j, m in enumerate(mask):\n",
    "            # Mark=0, meaning its a pad word, dont compare\n",
    "            if m:\n",
    "                if tag2name[label_ids[i][j]] not in [\"X\", \"[CLS]\", \"[SEP]\"]: # Exclude the X label\n",
    "                    # print(tag2name[logits[i][j]])\n",
    "                    temp_1.append(tag2name[label_ids[i][j]])\n",
    "                    temp_2.append(tag2name[logits[i][j]])\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        y_true.append(temp_1)\n",
    "        y_pred.append(temp_2)\n",
    "\n",
    "\n",
    "print(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\n",
    "print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nipua\\AppData\\Local\\anaconda3\\envs\\ner_ast\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\nipua\\AppData\\Local\\anaconda3\\envs\\ner_ast\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n     problem     0.0000    0.0000    0.0000        30\\n        test     0.0000    0.0000    0.0000        11\\n   treatment     0.0000    0.0000    0.0000        25\\n\\n   micro avg     0.0000    0.0000    0.0000        66\\n   macro avg     0.0000    0.0000    0.0000        66\\nweighted avg     0.0000    0.0000    0.0000        66\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_true, y_pred, digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     problem     0.0000    0.0000    0.0000        30\n",
      "        test     0.0000    0.0000    0.0000        11\n",
      "   treatment     0.0000    0.0000    0.0000        25\n",
      "\n",
      "   micro avg     0.0000    0.0000    0.0000        66\n",
      "   macro avg     0.0000    0.0000    0.0000        66\n",
      "weighted avg     0.0000    0.0000    0.0000        66\n",
      "\n",
      "f1 socre: 0.000000\n",
      "Accuracy score: 0.732000\n"
     ]
    }
   ],
   "source": [
    "# Get acc , recall, F1 result report\n",
    "report = classification_report(y_true, y_pred, digits=4)\n",
    "\n",
    "# Save the report into file\n",
    "output_eval_file = os.path.join(bert_out_address, \"eval_results.txt\")\n",
    "with open(output_eval_file, \"w\") as writer:\n",
    "    print(\"***** Eval results *****\")\n",
    "    print(\"\\n%s\"%(report))\n",
    "    print(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\n",
    "    print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
    "    \n",
    "    writer.write(\"f1 socre:\\n\")\n",
    "    writer.write(str(f1_score(y_true, y_pred)))\n",
    "    writer.write(\"\\n\\nAccuracy score:\\n\")\n",
    "    writer.write(str(accuracy_score(y_true, y_pred)))\n",
    "    writer.write(\"\\n\\n\")  \n",
    "    writer.write(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner_ast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
