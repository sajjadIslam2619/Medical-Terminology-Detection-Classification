{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertConfig, BertForTokenClassification, \\\n",
    "                            get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn import metrics\n",
    "from ner_config import *\n",
    "from ner_utils import *\n",
    "from data_processor import i2b2Dataset, pad_batch\n",
    "from model import Bert_BiLSTM_CRF\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "import stanza\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee515aaa1474cce9acda68ab1920557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 03:21:53 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "========================\n",
      "\n",
      "2022-08-04 03:21:53 INFO: Use device: gpu\n",
      "2022-08-04 03:21:53 INFO: Loading: tokenize\n",
      "2022-08-04 03:21:57 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize\")\n",
    "except Exception:\n",
    "    stanza.download(\"en\")\n",
    "    nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = '''\n",
    "Two days prior to admission, she was started on a prednisone taper and one day prior to admission she required oxygen at home in order to maintain oxygen saturation greater than 90%.  She has also been on levofloxacin and nebulizers, and was not getting better, and presented to the [**Hospital1 18**] Emergency Room.  In the [**Hospital3 **] Emergency Room, her oxygen saturation was 100% on CPAP.  She was not able to be weaned off of this despite nebulizer treatment and Solu-Medrol 125 mg IV x2.  Review of systems is negative for the following:  Fevers, chills, nausea, vomiting, night sweats, change in weight, gastrointestinal complaints, neurologic changes, rashes, palpitations, orthopnea.  Is positive for the following: Chest pressure occasionally with shortness of breath with exertion, some shortness of breath that is positionally related, but is improved with nebulizer treatment.  PAST MEDICAL HISTORY: 1. COPD.  Last pulmonary function tests in [**2117-11-3**] demonstrated a FVC of 52% of predicted, a FEV1 of 54% of predicted, a MMF of 23% of predicted, and a FEV1:FVC ratio of 67% of predicted, that does not improve with bronchodilator treatment.  The FVC, however, does significantly improve with bronchodilator treatment consistent with her known reversible air flow obstruction in addition to an underlying restrictive ventilatory defect.  The patient has never been on home oxygen prior to this recent episode.  She has never been on steroid taper or been intubated in the past. 2. Lacunar CVA.  MRI of the head in [**2114-11-4**] demonstrates \"mild degree of multiple small foci of high T2 signal within the white matter of both cerebral hemispheres as well as the pons, in the latter region predominantly to the right of midline.  The abnormalities, while nonspecific in etiology, are most likely secondary to chronic microvascular infarction.  There is no mass, lesion, shift of the normal midline strictures or hydrocephalus.  The major vascular flow patterns are preserved. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:1')\n",
    "ckpt_name = 'best_NER_bert_crf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Bert_BiLSTM_CRF(tag2idx).to(DEVICE)\n",
    "tokenizer = BertTokenizer.from_pretrained(BASE_MODEL)\n",
    "ckpt = torch.load(f\"{NER_MODEL_SAVED_DIR}/{ckpt_name}.ckpt\", map_location=DEVICE)\n",
    "model.load_state_dict(ckpt['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input a whole sentence as a list\n",
    "def create_query(sentence, tokenizer):\n",
    "\n",
    "    temp_token = ['[CLS]']\n",
    "    # word_list = sentence.split()\n",
    "    for word in sentence:\n",
    "        temp_token.extend(tokenizer.tokenize(word))\n",
    "    temp_token = temp_token[:MAX_LEN - 1]\n",
    "    temp_token.append('[SEP]')\n",
    "    input_id = tokenizer.convert_tokens_to_ids(temp_token)\n",
    "    padding_len = MAX_LEN - len(input_id)\n",
    "    input_id = input_id + ([0] * padding_len)\n",
    "    tokenized_texts = torch.LongTensor([input_id])\n",
    "    # print(input_id)\n",
    "    # attention_masks = [[int(i>0) for i in input_id]]\n",
    "    attention_masks = (tokenized_texts > 0)\n",
    "\n",
    "    return temp_token, tokenized_texts, attention_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "all_tags = []\n",
    "doc = nlp(long_text)\n",
    "for i, sentence in enumerate(doc.sentences):\n",
    "    word_list = [token.text for token in sentence.tokens]\n",
    "    # print(word_list)\n",
    "    temp_token, sentence_tensor, mask = create_query(word_list, tokenizer)\n",
    "    sentence_tensor = sentence_tensor.to(DEVICE)\n",
    "    mask = mask.to(DEVICE)\n",
    "    y = model(sentence_tensor, None, mask, is_test=True)\n",
    "    y = y[0]\n",
    "    y_tag = [idx2tag[i] for i in y]\n",
    "    pretok_sent = ''\n",
    "    pretags = ''\n",
    "    for i in range(1, len(temp_token)-1):\n",
    "        if temp_token[i].startswith(\"##\"):\n",
    "            pretok_sent += temp_token[i][2:]\n",
    "        else:\n",
    "            pretok_sent += f\" {temp_token[i]}\"\n",
    "            pretags += f\" {y[i]}\"\n",
    "    pretok_sent = pretok_sent[1:]\n",
    "    pretags = pretags[1:]\n",
    "    s = pretok_sent.split()\n",
    "    t = pretags.split()\n",
    "    all_sentences.append(s)\n",
    "    all_tags.append([idx2tag.get(int(x)) for x in t])\n",
    "# print(all_sentences, all_tags)\n",
    "# print(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def entity_extractor(all_sentences, all_tags):\n",
    "    sentences_with_problem = []\n",
    "    all_problems_in_text_tmp = []\n",
    "    all_treatment_in_text = []\n",
    "    all_test_in_text = []\n",
    "\n",
    "    for s, t in zip(all_sentences, all_tags):\n",
    "        flag_treatment, flag_problem, flag_test = 0, 0, 0\n",
    "        problem_in_sentence = ''\n",
    "        treatment_in_sentence = []\n",
    "        test_in_sentence = []\n",
    "        for i in range(len(t)):\n",
    "            if t[i] == 'B-problem' or t[i] == 'I-problem' and flag_problem == 0: \n",
    "                flag_problem = 1\n",
    "                # if there is an entity, add the index of sentence to a list\n",
    "                # sentences_with_problem.append(n)\n",
    "                # append the index of entity to a list\n",
    "                if problem_in_sentence:\n",
    "                    problem_in_sentence = f'{problem_in_sentence}| {str(i)}'\n",
    "                else:\n",
    "                    problem_in_sentence += str(i)\n",
    "            elif t[i] == 'I-problem' or t[i] == 'X' and flag_problem == 1:\n",
    "                problem_in_sentence = f'{problem_in_sentence} {str(i)}'\n",
    "                \n",
    "                \n",
    "            elif t[i] == 'B-test' or t[i] == 'I-test':\n",
    "                flag_test = 1\n",
    "                test_in_sentence.append(i)\n",
    "            elif t[i] == 'X' and flag_test == 1:\n",
    "                test_in_sentence.append(i)\n",
    "            elif t[i] == 'B-treatment' or t[i] == 'I-treatment':\n",
    "                flag_treatment = 1\n",
    "                treatment_in_sentence.append(i)\n",
    "            elif t[i] == 'X' and flag_treatment == 1:\n",
    "                treatment_in_sentence.append(i)\n",
    "            elif t[i] in ['O', 'X']:\n",
    "                flag_treatment, flag_problem, flag_test = 0, 0, 0\n",
    "                # print(s[i], end=' ')\n",
    "        print(problem_in_sentence)\n",
    "        all_problems_in_text_tmp.append(problem_in_sentence)\n",
    "        all_treatment_in_text.append(treatment_in_sentence)\n",
    "        all_test_in_text.append(test_in_sentence)\n",
    "            \n",
    "    # create sentences with '[entity]' tag\n",
    "    all_problems_in_text = []\n",
    "    sentences_with_problem = []\n",
    "    for sentence, problem_index in zip(all_sentences, all_problems_in_text_tmp):\n",
    "        # print(problem_index)\n",
    "        if problem_index:\n",
    "            index = problem_index.split('|')\n",
    "            tmp = [i.split() for i in index]\n",
    "            all_problems_in_text.append(tmp)\n",
    "            for i_list in tmp:\n",
    "                s = copy.deepcopy(sentence)\n",
    "                s.insert(int(i_list[-1])+1, '[entity]')\n",
    "                s.insert(int(i_list[0]), '[entity]')\n",
    "                s = ' '.join(s)\n",
    "                sentences_with_problem.append(s)\n",
    "        else:\n",
    "            # sentences_with_problem.append(sentence)\n",
    "            all_problems_in_text.append(problem_index)\n",
    "\n",
    "    return sentences_with_problem, all_problems_in_text, all_treatment_in_text, all_test_in_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "9| 11| 13| 15| 17 18| 20 21 22| 24 25| 27 28| 30| 32| 34\n",
      "6 7| 10 11 12| 14| 16 17 18 19| 22 23\n",
      "6\n",
      "\n",
      "0 1| 13 14 15 16 17 18| 22 23 24 25 26\n",
      "10 11 12\n",
      "\n",
      "2 3\n",
      "18 19| 21 22 23| 25 26 27| 29 30 31\n",
      "1| 13 14 15\n",
      "3| 5| 7| 9 10 11 12| 14\n",
      "2 3\n"
     ]
    }
   ],
   "source": [
    "sentences_with_problem, all_problems_in_text, all_treatment_in_text, all_test_in_text = entity_extractor(all_sentences, all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[28, 29],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [3, 4, 5, 10],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [0, 1, 2, 3, 17, 18, 25, 26, 33, 34, 42, 43, 45, 46],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [0, 1, 2, 3],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['review of systems is negative for the following : [entity] fevers [entity] , chills , nausea , vomiting , night sweats , change in weight , gastrointestinal complaints , neurologic changes , rashes , palpitations , orthopnea .',\n",
       " 'review of systems is negative for the following : fevers , [entity] chills [entity] , nausea , vomiting , night sweats , change in weight , gastrointestinal complaints , neurologic changes , rashes , palpitations , orthopnea .',\n",
       " 'review of systems is negative for the following : fevers , chills , [entity] nausea [entity] , vomiting , night sweats , change in weight , gastrointestinal complaints , neurologic changes , rashes , palpitations , orthopnea .',\n",
       " 'review of systems is negative for the following : fevers , chills , nausea , [entity] vomiting [entity] , night sweats , change in weight , gastrointestinal complaints , neurologic changes , rashes , palpitations , orthopnea .',\n",
       " 'review of systems is negative for the following : fevers , chills , nausea , vomiting , [entity] night sweats [entity] , change in weight , gastrointestinal complaints , neurologic changes , rashes , palpitations , orthopnea .',\n",
       " 'review of systems is negative for the following : fevers , chills , nausea , vomiting , night sweats , [entity] change in weight [entity] , gastrointestinal complaints , neurologic changes , rashes , palpitations , orthopnea .',\n",
       " 'review of systems is negative for the following : fevers , chills , nausea , vomiting , night sweats , change in weight , [entity] gastrointestinal complaints [entity] , neurologic changes , rashes , palpitations , orthopnea .',\n",
       " 'review of systems is negative for the following : fevers , chills , nausea , vomiting , night sweats , change in weight , gastrointestinal complaints , [entity] neurologic changes [entity] , rashes , palpitations , orthopnea .',\n",
       " 'review of systems is negative for the following : fevers , chills , nausea , vomiting , night sweats , change in weight , gastrointestinal complaints , neurologic changes , [entity] rashes [entity] , palpitations , orthopnea .',\n",
       " 'review of systems is negative for the following : fevers , chills , nausea , vomiting , night sweats , change in weight , gastrointestinal complaints , neurologic changes , rashes , [entity] palpitations [entity] , orthopnea .',\n",
       " 'review of systems is negative for the following : fevers , chills , nausea , vomiting , night sweats , change in weight , gastrointestinal complaints , neurologic changes , rashes , palpitations , [entity] orthopnea [entity] .',\n",
       " 'is positive for the following : [entity] chest pressure [entity] occasionally with shortness of breath with exertion , some shortness of breath that is positionally related , but is improved with nebulizer treatment .',\n",
       " 'is positive for the following : chest pressure occasionally with [entity] shortness of breath [entity] with exertion , some shortness of breath that is positionally related , but is improved with nebulizer treatment .',\n",
       " 'is positive for the following : chest pressure occasionally with shortness of breath with [entity] exertion [entity] , some shortness of breath that is positionally related , but is improved with nebulizer treatment .',\n",
       " 'is positive for the following : chest pressure occasionally with shortness of breath with exertion , [entity] some shortness of breath [entity] that is positionally related , but is improved with nebulizer treatment .',\n",
       " 'is positive for the following : chest pressure occasionally with shortness of breath with exertion , some shortness of breath that is [entity] positionally related [entity] , but is improved with nebulizer treatment .',\n",
       " 'past medical history : 1 . [entity] copd [entity] .',\n",
       " '[entity] the fvc [entity] , however , does significantly improve with bronchodilator treatment consistent with her known reversible air flow obstruction in addition to an underlying restrictive ventilatory defect .',\n",
       " 'the fvc , however , does significantly improve with bronchodilator treatment consistent with [entity] her known reversible air flow obstruction [entity] in addition to an underlying restrictive ventilatory defect .',\n",
       " 'the fvc , however , does significantly improve with bronchodilator treatment consistent with her known reversible air flow obstruction in addition to [entity] an underlying restrictive ventilatory defect [entity] .',\n",
       " 'the patient has never been on home oxygen prior to [entity] this recent episode [entity] .',\n",
       " '2 . [entity] lacunar cva [entity] .',\n",
       " 'mri of the head in [ * * 2114 - 11 - 4 * * ] demonstrates \" [entity] mild degree [entity] of multiple small foci of high t2 signal within the white matter of both cerebral hemispheres as well as the pons , in the latter region predominantly to the right of midline .',\n",
       " 'mri of the head in [ * * 2114 - 11 - 4 * * ] demonstrates \" mild degree of [entity] multiple small foci [entity] of high t2 signal within the white matter of both cerebral hemispheres as well as the pons , in the latter region predominantly to the right of midline .',\n",
       " 'mri of the head in [ * * 2114 - 11 - 4 * * ] demonstrates \" mild degree of multiple small foci of [entity] high t2 signal within the white matter [entity] of both cerebral hemispheres as well as the pons , in the latter region predominantly to the right of midline .',\n",
       " 'the [entity] abnormalities [entity] , while nonspecific in etiology , are most likely secondary to chronic microvascular infarction .',\n",
       " 'the abnormalities , while nonspecific in etiology , are most likely secondary to [entity] chronic microvascular infarction [entity] .',\n",
       " 'there is no [entity] mass [entity] , lesion , shift of the normal midline strictures or hydrocephalus .',\n",
       " 'there is no mass , [entity] lesion [entity] , shift of the normal midline strictures or hydrocephalus .',\n",
       " 'there is no mass , lesion , [entity] shift of the normal midline strictures [entity] or hydrocephalus .',\n",
       " 'there is no mass , lesion , shift of the normal midline strictures or [entity] hydrocephalus [entity] .',\n",
       " 'the major [entity] vascular flow [entity] patterns are preserved .']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_with_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_tr = 'B-treatment'\n",
    "i_tr = 'I-treatment'\n",
    "b_t = 'B-test'\n",
    "i_t = 'I-test'\n",
    "b_p = 'B-problem'\n",
    "i_p = 'I-problem'\n",
    "\n",
    "flag_treatment, flag_problem, flag_test = 0, 0, 0 \n",
    "for i in range(len(tags)):\n",
    "    \n",
    "    if tags[i] == b_tr:\n",
    "        flag_treatment = 1\n",
    "        print(b_tr, end=' ')\n",
    "    elif tags[i] == i_tr:\n",
    "        if flag_treatment == 0:\n",
    "       print(b_t, end=' ')\n",
    "            flag_test = 1\n",
    "        else:\n",
    "            print(i_t, end=' ')\n",
    "    elif tags[i] == 'X' and flag_test == 1:\n",
    "        print(i_t, end=' ')\n",
    "        \n",
    "    elif tags[i] == b_p:\n",
    "        flag_problem = 1\n",
    "        print(b_p, end=' ')\n",
    "    elif tags[i] == i_p:\n",
    "        if flag_problem == 0:\n",
    "            print(b_p, end=' ')\n",
    "            flag_problem = 1\n",
    "        else:\n",
    "            print(i_p, end=' ')   \n",
    "    elif tags[i] == 'X' and flag_problem == 1 :\n",
    "        print(i_p, end=' ')    \n",
    "        \n",
    "    elif tags[i] == 'O' or tags[i] == 'X':\n",
    "        flag_treatment, flag_problem, flag_test = 0, 0, 0 \n",
    "        print('O', end=' ')      print(b_tr, end=' ')\n",
    "            flag_treatment = 1\n",
    "        else:\n",
    "            print(i_tr, end=' ')\n",
    "    elif tags[i] == 'X' and flag_treatment == 1 :\n",
    "            print(i_tr, end=' ')\n",
    "              \n",
    "    elif tags[i] == b_t:\n",
    "        flag_test = 1\n",
    "        print(b_t, end=' ')\n",
    "    elif tags[i] == i_t:\n",
    "        if flag_test == 0:\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'B-problem',\n",
    "  'I-problem',\n",
    "  'O',\n",
    "  'O',\n",
    "  'B-problem',\n",
    "  'X',\n",
    "  'I-problem',\n",
    "  'O',\n",
    "  'B-problem',\n",
    "  'O',\n",
    "  'O',\n",
    "  'I-problem',\n",
    "  'I-problem',\n",
    "  'X',\n",
    "  'O',\n",
    "  'O',\n",
    "  'B-problem',\n",
    "  'I-problem',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'B-treatment',\n",
    "  'I-treatment',\n",
    "  'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O O O O O O B-problem I-problem O O B-problem I-problem I-problem O B-problem O O B-problem I-problem I-problem O O B-problem I-problem O O O O O B-treatment I-treatment O "
     ]
    }
   ],
   "source": [
    "b_tr = 'B-treatment'\n",
    "i_tr = 'I-treatment'\n",
    "b_t = 'B-test'\n",
    "i_t = 'I-test'\n",
    "b_p = 'B-problem'\n",
    "i_p = 'I-problem'\n",
    "\n",
    "flag_treatment, flag_problem, flag_test = 0, 0, 0 \n",
    "for i in range(len(tags)):\n",
    "    if tags[i] == b_tr or tags[i] == i_tr and flag_treatment == 0:\n",
    "        flag_treatment = 1\n",
    "        print(b_tr, end=' ')\n",
    "    elif tags[i] == i_tr or tags[i] == 'X' and flag_treatment == 1:\n",
    "        print(i_tr, end=' ')\n",
    "        \n",
    "    elif tags[i] == b_p or tags[i] == i_p and flag_problem == 0:\n",
    "        flag_problem = 1\n",
    "        print(b_p, end=' ')\n",
    "    elif tags[i] == i_p or tags[i] == 'X' and flag_problem == 1 :\n",
    "        print(i_p, end=' ')    \n",
    "        \n",
    "    elif tags[i] == b_t or tags[i] == i_t and flag_test == 0:\n",
    "        flag_test = 1\n",
    "        print(b_t, end=' ')   \n",
    "\n",
    "    elif tags[i] == i_t or tags[i] == 'X' and flag_treatment == 1:\n",
    "        print(i_t, end=' ')\n",
    "            \n",
    "    elif tags[i] == 'O' or tags[i] == 'X':\n",
    "        flag_treatment, flag_problem, flag_test = 0, 0, 0 \n",
    "        print('O', end=' ') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-test',\n",
       " 'I-test',\n",
       " 'I-test',\n",
       " 'I-test',\n",
       " 'O',\n",
       " 'O',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-problem',\n",
       " 'O',\n",
       " 'B-problem',\n",
       " 'I-problem',\n",
       " 'I-problem',\n",
       " 'X',\n",
       " 'B-problem',\n",
       " 'I-problem',\n",
       " 'I-problem',\n",
       " 'O',\n",
       " 'I-problem',\n",
       " 'I-problem',\n",
       " 'I-problem',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'B-problem',\n",
    "  'I-problem',\n",
    "  'O',\n",
    "  'O',\n",
    "  'B-problem',\n",
    "  'X',\n",
    "  'I-problem',\n",
    "  'O',\n",
    "  'B-problem',\n",
    "  'O',\n",
    "  'O',\n",
    "  'I-problem',\n",
    "  'I-problem',\n",
    "  'X',\n",
    "  'O',\n",
    "  'O',\n",
    "  'B-problem',\n",
    "  'I-problem',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'B-treatment',\n",
    "  'I-treatment',\n",
    "  'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'O', 'O', 'O', 'X', 'X', 'O', 'X', 'X', 'X', 'X', 'O', 'X', 'X'], ['O', 'O', 'O', 'O', 'X', 'X', 'O', 'X', 'X', 'X', 'X', 'O', 'X', 'X'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'O', 'O', 'O', 'O', 'X', 'X'], ['O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'B-problem', 'I-problem', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'O', 'O', 'O', 'O', 'O', 'O', 'B-test', 'I-test', 'O', 'O', 'O', 'X', 'O'], ['O', 'O', 'O', 'O', 'O', 'B-treatment', 'O', 'B-treatment', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'O', 'O', 'X', 'X', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O', 'X', 'X', 'O', 'X', 'X', 'X'], ['O', 'O', 'O', 'B-test', 'I-test', 'I-test', 'O', 'O', 'X', 'O', 'B-treatment', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'O', 'B-treatment', 'I-treatment', 'O', 'B-treatment', 'X', 'X', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'O', 'B-problem', 'O', 'B-problem', 'O', 'B-problem', 'O', 'B-problem', 'I-problem', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'I-problem', 'O', 'B-problem', 'I-problem', 'O', 'B-problem', 'O', 'B-problem', 'O', 'B-problem', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'O', 'O', 'B-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'O'], ['O', 'O', 'O', 'O', 'O', 'X', 'B-problem', 'O'], ['B-test', 'I-test', 'I-test', 'I-test', 'O', 'O', 'X', 'X', 'O', 'X', 'X', 'X', 'X', 'O', 'X', 'X', 'O', 'B-test', 'I-test', 'O', 'O', 'X', 'X', 'O', 'O', 'B-test', 'I-test', 'O', 'O', 'X', 'O', 'O', 'O', 'B-test', 'I-test', 'O', 'O', 'X', 'O', 'O', 'O', 'O', 'B-test', 'I-test', 'I-test', 'I-test', 'I-test', 'O', 'O', 'X', 'O', 'O'], ['B-test', 'I-test', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'O', 'I-problem', 'O'], ['O', 'O', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'X', 'B-problem', 'I-problem', 'O'], ['B-test', 'I-test', 'I-test', 'I-test', 'O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'I-problem', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'I-problem', 'I-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'O'], ['O', 'O', 'O', 'B-problem', 'O', 'B-problem', 'O', 'B-problem', 'O', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'O'], ['O', 'O', 'I-problem', 'I-problem', 'O', 'O', 'O', 'O'], ['O', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'O'], ['B-problem', 'I-problem', 'O', 'O', 'B-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'I-problem', 'I-problem', 'O'], ['O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'O', 'O'], ['O', 'X', 'B-problem', 'O'], ['O', 'O', 'I-test', 'I-test', 'O', 'O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'B-test', 'I-test', 'I-test', 'I-test', 'O', 'O', 'X', 'X', 'O', 'O', 'X', 'O', 'B-test', 'I-test', 'I-test', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'O'], ['B-test', 'I-test', 'O', 'O', 'I-test', 'I-test', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'O', 'O', 'B-test', 'I-test', 'I-test', 'O', 'O', 'X', 'O'], ['O', 'O', 'O', 'B-problem', 'O', 'O', 'O', 'B-problem', 'B-problem', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'B-treatment', 'I-treatment', 'O'], ['O', 'X', 'B-problem', 'O', 'B-treatment', 'O'], ['O', 'X', 'O', 'O', 'B-treatment', 'O'], ['O', 'X', 'B-problem', 'X', 'I-problem', 'O', 'B-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'X', 'B-treatment', 'O', 'O', 'X', 'X', 'X', 'O', 'X', 'B-treatment', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'X', 'B-treatment', 'O', 'O', 'O', 'X', 'X', 'X', 'O', 'X', 'B-treatment', 'O', 'O', 'O', 'X', 'X', 'X', 'O', 'X', 'B-treatment', 'O', 'O', 'O', 'X', 'X', 'X'], ['O', 'X', 'B-treatment', 'I-treatment', 'O', 'X', 'X', 'X', 'X', 'X'], ['O', 'X', 'B-treatment', 'I-treatment', 'O', 'X', 'O', 'X', 'O', 'O', 'O', 'X', 'B-treatment', 'O', 'O', 'O', 'X', 'X', 'X', 'O', 'X', 'B-treatment', 'O', 'O', 'O', 'X', 'X', 'X', 'O', 'X', 'B-treatment', 'O', 'O', 'O', 'X', 'X', 'X', 'O', 'O', 'B-treatment', 'O', 'O', 'B-problem'], ['O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'X', 'X', 'O', 'O', 'O', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'O', 'O', 'O', 'X', 'X', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-test', 'I-test', 'O', 'O', 'O', 'O', 'O', 'B-test', 'I-test', 'O', 'X', 'X', 'O', 'B-test', 'I-test', 'O', 'O', 'O', 'O', 'B-test', 'O', 'O', 'X', 'X', 'O', 'O', 'O', 'X', 'B-test', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'X', 'O', 'B-treatment', 'O', 'O', 'O', 'I-problem', 'O'], ['O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'I-problem', 'O'], ['O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'O', 'B-treatment', 'I-treatment', 'O', 'O', 'B-test', 'I-test', 'I-test', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'B-problem', 'O'], ['O', 'O', 'O', 'B-problem', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'O', 'O', 'O', 'I-problem', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'O', 'B-problem', 'O', 'B-problem', 'O', 'O', 'B-problem', 'O'], ['B-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'O', 'B-problem', 'O', 'O', 'B-problem', 'O'], ['O', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'O'], ['B-test', 'O', 'O', 'O', 'O', 'X', 'X', 'O', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'O', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O'], ['B-test', 'I-test', 'O', 'O', 'B-test', 'O', 'O', 'B-test', 'O', 'O'], ['B-test', 'X', 'X', 'O', 'O', 'O', 'O', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'O', 'O', 'O'], ['B-test', 'O', 'O', 'O'], ['B-test', 'O', 'O', 'O', 'O', 'O'], ['B-test', 'I-test', 'I-test', 'O', 'O', 'B-test', 'O', 'O', 'X', 'X', 'O', 'B-test', 'O', 'O', 'O', 'B-test', 'O', 'O', 'O'], ['B-test', 'I-test', 'X', 'X', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'I-problem', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'I-problem', 'O'], ['B-test', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'X', 'I-problem', 'I-problem', 'I-problem', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'B-problem', 'O', 'B-problem', 'O', 'B-problem', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'I-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'O', 'B-treatment', 'I-treatment', 'O'], ['O', 'O', 'O', 'O', 'B-treatment', 'O', 'O', 'X', 'X', 'O'], ['O', 'O', 'O', 'B-test', 'I-test', 'X'], ['B-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'X', 'X', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'O'], ['O', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-test', 'I-test', 'O', 'O', 'O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'O', 'O', 'B-problem', 'O'], ['O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'B-treatment', 'B-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'X'], ['O', 'X', 'X', 'O', 'O', 'X', 'O', 'O', 'X', 'X', 'O', 'B-treatment', 'I-treatment', 'O', 'B-treatment', 'I-treatment', 'O'], ['O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'I-treatment', 'I-treatment', 'I-treatment', 'O', 'B-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'O', 'O', 'O'], ['O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'X', 'O', 'O', 'O'], ['O', 'X', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'X'], ['O', 'O', 'O', 'B-problem', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'O', 'O', 'B-test', 'O', 'O', 'B-test', 'I-test', 'O'], ['O', 'O', 'O', 'O', 'B-treatment', 'O', 'B-treatment', 'O', 'O', 'B-treatment', 'O', 'B-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'O'], ['O', 'X', 'B-problem', 'O'], ['O', 'O', 'O', 'O', 'B-treatment', 'O', 'B-treatment', 'O', 'O', 'B-test', 'I-test', 'I-test', 'O', 'O', 'O', 'B-test', 'O'], ['O', 'X', 'B-problem', 'O'], ['O', 'O', 'O', 'B-problem', 'I-problem', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'O'], ['B-treatment', 'I-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O'], ['O', 'O', 'B-test', 'I-test', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'O', 'B-problem', 'O'], ['O', 'X', 'B-problem', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'X', 'I-treatment', 'I-treatment', 'O', 'O', 'B-problem', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'O'], ['O', 'O', 'O', 'O', 'O', 'B-test', 'I-test', 'O', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'O'], ['O', 'X', 'B-problem', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'B-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'O', 'B-test', 'I-test', 'I-test', 'I-test', 'I-test', 'O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'X', 'X', 'O'], ['O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'O', 'O', 'O', 'O', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'O'], ['O', 'X', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'O', 'O', 'X', 'X', 'X', 'O', 'X', 'X', 'X', 'O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O'], ['O', 'O', 'O', 'O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'O'], ['O', 'X', 'B-problem', 'O'], ['O', 'O', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'I-treatment', 'O'], ['O', 'X', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'B-treatment', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'X', 'O', 'O'], ['O', 'O', 'O', 'O', 'B-treatment', 'X', 'I-treatment', 'I-treatment', 'O', 'B-treatment', 'I-treatment', 'O'], ['O', 'O'], ['B-problem', 'I-problem', 'O'], ['O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'O'], ['O', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'B-treatment', 'O', 'B-treatment', 'O', 'O', 'B-treatment', 'O', 'O', 'O', 'O'], ['O', 'X', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'X', 'B-problem', 'I-problem', 'O'], ['O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'B-problem', 'I-problem', 'O', 'B-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'B-test', 'I-test', 'O', 'B-test', 'I-test', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'O', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'X'], ['O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'O', 'O', 'O', 'B-problem', 'I-problem', 'O', 'O', 'B-problem', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'X', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'B-test', 'I-test', 'I-test', 'I-test', 'I-test', 'O', 'O', 'O', 'O', 'B-problem', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'O', 'B-treatment', 'I-treatment', 'I-treatment', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'B-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'O', 'O', 'O', 'O', 'I-test', 'I-test', 'O'], ['B-test', 'I-test', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'O'], ['O', 'O', 'O', 'O', 'X', 'B-treatment', 'O', 'O', 'O', 'X', 'X', 'X', 'O', 'X', 'X', 'X', 'O', 'X', 'B-treatment', 'O', 'O', 'O', 'X', 'X', 'X', 'O', 'X', 'X', 'X', 'O', 'X', 'B-treatment', 'O', 'O', 'O', 'X', 'X', 'X', 'O', 'X', 'X', 'X', 'O', 'X', 'B-treatment', 'O', 'O'], ['O', 'X', 'B-treatment', 'I-treatment', 'O', 'O', 'O', 'X', 'X', 'X', 'X', 'X'], ['O', 'X', 'B-treatment', 'O', 'X', 'X', 'O', 'O', 'X', 'X', 'X', 'O', 'X', 'O', 'X', 'X', 'X', 'O', 'X', 'O', 'X', 'B-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'X', 'O', 'O', 'O', 'X', 'B-treatment', 'O', 'X', 'X', 'O', 'O', 'O'], ['O', 'X', 'B-treatment', 'I-treatment', 'O', 'X', 'X', 'X', 'O', 'O', 'O', 'X', 'B-treatment', 'O', 'O', 'O', 'X', 'X', 'X', 'O', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O'], ['O', 'X', 'B-treatment', 'O', 'B-treatment', 'X', 'B-treatment', 'O', 'O', 'O', 'X', 'X', 'X', 'O', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'O', 'O', 'B-treatment', 'O'], ['O', 'X', 'B-treatment', 'O', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'X', 'X', 'X', 'O', 'O', 'O', 'X', 'X', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'X'], ['O', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'X', 'O', 'O', 'X', 'X', 'O', 'O', 'O', 'O', 'X', 'O', 'O', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-treatment', 'I-treatment', 'O', 'O', 'O', 'B-problem', 'X', 'X', 'I-problem', 'O'], ['O', 'O', 'O', 'O', 'X', 'B-problem', 'O', 'O', 'B-treatment', 'I-treatment', 'I-treatment', 'I-treatment', 'I-treatment', 'I-treatment', 'I-treatment', 'I-treatment', 'O'], ['O', 'X', 'B-problem', 'O'], ['O', 'X', 'B-problem', 'O'], ['O', 'X', 'B-problem', 'I-problem', 'I-problem', 'O'], ['O', 'X', 'O', 'O'], ['O', 'X', 'O', 'X', 'X', 'O', 'X', 'X', 'X', 'O', 'O', 'X', 'X', 'O', 'O', 'X', 'X', 'O', 'O', 'X', 'X', 'O', 'O', 'X', 'X'], ['O', 'X', 'X', 'O', 'O', 'O', 'O', 'X', 'X', 'O', 'O', 'O', 'O', 'O'], ['O', 'X', 'X', 'X'], ['O', 'O', 'O', 'O', 'X', 'X', 'O', 'X', 'X', 'X', 'X', 'O', 'X', 'X'], ['O', 'X', 'X', 'O', 'O', 'O', 'X', 'X', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X'], ['O', 'X', 'X', 'O', 'O', 'O', 'O', 'X', 'X', 'O', 'O', 'O', 'O', 'X', 'X']]\n"
     ]
    }
   ],
   "source": [
    "location = {}\n",
    "flag_treatment, flag_problem, flag_test = 0, 0, 0 \n",
    "for i in range(1, len(t)-1):\n",
    "    if t[i] == 'B-treatment':\n",
    "        flag_treatment = 1\n",
    "        print(print_treatment(s[i]), end=' ')\n",
    "    elif t[i] == 'I-treatment' or t[i] == 'X' and flag_treatment == 1 :\n",
    "        print(print_treatment(s[i]), end=' ')\n",
    "    elif t[i] == 'B-test':\n",
    "        flag_test = 1\n",
    "        print(print_test(s[i]), end=' ')\n",
    "    elif t[i] == 'I-test' or t[i] == 'X' and flag_test == 1 :\n",
    "        print(print_test(s[i]), end=' ')\n",
    "    elif t[i] == 'B-problem':\n",
    "        flag_problem = 1\n",
    "        print(print_problem(s[i]), end=' ')\n",
    "    elif t[i] == 'I-problem' or t[i] == 'X' and flag_problem == 1 :\n",
    "        print(print_problem(s[i]), end=' ')    \n",
    "    elif t[i] == 'O':\n",
    "        flag_treatment, flag_problem, flag_test = 0, 0, 0 \n",
    "        print(s[i], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'O', 'O', 'O', 'O', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'I-problem', 'I-problem', 'I-problem', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = all_tags.index(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'was',\n",
       " 'felt',\n",
       " 'that',\n",
       " 'the',\n",
       " 'leukocytosis',\n",
       " 'was',\n",
       " 'secondary',\n",
       " 'to',\n",
       " 'both',\n",
       " 'steroids',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'question',\n",
       " 'of',\n",
       " 'a',\n",
       " 'left',\n",
       " 'lower',\n",
       " 'lobe',\n",
       " 'pneumonia',\n",
       " '.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-problem', 'I-problem', 'O', 'I-problem', 'I-problem', 'I-problem', 'O', 'O', 'O', 'O', 'O', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '[CLS] admission date : [ * * 2118 - 6 - 2 * * ] [SEP]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CLS] admission date : [ * * 2118 - 6 - 2 * * ] [SEP]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "all_tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pretok_sent = \"\"\n",
    "pretags = \"\"\n",
    "for i, tok in enumerate(temp_token):\n",
    "    if tok.startswith(\"##\"):\n",
    "        pretok_sent += tok[2:]\n",
    "    else:\n",
    "        pretok_sent += f\" {tok}\"\n",
    "        pretags += f\" {result[i]}\"\n",
    "pretok_sent = pretok_sent[1:]\n",
    "pretags = pretags[1:]\n",
    "s = pretok_sent.split()\n",
    "t = pretags.split()\n",
    "all_sentences.append(s)\n",
    "all_tags.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = 'The FVC, however, does significantly improve with bronchodilator treatment consistent with her known reversible air flow obstruction in addition to an underlying restrictive ventilatory defect.'\n",
    "sentence = 'At 9am the morning of admission he passed a large , bloody bowel movement and came to the Michael .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_token, sentence_tensor, mask = create_query(sentence, tokenizer)\n",
    "sentence_tensor = sentence_tensor.to(DEVICE)\n",
    "mask = mask.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(sentence_tensor, None, mask, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[0]\n",
    "y_tag = [idx2tag[i] for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'O',\n",
       " 'O',\n",
       " 'X',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-problem',\n",
       " 'I-problem',\n",
       " 'I-problem',\n",
       " 'I-problem',\n",
       " 'I-problem',\n",
       " 'X',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'X',\n",
       " 'X',\n",
       " 'O',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(model, input_ids):\n",
    "    model.to(DEVICE)\n",
    "    input_ids = input_ids.to(DEVICE)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, token_type_ids=None,\n",
    "                        attention_mask=None)\n",
    "        # For eval mode, the first result of outputs is logits\n",
    "        logits = outputs[0]\n",
    "    # Get NER predict result\n",
    "    predict_results = logits.detach().cpu().numpy()\n",
    "    result_arrays_soft = softmax(predict_results[0])\n",
    "\n",
    "    return np.argmax(result_arrays_soft, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entities(long_text):\n",
    "    all_sentences = []\n",
    "    all_tags = []\n",
    "    doc = nlp(long_text)\n",
    "    for i, sentence in enumerate(doc.sentences):\n",
    "        # temp_token: tokenized words\n",
    "        # input_ids: convert temp_token to id\n",
    "        word_list = [token.text for token in sentence.tokens]\n",
    "        temp_token, input_ids, attention_masks = create_query(word_list, tokenizer_ner)\n",
    "        result_list = model_inference(model_ner, input_ids)\n",
    "        result = [tag2name[t] for t in result_list]\n",
    "        pretok_sent = \"\"\n",
    "        pretags = \"\"\n",
    "        for i, tok in enumerate(temp_token):\n",
    "            if tok.startswith(\"##\"):\n",
    "                pretok_sent += tok[2:]\n",
    "            else:\n",
    "                pretok_sent += f\" {tok}\"\n",
    "                pretags += f\" {result[i]}\"\n",
    "        pretok_sent = pretok_sent[1:]\n",
    "        pretags = pretags[1:]\n",
    "        s = pretok_sent.split()\n",
    "        t = pretags.split()\n",
    "        all_sentences.append(s)\n",
    "        all_tags.append(t)\n",
    "    return all_sentences, all_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_name = 'best_NER_bert_crf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/users/home/jwu51/Programs/Projects/i2b2-NER-scratch/NER/ner_test_bert_crf.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Beverest/users/home/jwu51/Programs/Projects/i2b2-NER-scratch/NER/ner_test_bert_crf.ipynb#ch0000016vscode-remote?line=0'>1</a>\u001b[0m DEVICE \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda:1\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start infer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "Loading the pre-trained checkpoint...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/users/home/jwu51/Programs/Projects/i2b2-NER-scratch/NER/ner_test_bert_crf.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beverest/users/home/jwu51/Programs/Projects/i2b2-NER-scratch/NER/ner_test_bert_crf.ipynb#ch0000009vscode-remote?line=8'>9</a>\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(ckpt[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beverest/users/home/jwu51/Programs/Projects/i2b2-NER-scratch/NER/ner_test_bert_crf.ipynb#ch0000009vscode-remote?line=9'>10</a>\u001b[0m     exit()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Beverest/users/home/jwu51/Programs/Projects/i2b2-NER-scratch/NER/ner_test_bert_crf.ipynb#ch0000009vscode-remote?line=10'>11</a>\u001b[0m     sentence \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m[CLS]\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(args\u001b[39m.\u001b[39mtxt) \u001b[39m+\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m[SEP]\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beverest/users/home/jwu51/Programs/Projects/i2b2-NER-scratch/NER/ner_test_bert_crf.ipynb#ch0000009vscode-remote?line=11'>12</a>\u001b[0m     infer(model, tokenizer, sentence)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beverest/users/home/jwu51/Programs/Projects/i2b2-NER-scratch/NER/ner_test_bert_crf.ipynb#ch0000009vscode-remote?line=12'>13</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "if ckpt_name is not None:\n",
    "    if os.path.exists(f\"{NER_MODEL_SAVED_DIR}/{ckpt_name}.ckpt\"):\n",
    "        print(\"Loading the pre-trained checkpoint...\")\n",
    "        ckpt = torch.load(f\"{NER_MODEL_SAVED_DIR}/{ckpt_name}.ckpt\", map_location=DEVICE)\n",
    "        model.load_state_dict(ckpt['model'])\n",
    "        sentence = ['[CLS]'] + list(txt) + ['[SEP]']\n",
    "        infer(model, tokenizer, sentence)\n",
    "    else:\n",
    "        print(\"No such file!\")\n",
    "else:\n",
    "    print(\"mode type error!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "tag2idx = {'B-problem': 0,\n",
    "           'B-test': 1,\n",
    "           'B-treatment': 2,\n",
    "           'I-problem': 3,\n",
    "           'I-test': 4,\n",
    "           'I-treatment': 5,\n",
    "           'O': 6,\n",
    "           'X': 7,\n",
    "           '[CLS]': 8,\n",
    "           '[SEP]': 9\n",
    "           }\n",
    "\n",
    "idx2tag = {tag2idx[key]: key for key in tag2idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch18')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3f829630f1b6563e1c14e66dd3fb557869f017474ce886fb1a5c69364621e8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
