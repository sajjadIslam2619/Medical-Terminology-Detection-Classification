{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7ee39dedd1b64afc9feb49933f2b47b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfdc7261ea294d799bfce1c96dc0bcd9",
              "IPY_MODEL_f44119979806492880bef1076ae3e25e",
              "IPY_MODEL_d1018a7ce6d4470d91b6278dedf96cee"
            ],
            "layout": "IPY_MODEL_e4fdfcc178b649909ae7369f9e8b7cec"
          }
        },
        "dfdc7261ea294d799bfce1c96dc0bcd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32b3a47310144a4ea7d0b7e4bc36b2a2",
            "placeholder": "​",
            "style": "IPY_MODEL_3dafa2d0093b4ac790b2c6b536e92dbd",
            "value": "Downloading: 100%"
          }
        },
        "f44119979806492880bef1076ae3e25e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00f3fad8180148c98c491ca20207777d",
            "max": 435778770,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29f16f6c43f34eec9e7f057b2ee7f811",
            "value": 435778770
          }
        },
        "d1018a7ce6d4470d91b6278dedf96cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b29c5362dc934064959dd61a70b29cc4",
            "placeholder": "​",
            "style": "IPY_MODEL_4408cf0fe74d4f7e9d0e937a074ad277",
            "value": " 436M/436M [00:07&lt;00:00, 58.7MB/s]"
          }
        },
        "e4fdfcc178b649909ae7369f9e8b7cec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b3a47310144a4ea7d0b7e4bc36b2a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dafa2d0093b4ac790b2c6b536e92dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00f3fad8180148c98c491ca20207777d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29f16f6c43f34eec9e7f057b2ee7f811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b29c5362dc934064959dd61a70b29cc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4408cf0fe74d4f7e9d0e937a074ad277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8PBhC9Y78G9",
        "outputId": "1fe7a385-ebc8-4d71-a227-61c0912089ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 32.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 54.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 69.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=7c3a13434a619c7ae10995150d2116ee578b3b8656e5573428a5b41681127cf0\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 28.1 MB/s \n",
            "\u001b[?25hCollecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.7 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install seqeval\n",
        "!pip install torchtext==0.10.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
        "from transformers import AdamW\n",
        "from transformers import AutoModelForSequenceClassification, BertForSequenceClassification"
      ],
      "metadata": {
        "id": "TF-TLAS2_SVd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    print('GPU device not found')\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('Use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNS31KsV_a5E",
        "outputId": "901a4899-2077-4598-ac15-058e01a6802a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "Use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "SEED = 1111\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n",
        "print(len(tokenizer))\n",
        "tokens = tokenizer.tokenize('He had no [entity] cardiac murmur [entity] .')\n",
        "print(tokens)\n",
        "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(indexes)"
      ],
      "metadata": {
        "id": "Qv7x39gPCGXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a67016e-ed32-4ff0-d95a-c0b2192e055d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28996\n",
            "['he', 'had', 'no', '[', 'entity', ']', 'cardiac', 'murmur', '[', 'entity', ']', '.']\n",
            "[1119, 1125, 1185, 164, 9127, 166, 17688, 22895, 164, 9127, 166, 119]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_token = tokenizer.cls_token\n",
        "eos_token = tokenizer.sep_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KziWcljXCUY_",
        "outputId": "b8332b3e-09bd-42bd-8a62-8b72a2d22f7a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] [SEP] [PAD] [UNK]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anvVKt4ZCXRO",
        "outputId": "7b63ec7e-05f4-4b3b-d515-40c2519cdcdc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101 102 0 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = 512"
      ],
      "metadata": {
        "id": "u6RrH2IVCaIm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_bert(sentence):\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    #tokens = tokenizer.tokenize(sentence, max_length=512, truncation=True)\n",
        "    #tokens = tokenizer.tokenize(sentence, padding=True, max_length=512, truncation=True, return_tensors=\"pt\")\n",
        "    return tokens\n",
        "\n",
        "def split_and_cut(sentence):\n",
        "    tokens = sentence.strip().split(\" \")\n",
        "    tokens = tokens[:max_input_length-1]\n",
        "    return tokens\n",
        "\n",
        "def trim_sentence(sent):\n",
        "    try:\n",
        "        sent = sent.split()\n",
        "        sent = sent[:128]\n",
        "        return \" \".join(sent)\n",
        "    except:\n",
        "        return sent"
      ],
      "metadata": {
        "id": "URzopEObCdpH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path_train_url = \"https://raw.githubusercontent.com/sajjadIslam2619/sample_files/main/processed/merged/assertion_NLI_train.tsv\"\n",
        "df_train = pd.read_csv(data_path_train_url, sep=\"\\t\").astype(str)\n",
        "\n",
        "data_path_dev_url = \"https://raw.githubusercontent.com/sajjadIslam2619/sample_files/main/processed/merged/assertion_NLI_dev.tsv\"\n",
        "df_dev = pd.read_csv(data_path_dev_url, sep=\"\\t\").astype(str)\n",
        "\n",
        "data_path_test_url = \"https://raw.githubusercontent.com/sajjadIslam2619/sample_files/main/processed/merged/assertion_NLI_test.tsv\"\n",
        "#data_path_test_url = \"https://raw.githubusercontent.com/sajjadIslam2619/sample_files/main/processed/merged/assertion_NLI_test_mini.tsv\"\n",
        "df_test = pd.read_csv(data_path_test_url, sep=\"\\t\").astype(str)\n",
        "print(len(df_test))\n",
        "\n",
        "f = open(\"train.csv\", \"x\")\n",
        "f.close()\n",
        "f = open(\"dev.csv\", \"x\")\n",
        "f.close()\n",
        "f = open(\"test.csv\", \"x\")\n",
        "f.close()"
      ],
      "metadata": {
        "id": "I1gRzcX6Tnen",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13fe9945-9fc3-4898-b55e-9f356687e525"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sent1_token_type(sent):\n",
        "    try:\n",
        "        return [0]* len(sent)\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "def get_sent2_token_type(sent):\n",
        "    try:\n",
        "        return [1]* len(sent)\n",
        "    except:\n",
        "        return []\n",
        "    \n",
        "def combine_seq(seq):\n",
        "    return \" \".join(seq)\n",
        "\n",
        "def combine_mask(mask):\n",
        "    mask = [str(m) for m in mask]\n",
        "    return \" \".join(mask)"
      ],
      "metadata": {
        "id": "1VEp1-gCC63m"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_original_label = pd.DataFrame()"
      ],
      "metadata": {
        "id": "OdJiBOXNLtbO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = df_train[['label','premise','hypothesis']]\n",
        "df_dev = df_dev[['label','premise','hypothesis']]\n",
        "df_test = df_test[['label','premise','hypothesis']]\n",
        "\n",
        "df_test_original_label = df_test.copy()\n",
        "\n",
        "\n",
        "df_train['premise'] = df_train['premise'].apply(trim_sentence)\n",
        "df_train['hypothesis'] = df_train['hypothesis'].apply(trim_sentence)\n",
        "df_dev['premise'] = df_dev['premise'].apply(trim_sentence)\n",
        "df_dev['hypothesis'] = df_dev['hypothesis'].apply(trim_sentence)\n",
        "df_test['premise'] = df_test['premise'].apply(trim_sentence)\n",
        "df_test['hypothesis'] = df_test['hypothesis'].apply(trim_sentence)\n",
        "\n",
        "df_train['premise'] = '[CLS] ' + df_train['premise'] + ' [SEP] '\n",
        "df_train['hypothesis'] = df_train['hypothesis'] + ' [SEP]'\n",
        "df_dev['premise'] = '[CLS] ' + df_dev['premise'] + ' [SEP] '\n",
        "df_dev['hypothesis'] = df_dev['hypothesis'] + ' [SEP]'\n",
        "df_test['premise'] = '[CLS] ' + df_test['premise'] + ' [SEP] '\n",
        "df_test['hypothesis'] = df_test['hypothesis'] + ' [SEP]'\n",
        "\n",
        "df_train['sent1_t'] = df_train['premise'].apply(tokenize_bert)\n",
        "df_train['sent2_t'] = df_train['hypothesis'].apply(tokenize_bert)\n",
        "df_dev['sent1_t'] = df_dev['premise'].apply(tokenize_bert)\n",
        "df_dev['sent2_t'] = df_dev['hypothesis'].apply(tokenize_bert)\n",
        "df_test['sent1_t'] = df_test['premise'].apply(tokenize_bert)\n",
        "df_test['sent2_t'] = df_test['hypothesis'].apply(tokenize_bert)\n",
        "\n",
        "df_train['sent1_token_type'] = df_train['sent1_t'].apply(get_sent1_token_type)\n",
        "df_train['sent2_token_type'] = df_train['sent2_t'].apply(get_sent2_token_type)\n",
        "df_dev['sent1_token_type'] = df_dev['sent1_t'].apply(get_sent1_token_type)\n",
        "df_dev['sent2_token_type'] = df_dev['sent2_t'].apply(get_sent2_token_type)\n",
        "df_test['sent1_token_type'] = df_test['sent1_t'].apply(get_sent1_token_type)\n",
        "df_test['sent2_token_type'] = df_test['sent2_t'].apply(get_sent2_token_type)\n",
        "\n",
        "df_train['sequence'] = df_train['sent1_t'] + df_train['sent2_t']\n",
        "df_dev['sequence'] = df_dev['sent1_t'] + df_dev['sent2_t']\n",
        "df_test['sequence'] = df_test['sent1_t'] + df_test['sent2_t']\n",
        "\n",
        "\n",
        "df_train['attention_mask'] = df_train['sequence'].apply(get_sent2_token_type)\n",
        "df_dev['attention_mask'] = df_dev['sequence'].apply(get_sent2_token_type)\n",
        "df_test['attention_mask'] = df_test['sequence'].apply(get_sent2_token_type)\n",
        "\n",
        "df_train['token_type'] = df_train['sent1_token_type'] + df_train['sent2_token_type']\n",
        "df_dev['token_type'] = df_dev['sent1_token_type'] + df_dev['sent2_token_type']\n",
        "df_test['token_type'] = df_test['sent1_token_type'] + df_test['sent2_token_type']\n",
        "\n",
        "df_train['sequence'] = df_train['sequence'].apply(combine_seq)\n",
        "df_dev['sequence'] = df_dev['sequence'].apply(combine_seq)\n",
        "df_test['sequence'] = df_test['sequence'].apply(combine_seq)\n",
        "\n",
        "df_train['attention_mask'] = df_train['attention_mask'].apply(combine_mask)\n",
        "df_dev['attention_mask'] = df_dev['attention_mask'].apply(combine_mask)\n",
        "df_test['attention_mask'] = df_test['attention_mask'].apply(combine_mask)\n",
        "\n",
        "df_train['token_type'] = df_train['token_type'].apply(combine_mask)\n",
        "df_dev['token_type'] = df_dev['token_type'].apply(combine_mask)\n",
        "df_test['token_type'] = df_test['token_type'].apply(combine_mask)\n",
        "\n",
        "df_train = df_train[['label', 'sequence', 'attention_mask', 'token_type']]\n",
        "df_dev = df_dev[['label', 'sequence', 'attention_mask', 'token_type']]\n",
        "df_test = df_test[['label', 'sequence', 'attention_mask', 'token_type']]\n",
        "\n",
        "df_train.to_csv('train.csv', index=False)\n",
        "df_dev.to_csv('dev.csv', index=False)\n",
        "df_test.to_csv('test.csv', index=False)"
      ],
      "metadata": {
        "id": "631GcMdyC_GA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_test))\n",
        "print(len(df_test_original_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHeRIOXpJtSu",
        "outputId": "4ea1b0a6-940a-43b4-e230-cc7a30a822f8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59892\n",
            "59892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(df_train.head(3))\n",
        "#print(df_dev.head(2))\n",
        "#print(df_test.head(3))"
      ],
      "metadata": {
        "id": "Tjlv5ljADDd2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdx20myJDc2m",
        "outputId": "d3238ecd-fa5b-4ffa-fab1-123c4509458d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['entailment', 'contradiction'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "QNQoNMs9DfnG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_int(tok_ids):\n",
        "    tok_ids = [int(x) for x in tok_ids]\n",
        "    return tok_ids"
      ],
      "metadata": {
        "id": "vqTNxBt5Dk9n"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.legacy import data \n",
        "\n",
        "TEXT = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = split_and_cut,\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "LABEL = data.LabelField()\n",
        "\n",
        "ATTENTION = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = split_and_cut,\n",
        "                  preprocessing = convert_to_int,\n",
        "                  pad_token = pad_token_idx)\n",
        "\n",
        "TTYPE = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = split_and_cut,\n",
        "                  preprocessing = convert_to_int,\n",
        "                  pad_token = 1)"
      ],
      "metadata": {
        "id": "zA3Ib5TjDnlY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fields = [('label', LABEL), ('sequence', TEXT), ('attention_mask', ATTENTION), ('token_type', TTYPE)]\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "                                        path = '',\n",
        "                                        train = 'train.csv',\n",
        "                                        validation = 'dev.csv',\n",
        "                                        test = 'test.csv',\n",
        "                                        format = 'csv',\n",
        "                                        fields = fields,\n",
        "                                        skip_header = True)"
      ],
      "metadata": {
        "id": "i0r38zzOGprg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of training data: {len(train_data)}\")\n",
        "print(f\"Number of validation data: {len(valid_data)}\")\n",
        "print(f\"Number of testing data: {len(test_data)}\")\n",
        "\n",
        "train_data_len = len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqncRuwXG82x",
        "outputId": "896a1f70-e917-4e8f-97a2-e6c3cba599cd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training data: 38190\n",
            "Number of validation data: 4248\n",
            "Number of testing data: 59892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[0])['sequence'])\n",
        "LABEL.build_vocab(train_data)\n",
        "print(LABEL.vocab.stoi)\n",
        "print(LABEL.vocab.freqs.most_common())\n",
        "print(LABEL.vocab.itos)"
      ],
      "metadata": {
        "id": "qoKGSm_EHE4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a2f9ca2-6d75-48fb-b6f0-476a2e5fbfee"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(None, {'contradiction': 0, 'entailment': 1})\n",
            "[('contradiction', 31825), ('entailment', 6365)]\n",
            "['contradiction', 'entailment']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: len(x.sequence),\n",
        "    sort_within_batch = False, \n",
        "    device = device)"
      ],
      "metadata": {
        "id": "l-zh4MyYHonh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "bert_model = BertModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "7ee39dedd1b64afc9feb49933f2b47b7",
            "dfdc7261ea294d799bfce1c96dc0bcd9",
            "f44119979806492880bef1076ae3e25e",
            "d1018a7ce6d4470d91b6278dedf96cee",
            "e4fdfcc178b649909ae7369f9e8b7cec",
            "32b3a47310144a4ea7d0b7e4bc36b2a2",
            "3dafa2d0093b4ac790b2c6b536e92dbd",
            "00f3fad8180148c98c491ca20207777d",
            "29f16f6c43f34eec9e7f057b2ee7f811",
            "b29c5362dc934064959dd61a70b29cc4",
            "4408cf0fe74d4f7e9d0e937a074ad277"
          ]
        },
        "id": "GZ7AxreEHsgS",
        "outputId": "a45c07dc-cae9-4684-ea04-081478bd324c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ee39dedd1b64afc9feb49933f2b47b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnianyZrHw6Z",
        "outputId": "c5b1f701-96d4-4e30-d041-61f6a6b8339d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BERTNLIModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert_model,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                ):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert_model\n",
        "        \n",
        "        embedding_dim = bert_model.config.to_dict()['hidden_size']\n",
        "        self.out = nn.Linear(embedding_dim, output_dim)\n",
        "        \n",
        "        \n",
        "    def forward(self, sequence, attn_mask, token_type):       \n",
        "        embedded = self.bert(input_ids = sequence, attention_mask = attn_mask, token_type_ids= token_type)[1]\n",
        "        output = self.out(embedded)\n",
        "        \n",
        "        return output"
      ],
      "metadata": {
        "id": "gzaDOxTlH1Uq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HIDDEN_DIM = 512\n",
        "OUTPUT_DIM = len(LABEL.vocab)\n",
        "\n",
        "model = BERTNLIModel(bert_model,\n",
        "                         HIDDEN_DIM,\n",
        "                         OUTPUT_DIM,\n",
        "                        ).to(device)"
      ],
      "metadata": {
        "id": "_QawEY2XH5zk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-CTFFVkH9Q5",
        "outputId": "671d7953-ba98-47da-95f8-90a414155758"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 108,311,810 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from transformers import get_constant_schedule_with_warmup\n",
        "\n",
        "#optimizer = optim.Adam(model.parameters())\n",
        "optimizer = AdamW(model.parameters(),lr=2e-5,eps=1e-6,correct_bias=False)\n",
        "\n",
        "def get_scheduler(optimizer, warmup_steps):\n",
        "    scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)\n",
        "    return scheduler"
      ],
      "metadata": {
        "id": "8_oCrmVEIfrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b99ccd39-17e5-4e76-c82e-fdd6606f2f56"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "E2hOFATmIwVq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = (max_preds.squeeze(1)==y).float()\n",
        "    return correct.sum() / len(y)"
      ],
      "metadata": {
        "id": "LJUHPx1gIy-f"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_grad_norm = 1\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, scheduler):\n",
        "    #print(iterator)\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "\n",
        "        optimizer.zero_grad() # clear gradients first\n",
        "        torch.cuda.empty_cache() # releases all unoccupied cached memory \n",
        "        \n",
        "\n",
        "        sequence = batch.sequence\n",
        "        attn_mask = batch.attention_mask\n",
        "        token_type = batch.token_type\n",
        "        label = batch.label\n",
        "        \n",
        "        predictions = model(sequence, attn_mask, token_type)\n",
        "        loss = criterion(predictions, label)\n",
        "        \n",
        "        acc = categorical_accuracy(predictions, label)\n",
        "        \n",
        "        #if fp16:\n",
        "            #with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                #scaled_loss.backward()\n",
        "            #torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), max_grad_norm)\n",
        "        #else:\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "sCYCq7XLI5BS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    #print(iterator)\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "            sequence = batch.sequence\n",
        "            attn_mask = batch.attention_mask\n",
        "            token_type = batch.token_type\n",
        "            labels = batch.label\n",
        "                        \n",
        "            predictions = model(sequence, attn_mask, token_type)\n",
        "            \n",
        "            loss = criterion(predictions, labels)\n",
        "                \n",
        "            acc = categorical_accuracy(predictions, labels)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "NgTtJDR8JJCq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "-SDiwaSrJNe6"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "N_EPOCHS = 6\n",
        "\n",
        "warmup_percent = 0.2\n",
        "total_steps = math.ceil(N_EPOCHS*train_data_len*1./BATCH_SIZE)\n",
        "warmup_steps = int(total_steps*warmup_percent)\n",
        "scheduler = get_scheduler(optimizer, warmup_steps)\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, scheduler)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'bert-nli.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "O2rI_xNAJQUK",
        "outputId": "65d1f8ce-3fcb-437d-e2e7-5fec70b04733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-2e6642b091b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('bert-nli.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7CiQ6dLQa3x",
        "outputId": "ea45160d-8c12-4316-dcf7-4f6718b7530e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.070 |  Test Acc: 98.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "def test(model, iterator):\n",
        "    model.eval()\n",
        "    for batch in iterator:\n",
        "      #print('batch ', batch)\n",
        "      with torch.no_grad():\n",
        "        #batch = tuple(t.to(device) for t in batch)\n",
        "        sequence = batch.sequence\n",
        "        attn_mask = batch.attention_mask\n",
        "        token_type = batch.token_type\n",
        "        label = batch.label\n",
        "                        \n",
        "        result = model(sequence, attn_mask, token_type)\n",
        "\n",
        "        logits = result\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = label.to('cpu').numpy()\n",
        "\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "        #predictions.append(prediction)\n",
        "        #true_labels.append(label)\n",
        "        \n",
        "    return predictions, true_labels"
      ],
      "metadata": {
        "id": "0HNXDk0lU9Y8"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of BucketIterator in **test_2** method DataFrame is used. And probabilities are calculated. BucketIterator does not maintain order of the data. But to comapre the probability for each test sentence with 5 other generated sentence order is necessary. "
      ],
      "metadata": {
        "id": "ek3WIdGmfHAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test without BucketIterator\n",
        "def test_2(model, df_test_original_label):\n",
        "    model.eval()\n",
        "    for i in range (len(df_test_original_label)): \n",
        "      with torch.no_grad():\n",
        "        premise = df_test_original_label['premise'][i]\n",
        "        hypothesis = df_test_original_label['hypothesis'][i]\n",
        "        \n",
        "        premise = '[CLS] ' + premise + ' [SEP]'\n",
        "        hypothesis = hypothesis + ' [SEP]'\n",
        "    \n",
        "        prem_t = tokenize_bert(premise)\n",
        "        hypo_t = tokenize_bert(hypothesis)\n",
        "    \n",
        "        prem_type = get_sent1_token_type(prem_t)\n",
        "        hypo_type = get_sent2_token_type(hypo_t)\n",
        "    \n",
        "        indexes = prem_t + hypo_t\n",
        "    \n",
        "        indexes = tokenizer.convert_tokens_to_ids(indexes)\n",
        "        indexes_type = prem_type + hypo_type\n",
        "    \n",
        "        attn_mask = get_sent2_token_type(indexes)\n",
        "\n",
        "        indexes = torch.LongTensor(indexes).unsqueeze(0).to(device)\n",
        "        indexes_type = torch.LongTensor(indexes_type).unsqueeze(0).to(device)\n",
        "        attn_mask = torch.LongTensor(attn_mask).unsqueeze(0).to(device)\n",
        "    \n",
        "        #print(indexes_type)\n",
        "        result = model(indexes, attn_mask, indexes_type)                \n",
        "        #result = model(sequence, attn_mask, token_type)\n",
        "\n",
        "        logits = result\n",
        "\n",
        "        prob = logits.softmax(dim=1).cpu().numpy()\n",
        "        #prob_label_is_true = probs[:,1]\n",
        "\n",
        "        #prob = F.softmax(logits, dim=1).cpu().numpy()\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        #label_ids = label.to('cpu').numpy()\n",
        "\n",
        "        #probs_true.append(prob_label_is_true)\n",
        "        probs.append(prob)\n",
        "        predictions.append(logits)\n",
        "        #true_labels.append(label)\n",
        "\n",
        "        #predictions.append(prediction)\n",
        "        #true_labels.append(label)\n",
        "        \n",
        "    return predictions, probs"
      ],
      "metadata": {
        "id": "Blnt3k8vLEbM"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ol3sZYdZgMdQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Used test method**"
      ],
      "metadata": {
        "id": "kZwKhd1dgOju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "predictions , true_labels, probs = [], [], []\n",
        "\n",
        "predictions, true_labels = test(model, test_iterator)\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten() \n",
        "  y_true.extend(true_labels[i])\n",
        "  y_pred.extend(pred_labels_i) \n"
      ],
      "metadata": {
        "id": "dqCzoMElVAJ_"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Zi6mGwJXiy4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Caution:** To calculate F1 score for these 2 label test method is necessary.\n",
        "\n",
        "Label in order: ['contradiction', 'entailment']"
      ],
      "metadata": {
        "id": "4V1A8Xavi9XZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score,accuracy_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(\"f1 socre: %f\"%(f1_score(y_true, y_pred, average='micro')))\n",
        "print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
        "report = classification_report(y_true, y_pred,digits=4)\n",
        "print(\"***** Eval results *****\")\n",
        "print(\"\\n%s\"%(report))\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "print('***** Confusion Matrix *****')\n",
        "print(matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km4glc9zihaq",
        "outputId": "e122bad2-a1aa-47a6-8de5-9f7e56cc2374"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 socre: 0.982001\n",
            "Accuracy score: 0.982001\n",
            "***** Eval results *****\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9887    0.9898    0.9892     49910\n",
            "           1     0.9485    0.9432    0.9459      9982\n",
            "\n",
            "    accuracy                         0.9820     59892\n",
            "   macro avg     0.9686    0.9665    0.9675     59892\n",
            "weighted avg     0.9820    0.9820    0.9820     59892\n",
            "\n",
            "***** Confusion Matrix *****\n",
            "[[49399   511]\n",
            " [  567  9415]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Used test_2 method**"
      ],
      "metadata": {
        "id": "ELg2D8JpgWZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "y_prob = []\n",
        "y_entail_prob = []\n",
        "predictions , true_labels, probs = [], [], []\n",
        "\n",
        "print('df_test_original_label ::', len(df_test_original_label))\n",
        "predictions, probs = test_2(model, df_test_original_label)\n",
        "\n",
        "for i in range (len(df_test_original_label)): \n",
        "  label = df_test_original_label['label'][i]\n",
        "  if label == 'entailment': label = 1\n",
        "  else: label = 0\n",
        "  true_labels.append(label)\n",
        "\n",
        "print(len(true_labels))\n",
        "# For each input batch...\n",
        "for i in range(len(predictions)):\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten() \n",
        "  #y_true.extend(true_labels[i])\n",
        "  y_pred.extend(pred_labels_i) \n",
        "  y_prob.extend(probs[i])\n",
        "\n",
        "for i in range (len(true_labels)):\n",
        "  y_true.append(true_labels[i])\n",
        "\n",
        "#print(len(y_pred[0]))\n",
        "for i in range(len(y_pred)):\n",
        "  pred_value = y_pred[i]\n",
        "  #print(y_prob[i])\n",
        "  if pred_value == 0:\n",
        "    y_entail_prob.append(min(y_prob[i]))\n",
        "  elif pred_value == 1:\n",
        "    y_entail_prob.append(max(y_prob[i]))\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN9Tn_fweCJU",
        "outputId": "b51e4bb9-67af-42a1-efa2-5a884900eb35"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_test_original_label :: 59892\n",
            "59892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('No of total test sentecne : ',len(y_true))\n",
        "test_data_len = int(len(y_true)/6)\n",
        "print('No of actual test sentence : ', test_data_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR6qQ2SCQta-",
        "outputId": "39af6254-02a9-4fef-dcc8-223219aadbf3"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of total test sentecne :  59892\n",
            "No of actual test sentence :  9982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('predictions :: ', len(predictions))\n",
        "print('true_labels :: ', len(true_labels))\n",
        "print('df_test_original_label :: ', len(df_test_original_label))\n",
        "print('y_true :: ', len(y_true))\n",
        "print('y_pred :: ', len(y_pred))\n",
        "print('y_prob :: ', len(y_prob))\n",
        "print('probs :: ', len(probs))\n",
        "print('max_prob :: ', len(y_entail_prob))\n",
        "print('slice ', y_entail_prob[11736: 11740])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF7GcoRt4_0z",
        "outputId": "6f23766a-cbf0-4e55-cff9-89a684028ccb"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions ::  59892\n",
            "true_labels ::  59892\n",
            "df_test_original_label ::  59892\n",
            "y_true ::  59892\n",
            "y_pred ::  59892\n",
            "y_prob ::  59892\n",
            "probs ::  59892\n",
            "max_prob ::  59892\n",
            "slice  [0.00040664885, 0.00037196692, 0.0002589777, 0.0002357064]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = ['present', 'absent', 'possible', 'conditional', 'hypothetical', 'associated_with_someone_else', 'multiple_label']"
      ],
      "metadata": {
        "id": "ub5CfPhnegrb"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each label, it is possible to get multiple entailment from hypothesis. Following code is calculation how many sentence have multiple entailment. "
      ],
      "metadata": {
        "id": "Aj2Aa738g2O9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "present_true = 0\n",
        "present_false = 0\n",
        "absent_true = 0\n",
        "absent_false = 0\n",
        "possible_true = 0\n",
        "possible_false = 0 \n",
        "conditional_true = 0 \n",
        "conditional_false = 0\n",
        "hypothetical_true = 0\n",
        "hypothetical_false = 0\n",
        "associated_true = 0\n",
        "associated_false = 0\n",
        "\n",
        "true_label = []\n",
        "pred_label = []\n",
        "\n",
        "for i in range(test_data_len):\n",
        "  sentence = df_test_original_label['premise'][i]\n",
        "  hypothesis = df_test_original_label['hypothesis'][i]\n",
        "  label = hypothesis.split(' ')[-1]\n",
        "  label_index = label_names.index(label)\n",
        "  true_label.append(label_index)\n",
        "  \n",
        "  y_true_label = y_true[i]\n",
        "  is_pred_label_set = False\n",
        "  y_pred_label_list = []\n",
        "  for j in range(5):\n",
        "    next_sentence = df_test_original_label['premise'][i*5+test_data_len+j]\n",
        "    y_pred_label = y_pred [i*5+test_data_len+j]\n",
        "    if y_pred_label == y_true_label:\n",
        "      pred_label_index = label_names.index('multiple_label')\n",
        "      is_pred_label_set = True\n",
        "      break\n",
        "\n",
        "    y_pred_label_list.append(y_pred_label)\n",
        "  \n",
        "  if len(set(y_pred_label_list)) > 1:\n",
        "    pred_label_index = label_names.index('multiple_label')\n",
        "    is_pred_label_set = True\n",
        "\n",
        "  if is_pred_label_set == False:\n",
        "    pred_label.append(label_index)\n",
        "    if label == 'present': \n",
        "      present_true = present_true +1 \n",
        "    if label == 'absent':\n",
        "      absent_true = absent_true + 1\n",
        "    if label == 'possible':\n",
        "      possible_true = possible_true + 1\n",
        "    if label == 'conditional':\n",
        "      conditional_true = conditional_true + 1\n",
        "    if label == 'hypothetical':\n",
        "      hypothetical_true = hypothetical_true + 1\n",
        "    if label == 'associated_with_someone_else':\n",
        "      associated_true = associated_true + 1\n",
        "  else:\n",
        "    pred_label.append(pred_label_index)\n",
        "    if label == 'present': \n",
        "      present_false = present_false + 1 \n",
        "    if label == 'absent':\n",
        "      absent_false = absent_false + 1\n",
        "    if label == 'possible':\n",
        "      possible_false = possible_false + 1\n",
        "    if label == 'conditional':\n",
        "      conditional_false = conditional_false + 1\n",
        "    if label == 'hypothetical':\n",
        "      hypothetical_false = hypothetical_false + 1\n",
        "    if label == 'associated_with_someone_else':\n",
        "      associated_false = associated_false + 1\n",
        "\n",
        "#print(len(true_label))\n",
        "#print(len(pred_label))\n",
        "print('present - single ', present_true)\n",
        "print('present - multiple ', present_false)\n",
        "print('absent - single ', absent_true)\n",
        "print('absent - multiple ', absent_false)\n",
        "print('possible - single ', possible_true)\n",
        "print('possible - multiple ', possible_false)\n",
        "print('conditional - single ', conditional_true)\n",
        "print('conditional - multiple ', conditional_false)\n",
        "print('hypothetical - single ', hypothetical_true)\n",
        "print('hypothetical - multiple ', hypothetical_false)\n",
        "print('associated_with_someone_else - single ', associated_true)\n",
        "print('associated_with_someone_else - multiple ', associated_false)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t6Xsk6dEsq1",
        "outputId": "29f60a41-a948-4730-d78d-c735ceea0aec"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "present - single  6512\n",
            "present - multiple  152\n",
            "absent - single  2210\n",
            "absent - multiple  76\n",
            "possible - single  349\n",
            "possible - multiple  151\n",
            "conditional - single  58\n",
            "conditional - multiple  67\n",
            "hypothetical - single  254\n",
            "hypothetical - multiple  39\n",
            "associated_with_someone_else - single  90\n",
            "associated_with_someone_else - multiple  24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = ['present', 'absent', 'possible', 'conditional', 'hypothetical', 'associated_with_someone_else']"
      ],
      "metadata": {
        "id": "t0ZyYqfderuZ"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculation based on probability. Marging all 6 generated sentence in one to calculate F1 score.  "
      ],
      "metadata": {
        "id": "xHJD2bZt4rml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_label = []\n",
        "pred_label = []\n",
        "prob_by_group = []\n",
        "#print (y_max_prob)\n",
        "for i in range(test_data_len):\n",
        "  sentence = df_test_original_label['premise'][i]\n",
        "  hypothesis = df_test_original_label['hypothesis'][i]\n",
        "  label = hypothesis.split(' ')[-1]\n",
        "  label_index = label_names.index(label)\n",
        "  true_label.append(label_index)\n",
        "\n",
        "  prob_single_group = []\n",
        "  max_probability = y_entail_prob [i]\n",
        "  prob_single_group.append(max_probability)\n",
        "  for j in range(5):\n",
        "    next_sentence = df_test_original_label['premise'][i*5+test_data_len+j]\n",
        "    prob = y_entail_prob [i*5+test_data_len+j]\n",
        "    \n",
        "    prob_single_group.append(prob)\n",
        "    if max_probability < prob : \n",
        "      #print('index :: ', i*5+test_data_len+j)\n",
        "      #print('prob :: ', prob)\n",
        "      max_probability = prob\n",
        "      next_hypothesis = df_test_original_label['hypothesis'][i*5+test_data_len+j]\n",
        "      label = next_hypothesis.split(' ')[-1]\n",
        "      label_index = label_names.index(label)\n",
        "\n",
        "    \n",
        "  pred_label.append(label_index)\n",
        "  prob_by_group.append(prob_single_group)\n",
        "  \n",
        "\n",
        "#print(prob_by_group)\n",
        "#print(len(true_label))\n",
        "#print(len(pred_label))\n",
        "print(pred_label[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwSoT4cH4pvk",
        "outputId": "d9b5f693-3e29-4088-ac88-4a3a76510f9a"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 1, 0, 0, 0, 4, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label in order : ['present', 'absent', 'possible', 'conditional', 'hypothetical', 'associated_with_someone_else']"
      ],
      "metadata": {
        "id": "MRgI3nqpGer2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score,accuracy_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(\"f1 socre: %f\"%(f1_score(true_label, pred_label, average='micro')))\n",
        "print(\"Accuracy score: %f\"%(accuracy_score(true_label, pred_label)))\n",
        "report = classification_report(true_label, pred_label,digits=4)\n",
        "print(\"***** Eval results *****\")\n",
        "print(\"\\n%s\"%(report))\n",
        "matrix = confusion_matrix(true_label, pred_label)\n",
        "print('***** Confusion Matrix *****')\n",
        "print(matrix)"
      ],
      "metadata": {
        "id": "MZuGV4U1gVx1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c7ae368-c276-44f1-e1a1-3b5253317078"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 socre: 0.945602\n",
            "Accuracy score: 0.945602\n",
            "***** Eval results *****\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9537    0.9763    0.9649      6664\n",
            "           1     0.9648    0.9602    0.9625      2286\n",
            "           2     0.7813    0.6860    0.7306       500\n",
            "           3     0.6835    0.4320    0.5294       125\n",
            "           4     0.9299    0.8601    0.8936       293\n",
            "           5     0.9271    0.7807    0.8476       114\n",
            "\n",
            "    accuracy                         0.9456      9982\n",
            "   macro avg     0.8734    0.7825    0.8214      9982\n",
            "weighted avg     0.9432    0.9456    0.9437      9982\n",
            "\n",
            "***** Confusion Matrix *****\n",
            "[[6506   49   72   23   11    3]\n",
            " [  72 2195   14    1    0    4]\n",
            " [ 141   12  343    1    3    0]\n",
            " [  63    2    1   54    5    0]\n",
            " [  29    4    8    0  252    0]\n",
            " [  11   13    1    0    0   89]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_inference(premise, hypothesis, model, device):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    premise = '[CLS] ' + premise + ' [SEP]'\n",
        "    hypothesis = hypothesis + ' [SEP]'\n",
        "    \n",
        "    prem_t = tokenize_bert(premise)\n",
        "    hypo_t = tokenize_bert(hypothesis)\n",
        "    \n",
        "    prem_type = get_sent1_token_type(prem_t)\n",
        "    hypo_type = get_sent2_token_type(hypo_t)\n",
        "    \n",
        "    indexes = prem_t + hypo_t\n",
        "    \n",
        "    indexes = tokenizer.convert_tokens_to_ids(indexes)\n",
        "    indexes_type = prem_type + hypo_type\n",
        "    \n",
        "    attn_mask = get_sent2_token_type(indexes)\n",
        "\n",
        "    indexes = torch.LongTensor(indexes).unsqueeze(0).to(device)\n",
        "    indexes_type = torch.LongTensor(indexes_type).unsqueeze(0).to(device)\n",
        "    attn_mask = torch.LongTensor(attn_mask).unsqueeze(0).to(device)\n",
        "    \n",
        "    #print(indexes_type)\n",
        "    prediction = model(indexes, attn_mask, indexes_type)\n",
        "    \n",
        "    prediction = prediction.argmax(dim=-1).item()\n",
        "    \n",
        "    return LABEL.vocab.itos[prediction]"
      ],
      "metadata": {
        "id": "HaKo8uCPQfhB"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "premise = 'She had [entity] a functioning arteriovenous fistula [entity] with a thrill and a bruit in her left arm .'\n",
        "hypothesis = 'a functioning arteriovenous fistula is possible'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0ddYQw1fQjpx",
        "outputId": "57d5094d-08f0-4c54-d7af-cd3720cb3049"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'contradiction'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "premise = 'The differential diagnosis included [entity] viral pneumonitis [entity] , Mycoplasma , Chlamydia .'\n",
        "hypothesis = 'viral pneumonitis is possible'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GeLxjNGNbnma",
        "outputId": "8bd0a565-47be-4f89-9b75-ef10b6e44437"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'entailment'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "premise = 'Son died at 50 of [entity] diabetes [entity] and myocardial infarction .'\n",
        "hypothesis = 'diabetes is present'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gOPxE3TzcHos",
        "outputId": "eadcc2d5-7f51-4ca7-a41a-bafef9ee3ef1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'contradiction'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "premise = 'She is [entity] allergic [entity] to Augmentin which gives her a rash .'\n",
        "hypothesis = 'allergic is conditional'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "so5JemnCb0yC",
        "outputId": "3fea2f9e-a92c-44ec-a56a-dfe82692d205"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'entailment'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "premise = 'She is suffering from [entity] fever [entity] .'\n",
        "hypothesis = 'fever is associated with someone else'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mUOlTtytcGJ-",
        "outputId": "98c0fdff-6c62-40bf-a8dd-9ab65c3c0ee0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'contradiction'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "premise = 'There was [entity] an initial murmur [entity] on admission likely secondary to severe anemia which has since resolved .'\n",
        "hypothesis = 'an initial murmur is absent'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qbPuWbB3ckiP",
        "outputId": "58b13ab8-0387-447e-e57f-1421dbc1585a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'contradiction'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    }
  ]
}